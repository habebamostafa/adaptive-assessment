{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2211287,"sourceType":"datasetVersion","datasetId":1327957}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-15T15:23:24.790435Z","iopub.execute_input":"2025-09-15T15:23:24.790743Z","iopub.status.idle":"2025-09-15T15:23:24.795496Z","shell.execute_reply.started":"2025-09-15T15:23:24.790716Z","shell.execute_reply":"2025-09-15T15:23:24.794794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport torch.quantization\nfrom torch.quantization import QuantStub, DeQuantStub, prepare_qat, convert\nimport matplotlib.pyplot as plt\nimport math\nfrom torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR\nimport time\nfrom torch.cuda.amp import autocast, GradScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configuration for optimal performance\nclass Config:\n    # Hardware settings\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Model architecture (optimized for speed and accuracy)\n    img_size = 64\n    patch_size = 8\n    embed_dim = 256\n    depth = 6\n    num_heads = 8\n    mlp_ratio = 3.0\n    \n    # Training settings\n    batch_size = 128\n    num_epochs = 250\n    initial_lr = 0.001\n    weight_decay = 0.05\n    \n    # QAT settings - FIXED CONFIG\n    qat_epochs = 10\n    qat_lr = 1e-4\n    \n    # Data settings\n    num_workers = 4\n    pin_memory = True\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\n# Data paths\nbase_path = \"/kaggle/input/cifar10-64x64-resized-via-cai-super-resolution/cifar10-32\"\n\n# Data augmentation\ntrain_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomCrop(config.img_size, padding=4, padding_mode='reflect'),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616]),\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n])\n\ndef create_dataframe(split):\n    \"\"\"Create DataFrame with image paths and labels\"\"\"\n    data = []\n    split_path = os.path.join(base_path, split)\n    \n    for class_name in sorted(os.listdir(split_path)):\n        class_path = os.path.join(split_path, class_name)\n        if os.path.isdir(class_path):\n            for img_name in os.listdir(class_path):\n                img_path = os.path.join(class_path, img_name)\n                data.append([img_path, class_name])\n    \n    return pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n\nprint(\"Loading dataset...\")\nstart_time = time.time()\n\ntrain_df = create_dataframe(\"train\")\ntest_df = create_dataframe(\"test\")\n\n# Encode labels\nle = LabelEncoder()\ntrain_df[\"label\"] = le.fit_transform(train_df[\"label\"])\ntest_df[\"label\"] = le.transform(test_df[\"label\"])\n\nprint(f\"Dataset loaded in {time.time() - start_time:.2f}s\")\nprint(f\"Train samples: {len(train_df)}, Test samples: {len(test_df)}\")\n\nclass CIFARDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.image_paths = df[\"image_path\"].tolist()\n        self.labels = df[\"label\"].tolist()\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        try:\n            image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n            label = self.labels[idx]\n            \n            if self.transform:\n                image = self.transform(image)\n                \n            return image, label\n        except:\n            # Return black image for corrupted files\n            image = torch.zeros(3, config.img_size, config.img_size)\n            label = self.labels[idx]\n            return image, label\n\n# Create datasets\ntrain_dataset = CIFARDataset(train_df, transform=train_transform)\ntest_dataset = CIFARDataset(test_df, transform=test_transform)\n\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=config.batch_size, \n    shuffle=True,\n    num_workers=config.num_workers,\n    pin_memory=config.pin_memory\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=config.batch_size, \n    shuffle=False,\n    num_workers=config.num_workers,\n    pin_memory=config.pin_memory\n)\n\n# FIXED ViT MODEL FOR QAT\nclass PatchEmbedding(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, embed_dim=256):\n        super().__init__()\n        self.patch_size = patch_size\n        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n        \n    def forward(self, x):\n        x = self.proj(x)\n        x = x.flatten(2).transpose(1, 2)\n        return x\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout=0.1):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n        self.attn_drop = nn.Dropout(dropout)\n        self.proj = nn.Linear(embed_dim, embed_dim)\n        self.proj_drop = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = attn.softmax(dim=-1)\n        attn = self.attn_drop(attn)\n        \n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)l\n        return x\n\nclass MLP(nn.Module):\n    def __init__(self, in_features, hidden_features=None, drop=0.1):\n        super().__init__()\n        hidden_features = hidden_features or int(in_features * config.mlp_ratio)\n        \n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = nn.GELU()\n        self.fc2 = nn.Linear(hidden_features, in_features)\n        self.drop = nn.Dropout(drop)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4.0, drop=0.1):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(dim)\n        self.attn = MultiHeadAttention(dim, num_heads, drop)\n        self.norm2 = nn.LayerNorm(dim)\n        self.mlp = MLP(dim, hidden_features=int(dim * mlp_ratio), drop=drop)\n        \n    def forward(self, x):\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nclass OptimizedViT(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=3.0, dropout=0.1):\n        super().__init__()\n        \n        # Quantization stubs - MUST BE AT BEGINNING/END\n        self.quant = QuantStub()\n        self.dequant = DeQuantStub()\n        \n        # Patch embedding\n        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        num_patches = (img_size // patch_size) ** 2\n        \n        # Position embeddings\n        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n        self.pos_drop = nn.Dropout(dropout)\n        \n        # Transformer blocks\n        self.blocks = nn.ModuleList([\n            TransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n            for _ in range(depth)\n        ])\n        \n        self.norm = nn.LayerNorm(embed_dim)\n        self.head = nn.Linear(embed_dim, num_classes)\n        \n        self.apply(self._init_weights)\n        \n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.trunc_normal_(m.weight, std=0.02)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.LayerNorm):\n            nn.init.constant_(m.bias, 0)\n            nn.init.constant_(m.weight, 1.0)\n        elif isinstance(m, nn.Conv2d):\n            nn.init.kaiming_normal_(m.weight, mode='fan_out')\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x):\n        # Quantize input\n        x = self.quant(x)\n        \n        # Patch embedding\n        x = self.patch_embed(x)\n        x = x + self.pos_embed\n        x = self.pos_drop(x)\n\n        for block in self.blocks:\n            x = block(x)\n\n        x = self.norm(x)\n        x = x.mean(dim=1)\n        x = self.head(x)\n        \n        # Dequantize output\n        x = self.dequant(x)\n        return x\n\ndef train_model(model, train_loader, test_loader, config):\n    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.initial_lr, weight_decay=config.weight_decay)\n    scheduler = CosineAnnealingLR(optimizer, T_max=config.num_epochs)\n    \n    scaler = GradScaler()\n    best_acc = 0.0\n    train_losses, test_accs = [], []\n    \n    print(\"Starting training...\")\n    \n    for epoch in range(config.num_epochs):\n        # Training\n        model.train()\n        train_loss = 0.0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(config.device), labels.to(config.device)\n            \n            optimizer.zero_grad()\n            \n            with autocast():\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            train_loss += loss.item()\n        \n        # Validation\n        model.eval()\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for images, labels in test_loader:\n                images, labels = images.to(config.device), labels.to(config.device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        test_acc = 100. * correct / total\n        avg_loss = train_loss / len(train_loader)\n        \n        train_losses.append(avg_loss)\n        test_accs.append(test_acc)\n        \n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save({\n                'model_state_dict': model.state_dict(),\n                'accuracy': test_acc,\n                'epoch': epoch\n            }, 'best_model.pth')\n        \n        scheduler.step()\n        \n        if (epoch + 1) % 10 == 0:\n            print(f'Epoch [{epoch+1}/{config.num_epochs}], Loss: {avg_loss:.4f}, Acc: {test_acc:.2f}%, Best: {best_acc:.2f}%')\n    \n    print(f'Best Accuracy: {best_acc:.2f}%')\n    return train_losses, test_accs, best_acc\n\n# FIXED QAT FUNCTION\ndef prepare_model_for_qat(model):\n    \"\"\"Prepare model for QAT with proper configuration\"\"\"\n    model.train()\n    \n    # FIXED: Use per_tensor quantization instead of per_channel\n    model.qconfig = torch.quantization.QConfig(\n        activation=torch.quantization.MinMaxObserver.with_args(dtype=torch.quint8),\n        weight=torch.quantization.MinMaxObserver.with_args(dtype=torch.qint8)\n    )\n    \n    # Prepare for QAT\n    model_prepared = prepare_qat(model, inplace=False)\n    return model_prepared\n\ndef apply_qat(model, train_loader, config):\n    \"\"\"Apply Quantization-Aware Training\"\"\"\n    print(\"Preparing model for QAT...\")\n    \n    # Prepare model\n    model_qat = prepare_model_for_qat(model)\n    model_qat = model_qat.to(config.device)\n    \n    # QAT training\n    optimizer = torch.optim.Adam(model_qat.parameters(), lr=config.qat_lr)\n    criterion = nn.CrossEntropyLoss()\n    \n    print(\"Starting QAT fine-tuning...\")\n    \n    for epoch in range(config.qat_epochs):\n        model_qat.train()\n        running_loss = 0.0\n        \n        for i, (images, labels) in enumerate(train_loader):\n            if i > 20:  # Use only 20 batches for speed\n                break\n                \n            images, labels = images.to(config.device), labels.to(config.device)\n            \n            optimizer.zero_grad()\n            outputs = model_qat(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n        \n        print(f'QAT Epoch [{epoch+1}/{config.qat_epochs}], Loss: {running_loss/20:.4f}')\n    \n    # Convert to quantized model\n    print(\"Converting to quantized model...\")\n    model_qat.eval()\n    model_quantized = convert(model_qat, inplace=False)\n    \n    return model_quantized\n\n# Main execution\nif __name__ == \"__main__\":\n    print(\"=\"*50)\n    print(\"ViT WITH FIXED QAT IMPLEMENTATION\")\n    print(\"=\"*50)\n    \n    # Create and train model\n    model = OptimizedViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        mlp_ratio=config.mlp_ratio,\n        num_classes=len(le.classes_)\n    ).to(config.device)\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Model parameters: {total_params:,}\")\n    \n    # Train the model\n    train_losses, test_accs, best_acc = train_model(model, train_loader, test_loader, config)\n    \n    # Plot results\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses)\n    plt.title('Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.grid(True)\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(test_accs)\n    plt.title('Test Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig('training_results.png')\n    plt.show()\n    \n    # Apply QAT if accuracy is good\n    if best_acc > 70.0:\n        print(f\"\\nApplying QAT (Accuracy: {best_acc:.2f}% > 70%)\")\n        \n        # Load best model\n        checkpoint = torch.load('best_model.pth')\n        model.load_state_dict(checkpoint['model_state_dict'])\n        \n        # Apply QAT\n        quantized_model = apply_qat(model, train_loader, config)\n        \n        # Test quantized model\n        quantized_model.eval()\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for images, labels in test_loader:\n                images, labels = images.to(config.device), labels.to(config.device)\n                outputs = quantized_model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        qat_acc = 100. * correct / total\n        \n        # Save quantized model\n        torch.save(quantized_model.state_dict(), 'quantized_model.pth')\n        \n        # Model size comparison\n        original_size = sum(p.numel() * 4 for p in model.parameters()) / 1024 / 1024\n        quantized_size = sum(p.numel() * p.element_size() for p in quantized_model.parameters()) / 1024 / 1024\n        \n        print(f\"\\n=== QAT RESULTS ===\")\n        print(f\"Original accuracy: {best_acc:.2f}%\")\n        print(f\"Quantized accuracy: {qat_acc:.2f}%\")\n        print(f\"Accuracy drop: {best_acc - qat_acc:.2f}%\")\n        print(f\"Original size: {original_size:.2f} MB\")\n        print(f\"Quantized size: {quantized_size:.2f} MB\")\n        print(f\"Size reduction: {(1 - quantized_size/original_size)*100:.1f}%\")\n        \n    else:\n        print(f\"\\nSkipping QAT (Accuracy: {best_acc:.2f}% <= 70%)\")\n    \n    print(\"\\nTraining completed successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-26T15:42:08.207886Z","iopub.execute_input":"2025-09-26T15:42:08.208758Z","iopub.status.idle":"2025-09-26T18:20:41.503138Z","shell.execute_reply.started":"2025-09-26T15:42:08.208720Z","shell.execute_reply":"2025-09-26T18:20:41.502029Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading dataset...\nDataset loaded in 40.48s\nTrain samples: 50000, Test samples: 10000\n==================================================\nViT WITH FIXED QAT IMPLEMENTATION\n==================================================\nModel parameters: 4,019,466\nStarting training...\nEpoch [10/250], Loss: 1.4405, Acc: 58.05%, Best: 58.05%\nEpoch [20/250], Loss: 1.2095, Acc: 68.43%, Best: 68.43%\nEpoch [30/250], Loss: 1.0253, Acc: 75.67%, Best: 75.67%\nEpoch [40/250], Loss: 0.9162, Acc: 77.94%, Best: 78.04%\nEpoch [50/250], Loss: 0.8357, Acc: 78.56%, Best: 79.84%\nEpoch [60/250], Loss: 0.7785, Acc: 80.04%, Best: 81.00%\nEpoch [70/250], Loss: 0.7258, Acc: 80.46%, Best: 81.43%\nEpoch [80/250], Loss: 0.6852, Acc: 79.75%, Best: 81.53%\nEpoch [90/250], Loss: 0.6500, Acc: 80.36%, Best: 81.53%\nEpoch [100/250], Loss: 0.6230, Acc: 80.83%, Best: 81.53%\nEpoch [110/250], Loss: 0.6027, Acc: 80.89%, Best: 81.53%\nEpoch [120/250], Loss: 0.5826, Acc: 81.54%, Best: 81.81%\nEpoch [130/250], Loss: 0.5722, Acc: 81.90%, Best: 81.90%\nEpoch [140/250], Loss: 0.5574, Acc: 81.80%, Best: 81.95%\nEpoch [150/250], Loss: 0.5436, Acc: 81.78%, Best: 81.95%\nEpoch [160/250], Loss: 0.5360, Acc: 82.18%, Best: 82.43%\nEpoch [170/250], Loss: 0.5285, Acc: 82.12%, Best: 82.43%\nEpoch [180/250], Loss: 0.5204, Acc: 81.99%, Best: 82.60%\nEpoch [190/250], Loss: 0.5148, Acc: 82.23%, Best: 82.94%\nEpoch [200/250], Loss: 0.5100, Acc: 82.59%, Best: 83.00%\nEpoch [210/250], Loss: 0.5060, Acc: 83.00%, Best: 83.16%\nEpoch [220/250], Loss: 0.5047, Acc: 83.22%, Best: 83.22%\nEpoch [230/250], Loss: 0.5030, Acc: 83.10%, Best: 83.37%\nEpoch [240/250], Loss: 0.5025, Acc: 83.21%, Best: 83.37%\nEpoch [250/250], Loss: 0.5025, Acc: 83.22%, Best: 83.37%\nBest Accuracy: 83.37%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\nApplying QAT (Accuracy: 83.37% > 70%)\nPreparing model for QAT...\nStarting QAT fine-tuning...\nQAT Epoch [1/10], Loss: 0.0832\nQAT Epoch [2/10], Loss: 0.0556\nQAT Epoch [3/10], Loss: 0.0432\nQAT Epoch [4/10], Loss: 0.0335\nQAT Epoch [5/10], Loss: 0.0298\nQAT Epoch [6/10], Loss: 0.0298\nQAT Epoch [7/10], Loss: 0.0212\nQAT Epoch [8/10], Loss: 0.0265\nQAT Epoch [9/10], Loss: 0.0227\nQAT Epoch [10/10], Loss: 0.0191\nConverting to quantized model...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/630500888.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantized_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/630500888.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# Patch embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/630500888.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/ao/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_reversed_padding_repeated_twice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             )\n\u001b[0;32m--> 594\u001b[0;31m         return ops.quantized.conv2d(\n\u001b[0m\u001b[1;32m    595\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_packed_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_torchbind_op_overload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_overload_packet_from_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: getCudnnDataTypeFromScalarType() not supported for QUInt8"],"ename":"RuntimeError","evalue":"getCudnnDataTypeFromScalarType() not supported for QUInt8","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"# quant_export.py\nimport os, json, math\nimport torch, numpy as np\nfrom torchvision import transforms, datasets\nfrom PIL import Image\n\n# ---- CONFIG ----\nMODEL_CHECKPOINT = \"best_model.pth\"  \nOUT_DIR = \"export_mem\"\nNUM_BITS = 8  # target bits for weights (int8)\nACT_BITS = 8  # activations int8\nCALIBRATION_SAMPLES = 128  # for activation calibration if doing PTQ\nDEVICE = torch.device(\"cpu\")  # we'll run quantized model on CPU\n# -----------------\n\nos.makedirs(OUT_DIR, exist_ok=True)\n\ndef write_hex_mem(filename, arr, signed=True, width_bytes=1):\n    \"\"\"\n    arr: 1D numpy array of ints (signed expected if signed=True).\n    width_bytes: 1 for int8, 4 for int32 bias, etc.\n    Writes hex per-line (little-endian not necessary for readmemh).\n    \"\"\"\n    with open(filename, \"w\") as f:\n        for v in arr.flatten():\n            if signed:\n                # produce two's complement unsigned representation\n                bits = width_bytes * 8\n                u = int(v) & ((1 << bits) - 1)\n            else:\n                u = int(v)\n            f.write(f\"{u:0{width_bytes*2}x}\\n\")\n\ndef quantize_np_symmetric(tensor_np, num_bits=8):\n    \"\"\"Symmetric per-tensor quantization: returns int np array and scale\"\"\"\n    max_abs = float(np.max(np.abs(tensor_np))) if tensor_np.size else 0.0\n    if max_abs == 0:\n        scale = 1.0\n    else:\n        qmax = 2**(num_bits-1) - 1\n        scale = max_abs / qmax\n    q = np.round(tensor_np / scale).astype(np.int32)\n    qmin = -2**(num_bits-1)\n    qmax = 2**(num_bits-1)-1\n    q = np.clip(q, qmin, qmax).astype(np.int8 if num_bits==8 else np.int16)\n    return q, float(scale)\n\n# --- helper: load checkpoint state_dict or quantized state ---\nckpt = torch.load(MODEL_CHECKPOINT, map_location='cpu')\n# ckpt may be dict with 'model_state_dict' or just state_dict\nif isinstance(ckpt, dict) and 'model_state_dict' in ckpt:\n    state_dict = ckpt['model_state_dict']\nelse:\n    state_dict = ckpt\n\n# Try to detect if this is a quantized model object (we'll later try both ways)\n# We'll implement two flows: (A) if you have model object quantized_model (recommended),\n# (B) if you only have state_dict (float), we quantize offline per-tensor.\n\nprint(\"Export folder:\", OUT_DIR)\n\n# ---------- FLOW A: If you already have a quantized model object ----------\n# If you have `quantized_model` in memory (after convert()), use this block:\ndef export_from_quantized_model(model_quantized, out_dir=OUT_DIR):\n    \"\"\"\n    Extracts packed quantized weights from a quantized PyTorch model (modules like\n    nnq.Linear / nnq.Conv2d) and writes .mem + metadata.\n    \"\"\"\n    meta = {}\n    model_quantized.to(DEVICE)\n    model_quantized.eval()\n    for name, module in model_quantized.named_modules():\n        # Many quantized modules expose .weight() which is a Quantized Tensor\n        try:\n            # handle quantized layers like torch.ao.nn.quantized.Linear/Conv2d\n            if hasattr(module, 'weight') and callable(module.weight):\n                qweight = module.weight()  # quantized tensor\n                # int repr and scale/zero_point\n                w_int = qweight.int_repr().cpu().numpy().astype(np.int8)\n                scale = float(qweight.q_scale())\n                zp = int(qweight.q_zero_point())\n                fname = f\"{name.replace('.', '_')}_weight.mem\"\n                write_hex_mem(os.path.join(out_dir, fname), w_int, signed=True, width_bytes=1)\n                meta[name + \".weight\"] = {\"file\": fname, \"shape\": list(w_int.shape), \"scale\": scale, \"zero_point\": zp, \"dtype\":\"int8\"}\n            # bias could be attribute\n            if hasattr(module, 'bias') and module.bias is not None:\n                b = module.bias\n                # bias in quantized modules might already be float or int32 depending on config\n                if isinstance(b, torch.Tensor):\n                    b_np = b.detach().cpu().numpy()\n                    fname = f\"{name.replace('.', '_')}_bias.mem\"\n                    # write as signed 32-bit hex\n                    write_hex_mem(os.path.join(out_dir, fname), b_np.astype(np.int32), signed=True, width_bytes=4)\n                    meta[name + \".bias\"] = {\"file\": fname, \"shape\": list(b_np.shape), \"dtype\":\"int32\"}\n        except Exception:\n            # fallback: some layers expose ._weight_bias or state_dict entries; skip silently\n            continue\n\n    # Save metadata\n    with open(os.path.join(out_dir, \"export_meta_quant.json\"), \"w\") as f:\n        json.dump(meta, f, indent=2)\n    print(\"Exported quantized model weights to\", out_dir)\n    return meta\n\n# ---------- FLOW B: If you only have float state_dict ----------\ndef export_from_state_dict(state_dict, out_dir=OUT_DIR, num_bits=NUM_BITS):\n    meta = {}\n    for key, tensor in state_dict.items():\n        arr = tensor.cpu().numpy().astype(np.float32)\n        # Quantize per-tensor symmetric int8\n        q_arr, scale = quantize_np_symmetric(arr, num_bits=num_bits)\n        fname = f\"{key.replace('.', '_')}.mem\"\n        write_hex_mem(os.path.join(out_dir, fname), q_arr, signed=True, width_bytes=1)\n        meta[key] = {\"file\": fname, \"shape\": list(arr.shape), \"scale\": scale, \"dtype\":\"int8\"}\n    # save meta\n    with open(os.path.join(out_dir, \"export_meta_ptq.json\"), \"w\") as f:\n        json.dump(meta, f, indent=2)\n    print(\"Exported PTQ quantized weights to\", out_dir)\n    return meta\n\n# ---------- Export an example input image (quantized) ----------\ndef export_input_image_mem(img_path=None, out_dir=OUT_DIR, act_bits=ACT_BITS, test_transform=None):\n    # If no image provided, use first image from CIFAR10 test set (deterministic)\n    if img_path is None:\n        # load CIFAR test (will download if needed)\n        ds = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=test_transform)\n        img_tensor, label = ds[0]  # first sample\n        img_np = img_tensor.numpy().astype(np.float32)\n    else:\n        img = Image.open(img_path).convert(\"RGB\")\n        if test_transform is None:\n            raise ValueError(\"Provide test_transform or img_path=None for CIFAR auto\")\n        img_tensor = test_transform(img)\n        img_np = img_tensor.numpy().astype(np.float32)\n\n    # quantize per-tensor\n    q_img, s = quantize_np_symmetric(img_np, num_bits=act_bits)\n    fname = \"input_image.mem\"\n    write_hex_mem(os.path.join(out_dir, fname), q_img, signed=True, width_bytes=1)\n    meta = {\"file\": fname, \"shape\": list(q_img.shape), \"scale\": s, \"dtype\":\"int8\"}\n    with open(os.path.join(out_dir, \"input_meta.json\"), \"w\") as f:\n        json.dump(meta, f, indent=2)\n    print(\"Exported input image to\", os.path.join(out_dir, fname))\n    return meta\n\n# ---------- Utility: test quantized model on CPU ----------\ndef test_quantized_model_on_cpu(model_quantized, test_loader):\n    model_quantized.to('cpu')\n    model_quantized.eval()\n    correct, total = 0, 0\n    for images, labels in test_loader:\n        images = images.to('cpu')\n        labels = labels.to('cpu')\n        with torch.no_grad():\n            outputs = model_quantized(images)\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n    acc = 100.0 * correct / total\n    print(f\"Quantized model accuracy on CPU: {acc:.2f}%\")\n    return acc\n\n# ---------------- Main decide-and-run ----------------\n# If user has quantized model object in memory (quantized_model), use that:\nif 'quantized_model' in globals():\n    print(\"Detected quantized_model in memory  exporting from quantized object.\")\n    meta = export_from_quantized_model(globals()['quantized_model'], OUT_DIR)\n    _ = export_input_image_mem(None, OUT_DIR, act_bits=ACT_BITS, test_transform=test_transform)\nelse:\n    # If only state_dict available, export PTQ per-tensor\n    print(\"No quantized_model in memory. Exporting from state_dict using PTQ per-tensor quantization.\")\n    meta = export_from_state_dict(state_dict, OUT_DIR, num_bits=NUM_BITS)\n    _ = export_input_image_mem(None, OUT_DIR, act_bits=ACT_BITS, test_transform=test_transform)\n\nprint(\"Done. Files in:\", OUT_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T21:00:03.400889Z","iopub.execute_input":"2025-09-23T21:00:03.401650Z","iopub.status.idle":"2025-09-23T21:00:13.047614Z","shell.execute_reply.started":"2025-09-23T21:00:03.401622Z","shell.execute_reply":"2025-09-23T21:00:13.046640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport math\nimport os\nimport json\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nimport time\n\n# Configuration\nclass Config:\n    # Hardware settings - Use GPU if available for training speed\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Model architecture (optimized for hardware but realistic)\n    img_size = 64  # Better resolution for accuracy\n    patch_size = 8\n    embed_dim = 256  # Reasonable size for good performance\n    depth = 6      # Good depth for accuracy\n    num_heads = 8\n    mlp_ratio = 3.0\n    \n    # Training settings - optimized for full dataset\n    batch_size = 128\n    num_epochs = 50  # Reduced since we're using PyTorch optimization\n    learning_rate = 0.001\n    weight_decay = 0.05\n    \n    # Quantization settings\n    weight_bits = 8\n    activation_bits = 8\n    \n    # Export settings\n    export_dir = \"rtl_export\"\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\n# ============================================================================\n# CUSTOM MATHEMATICAL OPERATIONS FOR RTL EXPORT ONLY\n# ============================================================================\n\ndef custom_relu(x):\n    \"\"\"Custom ReLU activation - for RTL export only\"\"\"\n    return np.maximum(0, x)\n\ndef custom_gelu(x):\n    \"\"\"Custom GELU activation - for RTL export only\"\"\"\n    return 0.5 * x * (1 + np.tanh(np.sqrt(2/np.pi) * (x + 0.044715 * x**3)))\n\ndef custom_softmax(x, axis=-1):\n    \"\"\"Custom softmax with numerical stability - for RTL export only\"\"\"\n    x_shifted = x - np.max(x, axis=axis, keepdims=True)\n    exp_x = np.exp(x_shifted)\n    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n\ndef custom_layer_norm(x, weight, bias, eps=1e-5):\n    \"\"\"Custom Layer Normalization - for RTL export only\"\"\"\n    mean = np.mean(x, axis=-1, keepdims=True)\n    var = np.var(x, axis=-1, keepdims=True)\n    x_norm = (x - mean) / np.sqrt(var + eps)\n    return x_norm * weight + bias\n\ndef custom_conv2d(input_data, weight, bias=None, stride=1, padding=0):\n    \"\"\"Custom 2D convolution - for RTL export only\"\"\"\n    batch, in_ch, in_h, in_w = input_data.shape\n    out_ch, _, k_h, k_w = weight.shape\n    \n    # Add padding\n    if padding > 0:\n        input_padded = np.pad(input_data, ((0,0), (0,0), (padding,padding), (padding,padding)), 'constant')\n    else:\n        input_padded = input_data\n    \n    out_h = (in_h + 2*padding - k_h) // stride + 1\n    out_w = (in_w + 2*padding - k_w) // stride + 1\n    output = np.zeros((batch, out_ch, out_h, out_w))\n    \n    for b in range(batch):\n        for oc in range(out_ch):\n            for oh in range(out_h):\n                for ow in range(out_w):\n                    h_start = oh * stride\n                    w_start = ow * stride\n                    patch = input_padded[b, :, h_start:h_start+k_h, w_start:w_start+k_w]\n                    output[b, oc, oh, ow] = np.sum(patch * weight[oc])\n                    if bias is not None:\n                        output[b, oc, oh, ow] += bias[oc]\n    \n    return output\n\ndef custom_linear(input_data, weight, bias=None):\n    \"\"\"Custom linear layer - for RTL export only\"\"\"\n    output = np.dot(input_data, weight.T)\n    if bias is not None:\n        output += bias\n    return output\n\ndef custom_dropout(x, p=0.1, training=True):\n    \"\"\"Custom dropout - for RTL export only\"\"\"\n    if not training or p == 0:\n        return x\n    mask = np.random.binomial(1, 1-p, x.shape) / (1-p)\n    return x * mask\n\n# ============================================================================\n# PYTORCH VISION TRANSFORMER FOR TRAINING\n# ============================================================================\n\nclass PatchEmbedding(nn.Module):\n    def __init__(self, img_size, patch_size, in_channels, embed_dim):\n        super().__init__()\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.num_patches = (img_size // patch_size) ** 2\n        \n        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n        \n    def forward(self, x):\n        x = self.proj(x)  # (B, E, H/P, W/P)\n        x = x.flatten(2)  # (B, E, N)\n        x = x.transpose(1, 2)  # (B, N, E)\n        return x\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n        self.proj = nn.Linear(embed_dim, embed_dim)\n        self.attn_dropout = nn.Dropout(0.1)\n        self.proj_dropout = nn.Dropout(0.1)\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = attn.softmax(dim=-1)\n        attn = self.attn_dropout(attn)\n        \n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_dropout(x)\n        return x\n\nclass MLP(nn.Module):\n    def __init__(self, in_features, hidden_features):\n        super().__init__()\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = nn.GELU()\n        self.fc2 = nn.Linear(hidden_features, in_features)\n        self.dropout = nn.Dropout(0.1)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.dropout(x)\n        return x\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4.0):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(dim)\n        self.attn = MultiHeadAttention(dim, num_heads)\n        self.norm2 = nn.LayerNorm(dim)\n        self.mlp = MLP(dim, int(dim * mlp_ratio))\n        \n    def forward(self, x):\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nclass ViT(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=3.0):\n        super().__init__()\n        \n        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        num_patches = (img_size // patch_size) ** 2\n        \n        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n        self.pos_dropout = nn.Dropout(0.1)\n        \n        self.blocks = nn.ModuleList([\n            TransformerBlock(embed_dim, num_heads, mlp_ratio) for _ in range(depth)\n        ])\n        \n        self.norm = nn.LayerNorm(embed_dim)\n        self.head = nn.Linear(embed_dim, num_classes)\n        \n        # Initialize weights\n        self.apply(self._init_weights)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.LayerNorm):\n            torch.nn.init.zeros_(module.bias)\n            torch.nn.init.ones_(module.weight)\n        elif isinstance(module, nn.Conv2d):\n            torch.nn.init.normal_(module.weight, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n                \n    def forward(self, x):\n        x = self.patch_embed(x)\n        x = x + self.pos_embed\n        x = self.pos_dropout(x)\n        \n        for block in self.blocks:\n            x = block(x)\n            \n        x = self.norm(x)\n        x = x.mean(dim=1)  # Global average pooling\n        x = self.head(x)\n        return x\n\n# ============================================================================\n# DATA LOADING AND PREPROCESSING\n# ============================================================================\n\ndef load_cifar10_data():\n    \"\"\"Load CIFAR-10 data with GPU support\"\"\"\n    train_transform = transforms.Compose([\n        transforms.Resize((config.img_size, config.img_size)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomCrop(config.img_size, padding=4, padding_mode='reflect'),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n    ])\n    \n    test_transform = transforms.Compose([\n        transforms.Resize((config.img_size, config.img_size)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n    ])\n    \n    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n    \n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2\n    )\n    \n    test_loader = torch.utils.data.DataLoader(\n        test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2\n    )\n    \n    return train_loader, test_loader\n\n# ============================================================================\n# TRAINING WITH PYTORCH\n# ============================================================================\n\ndef train_pytorch_model(model, train_loader, test_loader, config):\n    \"\"\"Train the PyTorch ViT model\"\"\"\n    model.to(config.device)\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.num_epochs)\n    \n    train_losses = []\n    train_accs = []\n    test_accs = []\n    best_acc = 0.0\n    \n    print(\"Starting PyTorch training...\")\n    for epoch in range(config.num_epochs):\n        epoch_start = time.time()\n        \n        # Training phase\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n        total_samples = 0\n        \n        for batch_idx, (inputs, targets) in enumerate(train_loader):\n            inputs, targets = inputs.to(config.device), targets.to(config.device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = outputs.max(1)\n            running_corrects += predicted.eq(targets).sum().item()\n            total_samples += inputs.size(0)\n            \n            if batch_idx % 100 == 0:\n                print(f'  Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n        \n        epoch_loss = running_loss / total_samples\n        epoch_acc = 100. * running_corrects / total_samples\n        \n        # Test phase\n        test_acc = evaluate_model(model, test_loader, config)\n        \n        train_losses.append(epoch_loss)\n        train_accs.append(epoch_acc)\n        test_accs.append(test_acc)\n        \n        scheduler.step()\n        \n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save(model.state_dict(), 'best_vit_model.pth')\n        \n        epoch_time = time.time() - epoch_start\n        print(f'Epoch [{epoch+1}/{config.num_epochs}] ({epoch_time:.1f}s), '\n              f'Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, Test Acc: {test_acc:.2f}%, Best: {best_acc:.2f}%')\n    \n    # Load best model\n    model.load_state_dict(torch.load('best_vit_model.pth'))\n    print(f'Training completed! Best Test Accuracy: {best_acc:.2f}%')\n    \n    return train_losses, train_accs, test_accs, best_acc\n\ndef evaluate_model(model, test_loader, config):\n    \"\"\"Evaluate model on test set\"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs, targets = inputs.to(config.device), targets.to(config.device)\n            outputs = model(inputs)\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n    \n    accuracy = 100. * correct / total\n    return accuracy\n\n# ============================================================================\n# QUANTIZATION AND RTL EXPORT FUNCTIONS\n# ============================================================================\n\ndef symmetric_quantize(x, bits=8, scale=None):\n    \"\"\"Symmetric quantization for RTL export\"\"\"\n    if scale is None:\n        max_val = np.max(np.abs(x))\n        if max_val == 0:\n            scale = 1.0\n        else:\n            scale = max_val / (2**(bits-1) - 1)\n    \n    x_q = np.round(x / scale)\n    x_q = np.clip(x_q, -(2**(bits-1)), 2**(bits-1) - 1)\n    return x_q.astype(np.int8), scale\n\ndef dequantize(x_q, scale):\n    \"\"\"Dequantize values\"\"\"\n    return x_q.astype(np.float32) * scale\n\ndef convert_pytorch_to_custom_format(pytorch_model, config):\n    \"\"\"Convert PyTorch model to custom format for RTL export\"\"\"\n    \n    class CustomViTForExport:\n        def __init__(self):\n            # Extract parameters from PyTorch model\n            self.params = {}\n            \n            # Patch embedding\n            self.params['patch_embed.weight'] = pytorch_model.patch_embed.proj.weight.detach().cpu().numpy()\n            self.params['patch_embed.bias'] = pytorch_model.patch_embed.proj.bias.detach().cpu().numpy()\n            \n            # Positional embedding\n            self.params['pos_embed'] = pytorch_model.pos_embed.detach().cpu().numpy()[0]  # Remove batch dimension\n            \n            # Transformer blocks\n            for i, block in enumerate(pytorch_model.blocks):\n                # Layer norm 1\n                self.params[f'blocks.{i}.norm1.weight'] = block.norm1.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.norm1.bias'] = block.norm1.bias.detach().cpu().numpy()\n                \n                # Attention\n                self.params[f'blocks.{i}.attn.qkv.weight'] = block.attn.qkv.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.attn.qkv.bias'] = block.attn.qkv.bias.detach().cpu().numpy()\n                self.params[f'blocks.{i}.attn.proj.weight'] = block.attn.proj.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.attn.proj.bias'] = block.attn.proj.bias.detach().cpu().numpy()\n                \n                # Layer norm 2\n                self.params[f'blocks.{i}.norm2.weight'] = block.norm2.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.norm2.bias'] = block.norm2.bias.detach().cpu().numpy()\n                \n                # MLP\n                self.params[f'blocks.{i}.mlp.fc1.weight'] = block.mlp.fc1.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.mlp.fc1.bias'] = block.mlp.fc1.bias.detach().cpu().numpy()\n                self.params[f'blocks.{i}.mlp.fc2.weight'] = block.mlp.fc2.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.mlp.fc2.bias'] = block.mlp.fc2.bias.detach().cpu().numpy()\n            \n            # Final layers\n            self.params['norm.weight'] = pytorch_model.norm.weight.detach().cpu().numpy()\n            self.params['norm.bias'] = pytorch_model.norm.bias.detach().cpu().numpy()\n            self.params['head.weight'] = pytorch_model.head.weight.detach().cpu().numpy()\n            self.params['head.bias'] = pytorch_model.head.bias.detach().cpu().numpy()\n            \n            print(f\"Converted model with {sum(p.size for p in self.params.values()):,} parameters\")\n        \n        def quantize_model(self, bits=8):\n            \"\"\"Quantize all model parameters\"\"\"\n            quantized_params = {}\n            scales = {}\n            \n            print(f\"Quantizing {len(self.params)} parameter tensors to {bits} bits...\")\n            for name, param in self.params.items():\n                q_param, scale = symmetric_quantize(param, bits)\n                quantized_params[name] = q_param\n                scales[name] = scale\n                \n            return quantized_params, scales\n    \n    return CustomViTForExport()\n\n# ============================================================================\n# EXPORT FUNCTIONS FOR RTL\n# ============================================================================\n\ndef export_for_rtl(custom_model, test_loader, config):\n    \"\"\"Export quantized model and test data for RTL implementation\"\"\"\n    os.makedirs(config.export_dir, exist_ok=True)\n    \n    print(\"Quantizing model...\")\n    quantized_params, scales = custom_model.quantize_model(config.weight_bits)\n    \n    # Export quantized weights\n    print(\"Exporting weights...\")\n    for name, q_param in quantized_params.items():\n        filename = os.path.join(config.export_dir, f\"{name.replace('.', '_')}.mem\")\n        with open(filename, 'w') as f:\n            for val in q_param.flatten():\n                f.write(f\"{val & 0xFF:02x}\\n\")  # Convert to unsigned hex\n    \n    # Export scales\n    with open(os.path.join(config.export_dir, \"scales.json\"), 'w') as f:\n        scales_serializable = {}\n        for key, value in scales.items():\n            if isinstance(value, np.ndarray):\n                scales_serializable[key] = value.tolist()\n            else:\n                scales_serializable[key] = float(value)\n        json.dump(scales_serializable, f, indent=2)\n    \n    # Export test images and labels\n    print(\"Exporting test data...\")\n    test_dataset = test_loader.dataset\n    num_test_samples = min(100, len(test_dataset))\n    \n    for i in range(num_test_samples):\n        img, label = test_dataset[i]\n        img_np = img.numpy()\n        q_img, img_scale = symmetric_quantize(img_np, config.activation_bits)\n        \n        filename = os.path.join(config.export_dir, f\"test_img_{i:03d}.mem\")\n        with open(filename, 'w') as f:\n            for val in q_img.flatten():\n                f.write(f\"{val & 0xFF:02x}\\n\")\n    \n    # Export labels\n    test_labels = [test_dataset[i][1] for i in range(num_test_samples)]\n    with open(os.path.join(config.export_dir, \"test_labels.json\"), 'w') as f:\n        json.dump(test_labels, f)\n    \n    # Export model architecture info\n    arch_info = {\n        \"img_size\": config.img_size,\n        \"patch_size\": config.patch_size,\n        \"embed_dim\": config.embed_dim,\n        \"depth\": config.depth,\n        \"num_heads\": config.num_heads,\n        \"num_classes\": 10,\n        \"weight_bits\": config.weight_bits,\n        \"activation_bits\": config.activation_bits,\n        \"mlp_ratio\": config.mlp_ratio\n    }\n    \n    with open(os.path.join(config.export_dir, \"architecture.json\"), 'w') as f:\n        json.dump(arch_info, f, indent=2)\n    \n    print(f\"Export complete! Files saved to: {config.export_dir}\")\n\ndef generate_verilog_testbench(config):\n    \"\"\"Generate Verilog testbench template\"\"\"\n    tb_dir = os.path.join(config.export_dir, \"testbench\")\n    os.makedirs(tb_dir, exist_ok=True)\n    \n    verilog_tb = f'''\n// Verilog Testbench Template for Custom ViT\n// Generated automatically for RTL implementation\n\n`timescale 1ns / 1ps\n\nmodule vit_testbench();\n    \n    // Parameters from model architecture\n    localparam IMG_SIZE = {config.img_size};\n    localparam PATCH_SIZE = {config.patch_size};\n    localparam EMBED_DIM = {config.embed_dim};\n    localparam DEPTH = {config.depth};\n    localparam NUM_HEADS = {config.num_heads};\n    localparam NUM_CLASSES = 10;\n    localparam WEIGHT_BITS = {config.weight_bits};\n    localparam ACT_BITS = {config.activation_bits};\n    \n    // Derived parameters\n    localparam NUM_PATCHES = (IMG_SIZE / PATCH_SIZE) * (IMG_SIZE / PATCH_SIZE);\n    localparam IMG_PIXELS = IMG_SIZE * IMG_SIZE * 3; // RGB channels\n    \n    // Clock and reset\n    reg clk;\n    reg rst_n;\n    \n    // Input data\n    reg [ACT_BITS-1:0] input_image [0:IMG_PIXELS-1];\n    reg start;\n    \n    // Output data\n    wire [ACT_BITS-1:0] output_logits [0:NUM_CLASSES-1];\n    wire [3:0] predicted_class;\n    wire done;\n    \n    // DUT instantiation\n    vit_top #(\n        .IMG_SIZE(IMG_SIZE),\n        .PATCH_SIZE(PATCH_SIZE),\n        .EMBED_DIM(EMBED_DIM),\n        .DEPTH(DEPTH),\n        .NUM_HEADS(NUM_HEADS),\n        .NUM_CLASSES(NUM_CLASSES),\n        .WEIGHT_BITS(WEIGHT_BITS),\n        .ACT_BITS(ACT_BITS)\n    ) dut (\n        .clk(clk),\n        .rst_n(rst_n),\n        .input_image(input_image),\n        .start(start),\n        .output_logits(output_logits),\n        .predicted_class(predicted_class),\n        .done(done)\n    );\n    \n    // Clock generation\n    always #5 clk = ~clk;\n    \n    // Test sequence\n    initial begin\n        // Initialize\n        clk = 0;\n        rst_n = 0;\n        start = 0;\n        \n        // Load input image from memory file\n        $readmemh(\"test_img_000.mem\", input_image);\n        \n        // Reset sequence\n        #100;\n        rst_n = 1;\n        #50;\n        \n        // Start processing\n        start = 1;\n        #10;\n        start = 0;\n        \n        // Wait for completion\n        wait(done);\n        \n        // Check results\n        $display(\"Processing complete!\");\n        $display(\"Predicted class: %d\", predicted_class);\n        \n        // Display output logits\n        for (int i = 0; i < NUM_CLASSES; i++) begin\n            $display(\"Logit[%d] = %h\", i, output_logits[i]);\n        end\n        \n        #100;\n        $finish;\n    end\n    \nendmodule\n'''\n    \n    with open(os.path.join(tb_dir, \"vit_testbench.sv\"), 'w') as f:\n        f.write(verilog_tb)\n    \n    print(f\"Testbench generated in: {tb_dir}\")\n\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\n\ndef main():\n    print(\"=\"*60)\n    print(\"HYBRID ViT IMPLEMENTATION - PyTorch Training + RTL Export\")\n    print(\"=\"*60)\n    \n    # Load data\n    train_loader, test_loader = load_cifar10_data()\n    \n    # Create and train PyTorch model\n    model = ViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        mlp_ratio=config.mlp_ratio,\n        num_classes=10\n    )\n    \n    # Count parameters\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Total parameters: {total_params:,}\")\n    \n    # Train model with PyTorch\n    train_losses, train_accs, test_accs, best_acc = train_pytorch_model(\n        model, train_loader, test_loader, config\n    )\n    \n    # Plot results\n    plt.figure(figsize=(15, 5))\n    \n    plt.subplot(1, 3, 1)\n    plt.plot(train_losses)\n    plt.title('Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.grid(True)\n    \n    plt.subplot(1, 3, 2)\n    plt.plot(train_accs, label='Train')\n    plt.plot(test_accs, label='Test')\n    plt.title('Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.subplot(1, 3, 3)\n    plt.plot(test_accs)\n    plt.title('Test Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig('training_results.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    # Convert to custom format and export for RTL\n    print(\"Converting model for RTL export...\")\n    custom_model = convert_pytorch_to_custom_format(model, config)\n    \n    # Export for RTL implementation\n    export_for_rtl(custom_model, test_loader, config)\n    \n    # Generate RTL testbench\n    generate_verilog_testbench(config)\n    \n    print(f\"\\nTraining and export completed!\")\n    print(f\"Best accuracy: {best_acc:.2f}%\")\n    print(f\"All files exported to: {config.export_dir}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T15:05:29.062619Z","iopub.execute_input":"2025-09-28T15:05:29.063456Z","iopub.status.idle":"2025-09-28T15:46:13.685777Z","shell.execute_reply.started":"2025-09-28T15:05:29.063430Z","shell.execute_reply":"2025-09-28T15:46:13.684965Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n============================================================\nHYBRID ViT IMPLEMENTATION - PyTorch Training + RTL Export\n============================================================\nTotal parameters: 4,019,466\nStarting PyTorch training...\n  Batch [0/391], Loss: 2.3089\n  Batch [100/391], Loss: 2.0584\n  Batch [200/391], Loss: 1.9468\n  Batch [300/391], Loss: 1.7709\nEpoch [1/50] (51.3s), Loss: 1.8790, Train Acc: 29.27%, Test Acc: 35.83%, Best: 35.83%\n  Batch [0/391], Loss: 1.7620\n  Batch [100/391], Loss: 1.6701\n  Batch [200/391], Loss: 1.7343\n  Batch [300/391], Loss: 1.6130\nEpoch [2/50] (47.8s), Loss: 1.6675, Train Acc: 38.51%, Test Acc: 41.09%, Best: 41.09%\n  Batch [0/391], Loss: 1.6969\n  Batch [100/391], Loss: 1.6913\n  Batch [200/391], Loss: 1.4923\n  Batch [300/391], Loss: 1.4906\nEpoch [3/50] (49.0s), Loss: 1.5700, Train Acc: 42.64%, Test Acc: 44.89%, Best: 44.89%\n  Batch [0/391], Loss: 1.4658\n  Batch [100/391], Loss: 1.5881\n  Batch [200/391], Loss: 1.7653\n  Batch [300/391], Loss: 1.4999\nEpoch [4/50] (48.5s), Loss: 1.5002, Train Acc: 45.04%, Test Acc: 48.02%, Best: 48.02%\n  Batch [0/391], Loss: 1.3542\n  Batch [100/391], Loss: 1.5292\n  Batch [200/391], Loss: 1.4599\n  Batch [300/391], Loss: 1.4613\nEpoch [5/50] (48.9s), Loss: 1.4465, Train Acc: 47.64%, Test Acc: 50.94%, Best: 50.94%\n  Batch [0/391], Loss: 1.2650\n  Batch [100/391], Loss: 1.2846\n  Batch [200/391], Loss: 1.4643\n  Batch [300/391], Loss: 1.3967\nEpoch [6/50] (48.8s), Loss: 1.3755, Train Acc: 50.09%, Test Acc: 50.96%, Best: 50.96%\n  Batch [0/391], Loss: 1.2685\n  Batch [100/391], Loss: 1.4505\n  Batch [200/391], Loss: 1.1783\n  Batch [300/391], Loss: 1.2431\nEpoch [7/50] (48.7s), Loss: 1.3288, Train Acc: 51.70%, Test Acc: 53.86%, Best: 53.86%\n  Batch [0/391], Loss: 1.1762\n  Batch [100/391], Loss: 1.2585\n  Batch [200/391], Loss: 1.1613\n  Batch [300/391], Loss: 1.3354\nEpoch [8/50] (48.6s), Loss: 1.2723, Train Acc: 54.04%, Test Acc: 54.93%, Best: 54.93%\n  Batch [0/391], Loss: 1.2022\n  Batch [100/391], Loss: 1.0656\n  Batch [200/391], Loss: 1.1722\n  Batch [300/391], Loss: 1.2549\nEpoch [9/50] (48.6s), Loss: 1.2249, Train Acc: 55.96%, Test Acc: 57.90%, Best: 57.90%\n  Batch [0/391], Loss: 1.1970\n  Batch [100/391], Loss: 1.2425\n  Batch [200/391], Loss: 1.1141\n  Batch [300/391], Loss: 1.1638\nEpoch [10/50] (48.6s), Loss: 1.1774, Train Acc: 57.92%, Test Acc: 58.99%, Best: 58.99%\n  Batch [0/391], Loss: 1.0940\n  Batch [100/391], Loss: 1.0964\n  Batch [200/391], Loss: 1.2183\n  Batch [300/391], Loss: 1.1564\nEpoch [11/50] (48.6s), Loss: 1.1388, Train Acc: 59.24%, Test Acc: 59.22%, Best: 59.22%\n  Batch [0/391], Loss: 1.1842\n  Batch [100/391], Loss: 1.1753\n  Batch [200/391], Loss: 0.9552\n  Batch [300/391], Loss: 1.1088\nEpoch [12/50] (48.7s), Loss: 1.1013, Train Acc: 60.49%, Test Acc: 61.58%, Best: 61.58%\n  Batch [0/391], Loss: 1.1701\n  Batch [100/391], Loss: 0.9642\n  Batch [200/391], Loss: 1.0516\n  Batch [300/391], Loss: 1.2148\nEpoch [13/50] (48.8s), Loss: 1.0699, Train Acc: 61.74%, Test Acc: 62.54%, Best: 62.54%\n  Batch [0/391], Loss: 1.0141\n  Batch [100/391], Loss: 0.9595\n  Batch [200/391], Loss: 1.0557\n  Batch [300/391], Loss: 1.2020\nEpoch [14/50] (48.9s), Loss: 1.0351, Train Acc: 63.08%, Test Acc: 63.64%, Best: 63.64%\n  Batch [0/391], Loss: 0.9729\n  Batch [100/391], Loss: 1.1191\n  Batch [200/391], Loss: 1.0389\n  Batch [300/391], Loss: 1.0486\nEpoch [15/50] (48.3s), Loss: 1.0024, Train Acc: 64.36%, Test Acc: 65.26%, Best: 65.26%\n  Batch [0/391], Loss: 1.0592\n  Batch [100/391], Loss: 0.9791\n  Batch [200/391], Loss: 1.0860\n  Batch [300/391], Loss: 0.9815\nEpoch [16/50] (48.4s), Loss: 0.9811, Train Acc: 65.12%, Test Acc: 65.61%, Best: 65.61%\n  Batch [0/391], Loss: 0.8926\n  Batch [100/391], Loss: 1.0359\n  Batch [200/391], Loss: 0.8887\n  Batch [300/391], Loss: 0.8712\nEpoch [17/50] (48.7s), Loss: 0.9423, Train Acc: 66.35%, Test Acc: 67.04%, Best: 67.04%\n  Batch [0/391], Loss: 0.8545\n  Batch [100/391], Loss: 0.9118\n  Batch [200/391], Loss: 0.8930\n  Batch [300/391], Loss: 0.9529\nEpoch [18/50] (48.9s), Loss: 0.9183, Train Acc: 67.38%, Test Acc: 67.49%, Best: 67.49%\n  Batch [0/391], Loss: 0.8287\n  Batch [100/391], Loss: 0.9251\n  Batch [200/391], Loss: 0.9528\n  Batch [300/391], Loss: 0.9542\nEpoch [19/50] (48.5s), Loss: 0.8992, Train Acc: 67.91%, Test Acc: 68.52%, Best: 68.52%\n  Batch [0/391], Loss: 0.9212\n  Batch [100/391], Loss: 0.8927\n  Batch [200/391], Loss: 0.7102\n  Batch [300/391], Loss: 0.9101\nEpoch [20/50] (48.5s), Loss: 0.8739, Train Acc: 68.92%, Test Acc: 68.71%, Best: 68.71%\n  Batch [0/391], Loss: 0.8517\n  Batch [100/391], Loss: 1.1681\n  Batch [200/391], Loss: 0.8327\n  Batch [300/391], Loss: 0.6764\nEpoch [21/50] (48.5s), Loss: 0.8507, Train Acc: 69.98%, Test Acc: 69.57%, Best: 69.57%\n  Batch [0/391], Loss: 0.8129\n  Batch [100/391], Loss: 0.8282\n  Batch [200/391], Loss: 0.7995\n  Batch [300/391], Loss: 0.6725\nEpoch [22/50] (48.5s), Loss: 0.8261, Train Acc: 70.67%, Test Acc: 71.67%, Best: 71.67%\n  Batch [0/391], Loss: 0.8023\n  Batch [100/391], Loss: 0.6996\n  Batch [200/391], Loss: 0.8281\n  Batch [300/391], Loss: 0.6968\nEpoch [23/50] (48.6s), Loss: 0.8018, Train Acc: 71.40%, Test Acc: 71.42%, Best: 71.67%\n  Batch [0/391], Loss: 0.8469\n  Batch [100/391], Loss: 0.7310\n  Batch [200/391], Loss: 0.7520\n  Batch [300/391], Loss: 0.7455\nEpoch [24/50] (48.7s), Loss: 0.7688, Train Acc: 72.63%, Test Acc: 71.54%, Best: 71.67%\n  Batch [0/391], Loss: 0.8627\n  Batch [100/391], Loss: 0.6237\n  Batch [200/391], Loss: 0.9238\n  Batch [300/391], Loss: 0.8046\nEpoch [25/50] (48.8s), Loss: 0.7545, Train Acc: 73.22%, Test Acc: 72.60%, Best: 72.60%\n  Batch [0/391], Loss: 0.5469\n  Batch [100/391], Loss: 0.6402\n  Batch [200/391], Loss: 0.6507\n  Batch [300/391], Loss: 0.5701\nEpoch [26/50] (48.6s), Loss: 0.7308, Train Acc: 74.05%, Test Acc: 73.21%, Best: 73.21%\n  Batch [0/391], Loss: 0.6096\n  Batch [100/391], Loss: 0.6119\n  Batch [200/391], Loss: 0.6479\n  Batch [300/391], Loss: 0.8492\nEpoch [27/50] (48.6s), Loss: 0.7020, Train Acc: 75.25%, Test Acc: 73.06%, Best: 73.21%\n  Batch [0/391], Loss: 0.7517\n  Batch [100/391], Loss: 0.5800\n  Batch [200/391], Loss: 0.7236\n  Batch [300/391], Loss: 0.6008\nEpoch [28/50] (48.6s), Loss: 0.6832, Train Acc: 75.49%, Test Acc: 74.44%, Best: 74.44%\n  Batch [0/391], Loss: 0.6519\n  Batch [100/391], Loss: 0.7629\n  Batch [200/391], Loss: 0.6868\n  Batch [300/391], Loss: 0.7541\nEpoch [29/50] (48.7s), Loss: 0.6619, Train Acc: 76.51%, Test Acc: 74.39%, Best: 74.44%\n  Batch [0/391], Loss: 0.5228\n  Batch [100/391], Loss: 0.6786\n  Batch [200/391], Loss: 0.6715\n  Batch [300/391], Loss: 0.7178\nEpoch [30/50] (48.9s), Loss: 0.6415, Train Acc: 77.10%, Test Acc: 75.61%, Best: 75.61%\n  Batch [0/391], Loss: 0.5886\n  Batch [100/391], Loss: 0.7167\n  Batch [200/391], Loss: 0.7589\n  Batch [300/391], Loss: 0.6622\nEpoch [31/50] (48.6s), Loss: 0.6150, Train Acc: 78.22%, Test Acc: 76.27%, Best: 76.27%\n  Batch [0/391], Loss: 0.6446\n  Batch [100/391], Loss: 0.6085\n  Batch [200/391], Loss: 0.6787\n  Batch [300/391], Loss: 0.6593\nEpoch [32/50] (48.5s), Loss: 0.5972, Train Acc: 78.68%, Test Acc: 76.05%, Best: 76.27%\n  Batch [0/391], Loss: 0.6733\n  Batch [100/391], Loss: 0.5451\n  Batch [200/391], Loss: 0.4431\n  Batch [300/391], Loss: 0.5236\nEpoch [33/50] (48.6s), Loss: 0.5775, Train Acc: 79.61%, Test Acc: 76.79%, Best: 76.79%\n  Batch [0/391], Loss: 0.5285\n  Batch [100/391], Loss: 0.5527\n  Batch [200/391], Loss: 0.4951\n  Batch [300/391], Loss: 0.5965\nEpoch [34/50] (48.5s), Loss: 0.5594, Train Acc: 80.12%, Test Acc: 76.74%, Best: 76.79%\n  Batch [0/391], Loss: 0.7054\n  Batch [100/391], Loss: 0.7321\n  Batch [200/391], Loss: 0.5488\n  Batch [300/391], Loss: 0.6282\nEpoch [35/50] (48.7s), Loss: 0.5400, Train Acc: 80.80%, Test Acc: 77.16%, Best: 77.16%\n  Batch [0/391], Loss: 0.5800\n  Batch [100/391], Loss: 0.5411\n  Batch [200/391], Loss: 0.4947\n  Batch [300/391], Loss: 0.5079\nEpoch [36/50] (48.8s), Loss: 0.5271, Train Acc: 81.21%, Test Acc: 77.78%, Best: 77.78%\n  Batch [0/391], Loss: 0.5518\n  Batch [100/391], Loss: 0.4914\n  Batch [200/391], Loss: 0.6039\n  Batch [300/391], Loss: 0.4666\nEpoch [37/50] (48.4s), Loss: 0.5053, Train Acc: 81.98%, Test Acc: 77.47%, Best: 77.78%\n  Batch [0/391], Loss: 0.4701\n  Batch [100/391], Loss: 0.4694\n  Batch [200/391], Loss: 0.5188\n  Batch [300/391], Loss: 0.4343\nEpoch [38/50] (48.3s), Loss: 0.4896, Train Acc: 82.56%, Test Acc: 78.80%, Best: 78.80%\n  Batch [0/391], Loss: 0.4245\n  Batch [100/391], Loss: 0.5363\n  Batch [200/391], Loss: 0.4644\n  Batch [300/391], Loss: 0.5266\nEpoch [39/50] (48.2s), Loss: 0.4684, Train Acc: 83.44%, Test Acc: 78.23%, Best: 78.80%\n  Batch [0/391], Loss: 0.3517\n  Batch [100/391], Loss: 0.4472\n  Batch [200/391], Loss: 0.5251\n  Batch [300/391], Loss: 0.6364\nEpoch [40/50] (48.2s), Loss: 0.4580, Train Acc: 83.58%, Test Acc: 78.43%, Best: 78.80%\n  Batch [0/391], Loss: 0.4529\n  Batch [100/391], Loss: 0.5465\n  Batch [200/391], Loss: 0.4449\n  Batch [300/391], Loss: 0.5388\nEpoch [41/50] (48.3s), Loss: 0.4494, Train Acc: 84.01%, Test Acc: 78.90%, Best: 78.90%\n  Batch [0/391], Loss: 0.4417\n  Batch [100/391], Loss: 0.5078\n  Batch [200/391], Loss: 0.4116\n  Batch [300/391], Loss: 0.4845\nEpoch [42/50] (48.3s), Loss: 0.4308, Train Acc: 84.73%, Test Acc: 78.78%, Best: 78.90%\n  Batch [0/391], Loss: 0.3777\n  Batch [100/391], Loss: 0.4265\n  Batch [200/391], Loss: 0.4226\n  Batch [300/391], Loss: 0.4129\nEpoch [43/50] (48.5s), Loss: 0.4225, Train Acc: 84.93%, Test Acc: 79.08%, Best: 79.08%\n  Batch [0/391], Loss: 0.4062\n  Batch [100/391], Loss: 0.4361\n  Batch [200/391], Loss: 0.5582\n  Batch [300/391], Loss: 0.4910\nEpoch [44/50] (48.8s), Loss: 0.4165, Train Acc: 85.04%, Test Acc: 79.19%, Best: 79.19%\n  Batch [0/391], Loss: 0.4081\n  Batch [100/391], Loss: 0.3555\n  Batch [200/391], Loss: 0.4829\n  Batch [300/391], Loss: 0.3618\nEpoch [45/50] (48.6s), Loss: 0.4096, Train Acc: 85.40%, Test Acc: 79.21%, Best: 79.21%\n  Batch [0/391], Loss: 0.4989\n  Batch [100/391], Loss: 0.3451\n  Batch [200/391], Loss: 0.2718\n  Batch [300/391], Loss: 0.4291\nEpoch [46/50] (48.3s), Loss: 0.4017, Train Acc: 85.59%, Test Acc: 79.22%, Best: 79.22%\n  Batch [0/391], Loss: 0.5104\n  Batch [100/391], Loss: 0.4457\n  Batch [200/391], Loss: 0.3407\n  Batch [300/391], Loss: 0.3244\nEpoch [47/50] (48.3s), Loss: 0.3980, Train Acc: 85.78%, Test Acc: 79.35%, Best: 79.35%\n  Batch [0/391], Loss: 0.4749\n  Batch [100/391], Loss: 0.3710\n  Batch [200/391], Loss: 0.4184\n  Batch [300/391], Loss: 0.3452\nEpoch [48/50] (48.6s), Loss: 0.3956, Train Acc: 85.86%, Test Acc: 79.33%, Best: 79.35%\n  Batch [0/391], Loss: 0.3969\n  Batch [100/391], Loss: 0.3829\n  Batch [200/391], Loss: 0.4724\n  Batch [300/391], Loss: 0.3295\nEpoch [49/50] (48.7s), Loss: 0.3935, Train Acc: 86.08%, Test Acc: 79.35%, Best: 79.35%\n  Batch [0/391], Loss: 0.4207\n  Batch [100/391], Loss: 0.2965\n  Batch [200/391], Loss: 0.3745\n  Batch [300/391], Loss: 0.2997\nEpoch [50/50] (48.5s), Loss: 0.3919, Train Acc: 85.91%, Test Acc: 79.32%, Best: 79.35%\nTraining completed! Best Test Accuracy: 79.35%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x500 with 3 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Converting model for RTL export...\nConverted model with 4,019,466 parameters\nQuantizing model...\nQuantizing 79 parameter tensors to 8 bits...\nExporting weights...\nExporting test data...\nExport complete! Files saved to: rtl_export\nTestbench generated in: rtl_export/testbench\n\nTraining and export completed!\nBest accuracy: 79.35%\nAll files exported to: rtl_export\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport math\nimport os\nimport json\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nimport time\nfrom torch.quantization import QuantStub, DeQuantStub, prepare_qat, convert\n\n# Configuration\nclass Config:\n    # Hardware settings - Use GPU if available for training speed\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Model architecture (optimized for higher accuracy)\n    img_size = 32  # Increased resolution for better accuracy\n    patch_size = 8\n    embed_dim = 384  # Increased embedding dimension\n    depth = 8       # Increased depth for better performance\n    num_heads = 12\n    mlp_ratio = 4.0\n    \n    # Training settings - optimized for full dataset\n    batch_size = 64  # Reduced for larger model\n    num_epochs = 100  # More epochs for better convergence\n    learning_rate = 0.0005  # Lower learning rate for stability\n    weight_decay = 0.03\n    warmup_epochs = 10\n    \n    # Quantization settings\n    weight_bits = 8\n    activation_bits = 8\n    quantize_after_training = True  # Post-training quantization\n    \n    # Export settings\n    export_dir = \"rtl_export_enhanced\"\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\n# ============================================================================\n# ENHANCED CUSTOM OPERATIONS FOR RTL EXPORT\n# ============================================================================\n\ndef custom_relu(x):\n    \"\"\"Custom ReLU activation - for RTL export only\"\"\"\n    return np.maximum(0, x)\n\ndef custom_gelu_approximate(x):\n    \"\"\"Approximate GELU for hardware efficiency\"\"\"\n    return 0.5 * x * (1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * np.power(x, 3))))\n\ndef custom_softmax(x, axis=-1):\n    \"\"\"Custom softmax with numerical stability - for RTL export only\"\"\"\n    x_shifted = x - np.max(x, axis=axis, keepdims=True)\n    exp_x = np.exp(x_shifted)\n    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n\ndef custom_layer_norm(x, weight, bias, eps=1e-5):\n    \"\"\"Custom Layer Normalization - for RTL export only\"\"\"\n    mean = np.mean(x, axis=-1, keepdims=True)\n    var = np.var(x, axis=-1, keepdims=True)\n    x_norm = (x - mean) / np.sqrt(var + eps)\n    return x_norm * weight + bias\n\ndef custom_attention(q, k, v, scale=None):\n    \"\"\"Custom attention implementation for RTL\"\"\"\n    if scale is None:\n        scale = 1.0 / np.sqrt(q.shape[-1])\n    \n    attn_weights = np.matmul(q, k.transpose(0, 1, 3, 2)) * scale\n    attn_weights = custom_softmax(attn_weights, axis=-1)\n    output = np.matmul(attn_weights, v)\n    return output\n\n# ============================================================================\n# ENHANCED VISION TRANSFORMER WITH BETTER ARCHITECTURE\n# ============================================================================\n\nclass EnhancedPatchEmbedding(nn.Module):\n    def __init__(self, img_size, patch_size, in_channels, embed_dim):\n        super().__init__()\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.num_patches = (img_size // patch_size) ** 2\n        \n        # Use convolution with smaller kernel and overlap for better feature extraction\n        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, \n                             stride=patch_size-1, padding=1)\n        self.norm = nn.LayerNorm(embed_dim)\n        \n    def forward(self, x):\n        x = self.proj(x)\n        x = x.flatten(2).transpose(1, 2)\n        x = self.norm(x)\n        return x\n\nclass EnhancedMultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout=0.1):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n        self.attn_dropout = nn.Dropout(dropout)\n        self.proj = nn.Linear(embed_dim, embed_dim)\n        self.proj_dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = attn.softmax(dim=-1)\n        attn = self.attn_dropout(attn)\n        \n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_dropout(x)\n        return x\n\nclass EnhancedMLP(nn.Module):\n    def __init__(self, in_features, hidden_features, dropout=0.1):\n        super().__init__()\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = nn.GELU()\n        self.dropout1 = nn.Dropout(dropout)\n        self.fc2 = nn.Linear(hidden_features, in_features)\n        self.dropout2 = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.dropout1(x)\n        x = self.fc2(x)\n        x = self.dropout2(x)\n        return x\n\nclass EnhancedTransformerBlock(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4.0, dropout=0.1):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(dim)\n        self.attn = EnhancedMultiHeadAttention(dim, num_heads, dropout)\n        self.norm2 = nn.LayerNorm(dim)\n        self.mlp = EnhancedMLP(dim, int(dim * mlp_ratio), dropout)\n        \n    def forward(self, x):\n        # Pre-norm architecture for better training stability\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nclass EnhancedViT(nn.Module):\n    def __init__(self, img_size=96, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=384, depth=8, num_heads=12, mlp_ratio=4.0, dropout=0.1):\n        super().__init__()\n        \n        self.patch_embed = EnhancedPatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        num_patches = self.patch_embed.num_patches\n        \n        # Learnable positional embedding\n        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n        self.pos_dropout = nn.Dropout(dropout)\n        \n        # Stochastic depth for regularization\n        dpr = [x.item() for x in torch.linspace(0, 0.1, depth)]\n        \n        self.blocks = nn.ModuleList([\n            EnhancedTransformerBlock(embed_dim, num_heads, mlp_ratio, dropout) \n            for _ in range(depth)\n        ])\n        \n        self.norm = nn.LayerNorm(embed_dim)\n        self.head = nn.Linear(embed_dim, num_classes)\n        \n        # Initialize weights\n        self.apply(self._init_weights)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.trunc_normal_(module.weight, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.LayerNorm):\n            torch.nn.init.zeros_(module.bias)\n            torch.nn.init.ones_(module.weight)\n        elif isinstance(module, nn.Conv2d):\n            torch.nn.init.kaiming_normal_(module.weight)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Parameter):\n            torch.nn.init.trunc_normal_(module, std=0.02)\n                \n    def forward(self, x):\n        x = self.patch_embed(x)\n        x = x + self.pos_embed\n        x = self.pos_dropout(x)\n        \n        for block in self.blocks:\n            x = block(x)\n            \n        x = self.norm(x)\n        x = x.mean(dim=1)  # Global average pooling\n        x = self.head(x)\n        return x\n\n# ============================================================================\n# ADVANCED DATA LOADING WITH BETTER AUGMENTATION\n# ============================================================================\n\ndef load_enhanced_cifar10_data():\n    \"\"\"Load CIFAR-10 data with enhanced augmentation\"\"\"\n    train_transform = transforms.Compose([\n        transforms.Resize((config.img_size, config.img_size)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomCrop(config.img_size, padding=8, padding_mode='reflect'),\n        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n        transforms.RandomRotation(10),\n        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n        transforms.RandomErasing(p=0.2)\n    ])\n    \n    test_transform = transforms.Compose([\n        transforms.Resize((config.img_size, config.img_size)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n    ])\n    \n    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n    \n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4, pin_memory=True\n    )\n    \n    test_loader = torch.utils.data.DataLoader(\n        test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=4, pin_memory=True\n    )\n    \n    return train_loader, test_loader\n\n# ============================================================================\n# ADVANCED TRAINING WITH OPTIMIZATIONS\n# ============================================================================\n\ndef get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n    \"\"\"Create cosine learning rate schedule with warmup\"\"\"\n    def lr_lambda(current_step):\n        if current_step < num_warmup_steps:\n            return float(current_step) / float(max(1, num_warmup_steps))\n        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n    \n    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n\ndef train_enhanced_model(model, train_loader, test_loader, config):\n    \"\"\"Train the enhanced ViT model with advanced techniques\"\"\"\n    model.to(config.device)\n    \n    # Advanced optimizer settings\n    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label smoothing for regularization\n    \n    # Use AdamW with different parameter groups\n    no_decay = ['bias', 'LayerNorm.weight']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n         'weight_decay': config.weight_decay},\n        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n         'weight_decay': 0.0}\n    ]\n    \n    optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=config.learning_rate)\n    \n    # Learning rate scheduling\n    num_training_steps = len(train_loader) * config.num_epochs\n    num_warmup_steps = len(train_loader) * config.warmup_epochs\n    \n    scheduler = get_cosine_schedule_with_warmup(\n        optimizer, num_warmup_steps, num_training_steps\n    )\n    \n    # Gradient clipping\n    max_grad_norm = 1.0\n    \n    # Mixed precision training\n    scaler = torch.cuda.amp.GradScaler()\n    \n    train_losses = []\n    train_accs = []\n    test_accs = []\n    best_acc = 0.0\n    \n    print(\"Starting enhanced training...\")\n    for epoch in range(config.num_epochs):\n        epoch_start = time.time()\n        \n        # Training phase\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n        total_samples = 0\n        \n        for batch_idx, (inputs, targets) in enumerate(train_loader):\n            inputs, targets = inputs.to(config.device), targets.to(config.device)\n            \n            optimizer.zero_grad()\n            \n            # Mixed precision forward pass\n            with torch.cuda.amp.autocast():\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n            \n            # Mixed precision backward pass\n            scaler.scale(loss).backward()\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n            scaler.step(optimizer)\n            scaler.update()\n            \n            scheduler.step()\n            \n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = outputs.max(1)\n            running_corrects += predicted.eq(targets).sum().item()\n            total_samples += inputs.size(0)\n            \n            if batch_idx % 100 == 0:\n                current_lr = optimizer.param_groups[0]['lr']\n                print(f'  Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}, LR: {current_lr:.6f}')\n        \n        epoch_loss = running_loss / total_samples\n        epoch_acc = 100. * running_corrects / total_samples\n        \n        # Test phase\n        test_acc = evaluate_model(model, test_loader, config)\n        \n        train_losses.append(epoch_loss)\n        train_accs.append(epoch_acc)\n        test_accs.append(test_acc)\n        \n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'best_acc': best_acc,\n                'config': config.__dict__\n            }, 'best_enhanced_vit_model.pth')\n        \n        epoch_time = time.time() - epoch_start\n        print(f'Epoch [{epoch+1}/{config.num_epochs}] ({epoch_time:.1f}s), '\n              f'Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, Test Acc: {test_acc:.2f}%, Best: {best_acc:.2f}%')\n    \n    # Load best model\n    checkpoint = torch.load('best_enhanced_vit_model.pth')\n    model.load_state_dict(checkpoint['model_state_dict'])\n    print(f'Training completed! Best Test Accuracy: {best_acc:.2f}%')\n    \n    return train_losses, train_accs, test_accs, best_acc\n\ndef evaluate_model(model, test_loader, config):\n    \"\"\"Evaluate model on test set\"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs, targets = inputs.to(config.device), targets.to(config.device)\n            outputs = model(inputs)\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n    \n    accuracy = 100. * correct / total\n    return accuracy\n\n# ============================================================================\n# ADVANCED QUANTIZATION WITH POST-TRAINING QUANTIZATION\n# ============================================================================\n\nclass QuantizedViT(nn.Module):\n    \"\"\"Quantized version of ViT for deployment\"\"\"\n    def __init__(self, original_model):\n        super().__init__()\n        self.quant = QuantStub()\n        self.dequant = DeQuantStub()\n        \n        # Copy architecture\n        self.patch_embed = original_model.patch_embed\n        self.pos_embed = original_model.pos_embed\n        self.blocks = original_model.blocks\n        self.norm = original_model.norm\n        self.head = original_model.head\n        \n    def forward(self, x):\n        x = self.quant(x)\n        x = self.patch_embed(x)\n        x = x + self.pos_embed\n        x = self.dequant(x)  # Dequantize for operations that are hard to quantize\n        \n        for block in self.blocks:\n            x = block(x)\n            \n        x = self.norm(x)\n        x = x.mean(dim=1)\n        x = self.head(x)\n        return x\n\ndef apply_post_training_quantization(model, test_loader, config):\n    \"\"\"Apply post-training quantization to the model\"\"\"\n    print(\"Applying post-training quantization...\")\n    \n    # Create quantized model\n    quantized_model = QuantizedViT(model)\n    quantized_model.eval()\n    \n    # Prepare for quantization\n    quantized_model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n    \n    # Prepare and convert\n    model_prepared = torch.quantization.prepare(quantized_model, inplace=False)\n    \n    # Calibration with test data\n    print(\"Calibrating quantized model...\")\n    with torch.no_grad():\n        for i, (inputs, _) in enumerate(test_loader):\n            if i >= 100:  # Use 100 batches for calibration\n                break\n            model_prepared(inputs.to(config.device))\n    \n    # Convert to quantized model\n    model_quantized = torch.quantization.convert(model_prepared, inplace=False)\n    \n    # Test quantized model accuracy\n    quantized_accuracy = evaluate_model(model_quantized, test_loader, config)\n    print(f\"Quantized model accuracy: {quantized_accuracy:.2f}%\")\n    \n    return model_quantized\n\ndef symmetric_quantize_advanced(x, bits=8, scale=None, per_channel=False):\n    \"\"\"Advanced symmetric quantization with per-channel support\"\"\"\n    if scale is None:\n        if per_channel and x.ndim > 1:\n            # Per-channel quantization\n            max_vals = np.max(np.abs(x.reshape(x.shape[0], -1)), axis=1)\n            scale = max_vals / (2**(bits-1) - 1)\n            scale = scale.reshape(-1, *([1] * (x.ndim - 1)))\n        else:\n            # Per-tensor quantization\n            max_val = np.max(np.abs(x))\n            if max_val == 0:\n                scale = 1.0\n            else:\n                scale = max_val / (2**(bits-1) - 1)\n    \n    x_q = np.round(x / scale)\n    x_q = np.clip(x_q, -(2**(bits-1)), 2**(bits-1) - 1)\n    return x_q.astype(np.int8), scale\n\ndef dequantize_advanced(x_q, scale):\n    \"\"\"Advanced dequantization with per-channel support\"\"\"\n    return x_q.astype(np.float32) * scale\n\n# ============================================================================\n# COMPREHENSIVE EXPORT SYSTEM\n# ============================================================================\n\ndef convert_pytorch_to_custom_format_advanced(pytorch_model, config):\n    \"\"\"Convert PyTorch model to custom format for RTL export with enhanced features\"\"\"\n    \n    class AdvancedCustomViTForExport:\n        def __init__(self):\n            # Extract parameters from PyTorch model\n            self.params = {}\n            self.param_shapes = {}\n            \n            # Patch embedding\n            self.params['patch_embed.weight'] = pytorch_model.patch_embed.proj.weight.detach().cpu().numpy()\n            self.params['patch_embed.bias'] = pytorch_model.patch_embed.proj.bias.detach().cpu().numpy()\n            self.param_shapes['patch_embed.weight'] = self.params['patch_embed.weight'].shape\n            self.param_shapes['patch_embed.bias'] = self.params['patch_embed.bias'].shape\n            \n            # Positional embedding\n            self.params['pos_embed'] = pytorch_model.pos_embed.detach().cpu().numpy()[0]\n            self.param_shapes['pos_embed'] = self.params['pos_embed'].shape\n            \n            # Transformer blocks\n            for i, block in enumerate(pytorch_model.blocks):\n                # Layer norm 1\n                self.params[f'blocks.{i}.norm1.weight'] = block.norm1.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.norm1.bias'] = block.norm1.bias.detach().cpu().numpy()\n                \n                # Attention\n                self.params[f'blocks.{i}.attn.qkv.weight'] = block.attn.qkv.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.attn.qkv.bias'] = block.attn.qkv.bias.detach().cpu().numpy()\n                self.params[f'blocks.{i}.attn.proj.weight'] = block.attn.proj.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.attn.proj.bias'] = block.attn.proj.bias.detach().cpu().numpy()\n                \n                # Layer norm 2\n                self.params[f'blocks.{i}.norm2.weight'] = block.norm2.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.norm2.bias'] = block.norm2.bias.detach().cpu().numpy()\n                \n                # MLP\n                self.params[f'blocks.{i}.mlp.fc1.weight'] = block.mlp.fc1.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.mlp.fc1.bias'] = block.mlp.fc1.bias.detach().cpu().numpy()\n                self.params[f'blocks.{i}.mlp.fc2.weight'] = block.mlp.fc2.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.mlp.fc2.bias'] = block.mlp.fc2.bias.detach().cpu().numpy()\n                \n                # Store shapes\n                for key in [f'blocks.{i}.norm1.weight', f'blocks.{i}.norm1.bias',\n                           f'blocks.{i}.attn.qkv.weight', f'blocks.{i}.attn.qkv.bias',\n                           f'blocks.{i}.attn.proj.weight', f'blocks.{i}.attn.proj.bias',\n                           f'blocks.{i}.norm2.weight', f'blocks.{i}.norm2.bias',\n                           f'blocks.{i}.mlp.fc1.weight', f'blocks.{i}.mlp.fc1.bias',\n                           f'blocks.{i}.mlp.fc2.weight', f'blocks.{i}.mlp.fc2.bias']:\n                    self.param_shapes[key] = self.params[key].shape\n            \n            # Final layers\n            self.params['norm.weight'] = pytorch_model.norm.weight.detach().cpu().numpy()\n            self.params['norm.bias'] = pytorch_model.norm.bias.detach().cpu().numpy()\n            self.params['head.weight'] = pytorch_model.head.weight.detach().cpu().numpy()\n            self.params['head.bias'] = pytorch_model.head.bias.detach().cpu().numpy()\n            \n            self.param_shapes.update({\n                'norm.weight': self.params['norm.weight'].shape,\n                'norm.bias': self.params['norm.bias'].shape,\n                'head.weight': self.params['head.weight'].shape,\n                'head.bias': self.params['head.bias'].shape\n            })\n            \n            total_params = sum(p.size for p in self.params.values())\n            print(f\"Converted model with {total_params:,} parameters\")\n            print(f\"Parameter breakdown:\")\n            for name, param in self.params.items():\n                print(f\"  {name}: {param.shape} ({param.size:,} parameters)\")\n        \n        def quantize_model_advanced(self, weight_bits=8, activation_bits=8):\n            \"\"\"Advanced quantization with per-channel support for weights\"\"\"\n            quantized_params = {}\n            scales = {}\n            zero_points = {}\n            \n            print(f\"Quantizing {len(self.params)} parameter tensors...\")\n            \n            for name, param in self.params.items():\n                # Use per-channel quantization for weight matrices, per-tensor for others\n                per_channel = 'weight' in name and param.ndim > 1\n                q_param, scale = symmetric_quantize_advanced(param, weight_bits, per_channel=per_channel)\n                quantized_params[name] = q_param\n                scales[name] = scale\n                zero_points[name] = np.zeros_like(scale)  # Symmetric quantization\n                \n                # Calculate quantization error\n                param_dequant = dequantize_advanced(q_param, scale)\n                quant_error = np.mean(np.abs(param - param_dequant))\n                print(f\"  {name}: scale={np.mean(scale):.6f}, error={quant_error:.6f}\")\n            \n            return quantized_params, scales, zero_points\n    \n    return AdvancedCustomViTForExport()\n\ndef export_comprehensive_rtl(custom_model, test_loader, config):\n    \"\"\"Comprehensive export for RTL implementation\"\"\"\n    os.makedirs(config.export_dir, exist_ok=True)\n    \n    print(\"Advanced model quantization...\")\n    quantized_params, scales, zero_points = custom_model.quantize_model_advanced(\n        config.weight_bits, config.activation_bits\n    )\n    \n    # Export directory structure\n    weights_dir = os.path.join(config.export_dir, \"weights\")\n    test_data_dir = os.path.join(config.export_dir, \"test_data\")\n    metadata_dir = os.path.join(config.export_dir, \"metadata\")\n    \n    for dir_path in [weights_dir, test_data_dir, metadata_dir]:\n        os.makedirs(dir_path, exist_ok=True)\n    \n    # Export quantized weights in multiple formats\n    print(\"Exporting weights in multiple formats...\")\n    \n    # 1. Hex format for Verilog\n    for name, q_param in quantized_params.items():\n        # Flatten and export as hex\n        flat_data = q_param.flatten()\n        \n        # Hex format\n        hex_filename = os.path.join(weights_dir, f\"{name.replace('.', '_')}.hex\")\n        with open(hex_filename, 'w') as f:\n            for val in flat_data:\n                f.write(f\"{val & 0xFF:02x}\\n\")\n        \n        # Binary format (for simulation)\n        bin_filename = os.path.join(weights_dir, f\"{name.replace('.', '_')}.bin\")\n        with open(bin_filename, 'wb') as f:\n            f.write(flat_data.tobytes())\n    \n    # Export scales and zero points\n    with open(os.path.join(metadata_dir, \"quantization_info.json\"), 'w') as f:\n        quant_info = {\n            'scales': {k: v.tolist() if isinstance(v, np.ndarray) else float(v) \n                      for k, v in scales.items()},\n            'zero_points': {k: v.tolist() if isinstance(v, np.ndarray) else float(v) \n                          for k, v in zero_points.items()},\n            'weight_bits': config.weight_bits,\n            'activation_bits': config.activation_bits\n        }\n        json.dump(quant_info, f, indent=2)\n    \n    # Export parameter shapes\n    with open(os.path.join(metadata_dir, \"parameter_shapes.json\"), 'w') as f:\n        json.dump(custom_model.param_shapes, f, indent=2)\n    \n    # Comprehensive test data export\n    print(\"Exporting comprehensive test data...\")\n    test_dataset = test_loader.dataset\n    \n    # Export multiple test samples\n    num_test_samples = min(50, len(test_dataset))\n    test_samples = []\n    \n    for i in range(num_test_samples):\n        img, label = test_dataset[i]\n        img_np = img.numpy()\n        \n        # Quantize test image\n        q_img, img_scale = symmetric_quantize_advanced(img_np, config.activation_bits)\n        \n        # Save quantized image\n        img_filename = os.path.join(test_data_dir, f\"test_img_{i:03d}\")\n        \n        # Hex format\n        with open(img_filename + \".hex\", 'w') as f:\n            for val in q_img.flatten():\n                f.write(f\"{val & 0xFF:02x}\\n\")\n        \n        # Binary format\n        with open(img_filename + \".bin\", 'wb') as f:\n            f.write(q_img.tobytes())\n        \n        test_samples.append({\n            'index': i,\n            'label': int(label),\n            'scale': float(img_scale),\n            'shape': img_np.shape\n        })\n    \n    # Export test metadata\n    with open(os.path.join(test_data_dir, \"test_metadata.json\"), 'w') as f:\n        json.dump(test_samples, f, indent=2)\n    \n    # Export labels separately\n    test_labels = [test_dataset[i][1] for i in range(num_test_samples)]\n    with open(os.path.join(test_data_dir, \"test_labels.json\"), 'w') as f:\n        json.dump(test_labels, f)\n    \n    # Export model architecture and configuration\n    arch_info = {\n        \"architecture\": {\n            \"img_size\": config.img_size,\n            \"patch_size\": config.patch_size,\n            \"embed_dim\": config.embed_dim,\n            \"depth\": config.depth,\n            \"num_heads\": config.num_heads,\n            \"num_classes\": 10,\n            \"mlp_ratio\": config.mlp_ratio\n        },\n        \"quantization\": {\n            \"weight_bits\": config.weight_bits,\n            \"activation_bits\": config.activation_bits\n        },\n        \"training\": {\n            \"batch_size\": config.batch_size,\n            \"learning_rate\": config.learning_rate,\n            \"weight_decay\": config.weight_decay\n        }\n    }\n    \n    with open(os.path.join(metadata_dir, \"model_architecture.json\"), 'w') as f:\n        json.dump(arch_info, f, indent=2)\n    \n    # Generate summary report\n    generate_export_summary(config, custom_model, num_test_samples)\n    \n    print(f\"Comprehensive export complete! Files saved to: {config.export_dir}\")\n\ndef generate_export_summary(config, custom_model, num_test_samples):\n    \"\"\"Generate comprehensive export summary\"\"\"\n    summary = {\n        \"export_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"model_statistics\": {\n            \"total_parameters\": sum(p.size for p in custom_model.params.values()),\n            \"number_of_layers\": len(custom_model.params),\n            \"parameter_memory_mb\": sum(p.size for p in custom_model.params.values()) * config.weight_bits / 8 / 1024 / 1024\n        },\n        \"export_contents\": {\n            \"quantized_weights\": \"All model weights in hex and binary format\",\n            \"test_data\": f\"{num_test_samples} test images with labels\",\n            \"quantization_info\": \"Scales and zero points for all parameters\",\n            \"model_architecture\": \"Complete model configuration\",\n            \"parameter_shapes\": \"Shape information for all tensors\"\n        },\n        \"estimated_hardware_requirements\": {\n            \"weight_memory_bits\": sum(p.size for p in custom_model.params.values()) * config.weight_bits,\n            \"activation_memory_bits\": config.img_size * config.img_size * 3 * config.activation_bits,\n            \"computation_ops\": \"Approx. 4G FLOPS for inference\"  # Rough estimate\n        }\n    }\n    \n    with open(os.path.join(config.export_dir, \"export_summary.json\"), 'w') as f:\n        json.dump(summary, f, indent=2)\n    \n    # Print human-readable summary\n    print(\"\\n\" + \"=\"*60)\n    print(\"EXPORT SUMMARY\")\n    print(\"=\"*60)\n    print(f\"Model Parameters: {summary['model_statistics']['total_parameters']:,}\")\n    print(f\"Parameter Memory: {summary['model_statistics']['parameter_memory_mb']:.2f} MB\")\n    print(f\"Test Samples: {num_test_samples}\")\n    print(f\"Weight Precision: {config.weight_bits} bits\")\n    print(f\"Activation Precision: {config.activation_bits} bits\")\n    print(\"=\"*60)\n\ndef generate_enhanced_verilog_testbench(config):\n    \"\"\"Generate enhanced Verilog testbench with comprehensive testing\"\"\"\n    tb_dir = os.path.join(config.export_dir, \"verilog_testbench\")\n    os.makedirs(tb_dir, exist_ok=True)\n    \n    # Main testbench\n    verilog_tb = f'''\n// Enhanced Verilog Testbench for Custom ViT\n// Generated automatically for RTL implementation\n\n`timescale 1ns / 1ps\n\nmodule enhanced_vit_testbench();\n    \n    // Parameters from model architecture\n    localparam IMG_SIZE = {config.img_size};\n    localparam PATCH_SIZE = {config.patch_size};\n    localparam EMBED_DIM = {config.embed_dim};\n    localparam DEPTH = {config.depth};\n    localparam NUM_HEADS = {config.num_heads};\n    localparam NUM_CLASSES = 10;\n    localparam WEIGHT_BITS = {config.weight_bits};\n    localparam ACT_BITS = {config.activation_bits};\n    \n    // Derived parameters\n    localparam NUM_PATCHES = (IMG_SIZE / PATCH_SIZE) * (IMG_SIZE / PATCH_SIZE);\n    localparam IMG_PIXELS = IMG_SIZE * IMG_SIZE * 3; // RGB channels\n    localparam HEAD_DIM = EMBED_DIM / NUM_HEADS;\n    \n    // Clock and reset\n    reg clk;\n    reg rst_n;\n    \n    // Input data\n    reg [ACT_BITS-1:0] input_image [0:IMG_PIXELS-1];\n    reg start;\n    reg [7:0] test_image_index;\n    \n    // Output data\n    wire [ACT_BITS-1:0] output_logits [0:NUM_CLASSES-1];\n    wire [3:0] predicted_class;\n    wire done;\n    wire [7:0] processing_time;\n    \n    // Test control\n    reg [7:0] current_test;\n    reg [7:0] total_tests;\n    reg [7:0] passed_tests;\n    \n    // DUT instantiation\n    vit_top #(\n        .IMG_SIZE(IMG_SIZE),\n        .PATCH_SIZE(PATCH_SIZE),\n        .EMBED_DIM(EMBED_DIM),\n        .DEPTH(DEPTH),\n        .NUM_HEADS(NUM_HEADS),\n        .NUM_CLASSES(NUM_CLASSES),\n        .WEIGHT_BITS(WEIGHT_BITS),\n        .ACT_BITS(ACT_BITS)\n    ) dut (\n        .clk(clk),\n        .rst_n(rst_n),\n        .input_image(input_image),\n        .start(start),\n        .output_logits(output_logits),\n        .predicted_class(predicted_class),\n        .done(done)\n    );\n    \n    // Performance monitoring\n    reg [31:0] cycle_counter;\n    always @(posedge clk) begin\n        if (!rst_n) cycle_counter <= 0;\n        else if (start) cycle_counter <= 1;\n        else if (!done) cycle_counter <= cycle_counter + 1;\n    end\n    \n    assign processing_time = cycle_counter;\n    \n    // Clock generation\n    always #5 clk = ~clk;\n    \n    // Test sequence\n    initial begin\n        // Initialize\n        clk = 0;\n        rst_n = 0;\n        start = 0;\n        test_image_index = 0;\n        current_test = 0;\n        total_tests = 10; // Test with 10 different images\n        passed_tests = 0;\n        \n        $display(\"Starting Enhanced ViT Testbench\");\n        $display(\"Model Configuration:\");\n        $display(\"  Image Size: %0d\", IMG_SIZE);\n        $display(\"  Patch Size: %0d\", PATCH_SIZE);\n        $display(\"  Embed Dim: %0d\", EMBED_DIM);\n        $display(\"  Depth: %0d\", DEPTH);\n        $display(\"  Heads: %0d\", NUM_HEADS);\n        \n        // Reset sequence\n        #100;\n        rst_n = 1;\n        #50;\n        \n        // Run multiple test cases\n        for (current_test = 0; current_test < total_tests; current_test = current_test + 1) begin\n            $display(\"\\\\n=== Test Case %0d ===\", current_test);\n            \n            // Load input image from memory file\n            $readmemh($sformatf(\"test_data/test_img_%03d.hex\", current_test), input_image);\n            \n            // Start processing\n            start = 1;\n            #10;\n            start = 0;\n            \n            // Wait for completion\n            wait(done);\n            \n            // Check results\n            $display(\"Processing complete in %0d cycles\", processing_time);\n            $display(\"Predicted class: %0d\", predicted_class);\n            \n            // Verify prediction (simplified - in real test, compare with expected)\n            if (predicted_class < NUM_CLASSES) begin\n                passed_tests = passed_tests + 1;\n                $display(\" Test PASSED\");\n            end else begin\n                $display(\" Test FAILED - Invalid class prediction\");\n            end\n            \n            // Display output logits\n            $display(\"Output logits:\");\n            for (int i = 0; i < NUM_CLASSES; i = i + 1) begin\n                $display(\"  Class %0d: %h\", i, output_logits[i]);\n            end\n            \n            #100; // Delay between tests\n        end\n        \n        // Test summary\n        $display(\"\\\\n=== TEST SUMMARY ===\");\n        $display(\"Total Tests: %0d\", total_tests);\n        $display(\"Passed Tests: %0d\", passed_tests);\n        $display(\"Success Rate: %0.1f%%\", (100.0 * passed_tests) / total_tests);\n        \n        #100;\n        $finish;\n    end\n    \n    // Performance analysis\n    final begin\n        $display(\"\\\\n=== PERFORMANCE ANALYSIS ===\");\n        $display(\"Average processing time: %0.1f cycles per image\", \n                 (1.0 * cycle_counter) / total_tests);\n    end\n    \nendmodule\n\n// Memory initialization module\nmodule memory_initializer();\n    // This module would initialize all weight memories\n    // Implementation depends on specific memory architecture\nendmodule\n'''\n    \n    with open(os.path.join(tb_dir, \"enhanced_vit_testbench.sv\"), 'w') as f:\n        f.write(verilog_tb)\n    \n    # Generate memory initialization files\n    generate_memory_init_files(tb_dir, config)\n    \n    print(f\"Enhanced testbench generated in: {tb_dir}\")\n\ndef generate_memory_init_files(tb_dir, config):\n    \"\"\"Generate memory initialization files for Verilog\"\"\"\n    mem_init_dir = os.path.join(tb_dir, \"mem_init\")\n    os.makedirs(mem_init_dir, exist_ok=True)\n    \n    # Create sample memory initialization files\n    sample_mem_init = '''\n// Sample memory initialization file\n// This would be generated from actual weight data\n\n// Patch embedding weights\nmodule patch_embed_mem();\n    initial begin\n        // Memory initialization code would go here\n    end\nendmodule\n'''\n    \n    with open(os.path.join(mem_init_dir, \"sample_mem_init.sv\"), 'w') as f:\n        f.write(sample_mem_init)\n\n# ============================================================================\n# MAIN EXECUTION WITH ENHANCED FEATURES\n# ============================================================================\n\ndef main():\n    print(\"=\"*70)\n    print(\"ENHANCED HYBRID ViT IMPLEMENTATION\")\n    print(\"High Accuracy Training + Advanced RTL Export\")\n    print(\"=\"*70)\n    \n    # Load enhanced data\n    train_loader, test_loader = load_enhanced_cifar10_data()\n    \n    # Create enhanced model\n    model = EnhancedViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        mlp_ratio=config.mlp_ratio,\n        num_classes=10\n    )\n    \n    # Count parameters\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Total parameters: {total_params:,}\")\n    \n    # Train enhanced model\n    train_losses, train_accs, test_accs, best_acc = train_enhanced_model(\n        model, train_loader, test_loader, config\n    )\n    \n    # Apply post-training quantization if enabled\n    if config.quantize_after_training:\n        model = apply_post_training_quantization(model, test_loader, config)\n    \n    # Plot comprehensive results\n    plt.figure(figsize=(18, 6))\n    \n    plt.subplot(1, 3, 1)\n    plt.plot(train_losses)\n    plt.title('Enhanced Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.grid(True)\n    \n    plt.subplot(1, 3, 2)\n    plt.plot(train_accs, label='Train', linewidth=2)\n    plt.plot(test_accs, label='Test', linewidth=2)\n    plt.title('Enhanced Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.subplot(1, 3, 3)\n    # Plot learning rate schedule (approximate)\n    epochs = range(1, len(train_accs) + 1)\n    plt.plot(epochs, test_accs, 'g-', linewidth=2)\n    plt.title('Test Accuracy Progression')\n    plt.xlabel('Epoch')\n    plt.ylabel('Test Accuracy (%)')\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig('enhanced_training_results.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    # Convert to custom format and export for RTL\n    print(\"Converting model for comprehensive RTL export...\")\n    custom_model = convert_pytorch_to_custom_format_advanced(model, config)\n    \n    # Comprehensive export for RTL implementation\n    export_comprehensive_rtl(custom_model, test_loader, config)\n    \n    # Generate enhanced RTL testbench\n    generate_enhanced_verilog_testbench(config)\n    \n    print(f\"\\Enhanced training and export completed!\")\n    print(f\"Best accuracy: {best_acc:.2f}%\")\n    print(f\"All files exported to: {config.export_dir}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T15:56:40.255561Z","iopub.execute_input":"2025-09-28T15:56:40.256340Z","iopub.status.idle":"2025-09-28T17:07:24.716853Z","shell.execute_reply.started":"2025-09-28T15:56:40.256303Z","shell.execute_reply":"2025-09-28T17:07:24.715567Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n======================================================================\nENHANCED HYBRID ViT IMPLEMENTATION\nHigh Accuracy Training + Advanced RTL Export\n======================================================================\nTotal parameters: 14,281,354\nStarting enhanced training...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/1301805251.py:294: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n/tmp/ipykernel_36/1301805251.py:317: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"  Batch [0/782], Loss: 2.3411, LR: 0.000000\n  Batch [100/782], Loss: 2.1748, LR: 0.000006\n  Batch [200/782], Loss: 2.1361, LR: 0.000013\n  Batch [300/782], Loss: 2.0366, LR: 0.000019\n  Batch [400/782], Loss: 2.0510, LR: 0.000026\n  Batch [500/782], Loss: 2.0836, LR: 0.000032\n  Batch [600/782], Loss: 1.9270, LR: 0.000038\n  Batch [700/782], Loss: 2.0090, LR: 0.000045\nEpoch [1/100] (43.3s), Loss: 2.1020, Train Acc: 23.20%, Test Acc: 32.95%, Best: 32.95%\n  Batch [0/782], Loss: 2.0708, LR: 0.000050\n  Batch [100/782], Loss: 2.0524, LR: 0.000056\n  Batch [200/782], Loss: 1.9560, LR: 0.000063\n  Batch [300/782], Loss: 2.0685, LR: 0.000069\n  Batch [400/782], Loss: 2.0232, LR: 0.000076\n  Batch [500/782], Loss: 1.9613, LR: 0.000082\n  Batch [600/782], Loss: 1.7925, LR: 0.000088\n  Batch [700/782], Loss: 2.1882, LR: 0.000095\nEpoch [2/100] (43.0s), Loss: 1.9686, Train Acc: 30.06%, Test Acc: 37.58%, Best: 37.58%\n  Batch [0/782], Loss: 1.9437, LR: 0.000100\n  Batch [100/782], Loss: 2.0216, LR: 0.000106\n  Batch [200/782], Loss: 1.9756, LR: 0.000113\n  Batch [300/782], Loss: 1.9406, LR: 0.000119\n  Batch [400/782], Loss: 1.9058, LR: 0.000126\n  Batch [500/782], Loss: 1.8048, LR: 0.000132\n  Batch [600/782], Loss: 1.8633, LR: 0.000138\n  Batch [700/782], Loss: 1.8511, LR: 0.000145\nEpoch [3/100] (42.7s), Loss: 1.8922, Train Acc: 34.27%, Test Acc: 40.28%, Best: 40.28%\n  Batch [0/782], Loss: 1.7669, LR: 0.000150\n  Batch [100/782], Loss: 1.9142, LR: 0.000156\n  Batch [200/782], Loss: 1.9390, LR: 0.000163\n  Batch [300/782], Loss: 1.8520, LR: 0.000169\n  Batch [400/782], Loss: 1.7547, LR: 0.000176\n  Batch [500/782], Loss: 1.7832, LR: 0.000182\n  Batch [600/782], Loss: 1.6738, LR: 0.000188\n  Batch [700/782], Loss: 1.9137, LR: 0.000195\nEpoch [4/100] (41.9s), Loss: 1.8455, Train Acc: 37.08%, Test Acc: 44.74%, Best: 44.74%\n  Batch [0/782], Loss: 1.8604, LR: 0.000200\n  Batch [100/782], Loss: 1.7863, LR: 0.000206\n  Batch [200/782], Loss: 1.7513, LR: 0.000213\n  Batch [300/782], Loss: 1.8914, LR: 0.000219\n  Batch [400/782], Loss: 1.8640, LR: 0.000226\n  Batch [500/782], Loss: 1.7613, LR: 0.000232\n  Batch [600/782], Loss: 1.8849, LR: 0.000238\n  Batch [700/782], Loss: 1.7518, LR: 0.000245\nEpoch [5/100] (42.6s), Loss: 1.8098, Train Acc: 39.16%, Test Acc: 45.47%, Best: 45.47%\n  Batch [0/782], Loss: 1.7953, LR: 0.000250\n  Batch [100/782], Loss: 1.8824, LR: 0.000256\n  Batch [200/782], Loss: 1.7729, LR: 0.000263\n  Batch [300/782], Loss: 1.9231, LR: 0.000269\n  Batch [400/782], Loss: 1.8907, LR: 0.000276\n  Batch [500/782], Loss: 1.7751, LR: 0.000282\n  Batch [600/782], Loss: 1.8085, LR: 0.000288\n  Batch [700/782], Loss: 1.9200, LR: 0.000295\nEpoch [6/100] (41.9s), Loss: 1.7927, Train Acc: 40.02%, Test Acc: 46.66%, Best: 46.66%\n  Batch [0/782], Loss: 1.7071, LR: 0.000300\n  Batch [100/782], Loss: 1.6847, LR: 0.000306\n  Batch [200/782], Loss: 1.8202, LR: 0.000313\n  Batch [300/782], Loss: 1.6891, LR: 0.000319\n  Batch [400/782], Loss: 1.6738, LR: 0.000326\n  Batch [500/782], Loss: 1.7366, LR: 0.000332\n  Batch [600/782], Loss: 1.7846, LR: 0.000338\n  Batch [700/782], Loss: 1.6711, LR: 0.000345\nEpoch [7/100] (41.9s), Loss: 1.7818, Train Acc: 40.72%, Test Acc: 49.61%, Best: 49.61%\n  Batch [0/782], Loss: 1.9535, LR: 0.000350\n  Batch [100/782], Loss: 1.7124, LR: 0.000356\n  Batch [200/782], Loss: 1.6637, LR: 0.000363\n  Batch [300/782], Loss: 1.7131, LR: 0.000369\n  Batch [400/782], Loss: 1.7674, LR: 0.000376\n  Batch [500/782], Loss: 1.7039, LR: 0.000382\n  Batch [600/782], Loss: 1.8467, LR: 0.000388\n  Batch [700/782], Loss: 1.7896, LR: 0.000395\nEpoch [8/100] (41.4s), Loss: 1.7636, Train Acc: 41.39%, Test Acc: 48.04%, Best: 49.61%\n  Batch [0/782], Loss: 1.7313, LR: 0.000400\n  Batch [100/782], Loss: 1.6515, LR: 0.000406\n  Batch [200/782], Loss: 1.6488, LR: 0.000413\n  Batch [300/782], Loss: 1.8328, LR: 0.000419\n  Batch [400/782], Loss: 1.6211, LR: 0.000426\n  Batch [500/782], Loss: 1.6872, LR: 0.000432\n  Batch [600/782], Loss: 1.6484, LR: 0.000438\n  Batch [700/782], Loss: 1.7947, LR: 0.000445\nEpoch [9/100] (42.2s), Loss: 1.7501, Train Acc: 41.90%, Test Acc: 50.86%, Best: 50.86%\n  Batch [0/782], Loss: 1.9235, LR: 0.000450\n  Batch [100/782], Loss: 1.9803, LR: 0.000456\n  Batch [200/782], Loss: 1.8112, LR: 0.000463\n  Batch [300/782], Loss: 1.6860, LR: 0.000469\n  Batch [400/782], Loss: 1.7032, LR: 0.000476\n  Batch [500/782], Loss: 1.8245, LR: 0.000482\n  Batch [600/782], Loss: 1.8746, LR: 0.000488\n  Batch [700/782], Loss: 1.6482, LR: 0.000495\nEpoch [10/100] (42.1s), Loss: 1.7415, Train Acc: 42.58%, Test Acc: 50.94%, Best: 50.94%\n  Batch [0/782], Loss: 1.7310, LR: 0.000500\n  Batch [100/782], Loss: 1.9497, LR: 0.000500\n  Batch [200/782], Loss: 1.7845, LR: 0.000500\n  Batch [300/782], Loss: 1.6073, LR: 0.000500\n  Batch [400/782], Loss: 1.6709, LR: 0.000500\n  Batch [500/782], Loss: 1.5984, LR: 0.000500\n  Batch [600/782], Loss: 1.6478, LR: 0.000500\n  Batch [700/782], Loss: 1.6403, LR: 0.000500\nEpoch [11/100] (41.9s), Loss: 1.7276, Train Acc: 43.28%, Test Acc: 53.08%, Best: 53.08%\n  Batch [0/782], Loss: 1.7135, LR: 0.000500\n  Batch [100/782], Loss: 1.7298, LR: 0.000500\n  Batch [200/782], Loss: 1.8779, LR: 0.000500\n  Batch [300/782], Loss: 1.4852, LR: 0.000500\n  Batch [400/782], Loss: 1.6326, LR: 0.000500\n  Batch [500/782], Loss: 1.6691, LR: 0.000500\n  Batch [600/782], Loss: 1.7466, LR: 0.000500\n  Batch [700/782], Loss: 1.7278, LR: 0.000499\nEpoch [12/100] (42.3s), Loss: 1.7046, Train Acc: 44.34%, Test Acc: 53.34%, Best: 53.34%\n  Batch [0/782], Loss: 1.6918, LR: 0.000499\n  Batch [100/782], Loss: 1.6592, LR: 0.000499\n  Batch [200/782], Loss: 1.7823, LR: 0.000499\n  Batch [300/782], Loss: 1.6981, LR: 0.000499\n  Batch [400/782], Loss: 1.7002, LR: 0.000499\n  Batch [500/782], Loss: 1.7851, LR: 0.000499\n  Batch [600/782], Loss: 1.6515, LR: 0.000499\n  Batch [700/782], Loss: 1.5313, LR: 0.000499\nEpoch [13/100] (42.4s), Loss: 1.6817, Train Acc: 45.44%, Test Acc: 53.65%, Best: 53.65%\n  Batch [0/782], Loss: 1.7616, LR: 0.000499\n  Batch [100/782], Loss: 1.5485, LR: 0.000499\n  Batch [200/782], Loss: 1.6057, LR: 0.000498\n  Batch [300/782], Loss: 1.8262, LR: 0.000498\n  Batch [400/782], Loss: 1.7851, LR: 0.000498\n  Batch [500/782], Loss: 1.7204, LR: 0.000498\n  Batch [600/782], Loss: 1.5978, LR: 0.000498\n  Batch [700/782], Loss: 1.6126, LR: 0.000498\nEpoch [14/100] (41.9s), Loss: 1.6665, Train Acc: 46.32%, Test Acc: 55.36%, Best: 55.36%\n  Batch [0/782], Loss: 1.5971, LR: 0.000498\n  Batch [100/782], Loss: 1.6851, LR: 0.000497\n  Batch [200/782], Loss: 1.9435, LR: 0.000497\n  Batch [300/782], Loss: 1.5985, LR: 0.000497\n  Batch [400/782], Loss: 1.4999, LR: 0.000497\n  Batch [500/782], Loss: 1.5573, LR: 0.000497\n  Batch [600/782], Loss: 1.5089, LR: 0.000497\n  Batch [700/782], Loss: 1.5774, LR: 0.000496\nEpoch [15/100] (42.5s), Loss: 1.6477, Train Acc: 47.27%, Test Acc: 57.17%, Best: 57.17%\n  Batch [0/782], Loss: 1.5696, LR: 0.000496\n  Batch [100/782], Loss: 1.7094, LR: 0.000496\n  Batch [200/782], Loss: 1.7240, LR: 0.000496\n  Batch [300/782], Loss: 1.6914, LR: 0.000496\n  Batch [400/782], Loss: 1.6365, LR: 0.000495\n  Batch [500/782], Loss: 1.5881, LR: 0.000495\n  Batch [600/782], Loss: 1.5914, LR: 0.000495\n  Batch [700/782], Loss: 1.7388, LR: 0.000495\nEpoch [16/100] (42.1s), Loss: 1.6358, Train Acc: 47.67%, Test Acc: 58.18%, Best: 58.18%\n  Batch [0/782], Loss: 1.7329, LR: 0.000495\n  Batch [100/782], Loss: 1.7468, LR: 0.000494\n  Batch [200/782], Loss: 1.6846, LR: 0.000494\n  Batch [300/782], Loss: 1.6968, LR: 0.000494\n  Batch [400/782], Loss: 1.4622, LR: 0.000494\n  Batch [500/782], Loss: 1.5510, LR: 0.000493\n  Batch [600/782], Loss: 1.4768, LR: 0.000493\n  Batch [700/782], Loss: 1.6171, LR: 0.000493\nEpoch [17/100] (42.4s), Loss: 1.6121, Train Acc: 48.71%, Test Acc: 57.27%, Best: 58.18%\n  Batch [0/782], Loss: 1.6161, LR: 0.000493\n  Batch [100/782], Loss: 1.6326, LR: 0.000492\n  Batch [200/782], Loss: 1.6403, LR: 0.000492\n  Batch [300/782], Loss: 1.5006, LR: 0.000492\n  Batch [400/782], Loss: 1.5861, LR: 0.000491\n  Batch [500/782], Loss: 1.7966, LR: 0.000491\n  Batch [600/782], Loss: 1.5931, LR: 0.000491\n  Batch [700/782], Loss: 1.4919, LR: 0.000491\nEpoch [18/100] (42.2s), Loss: 1.6001, Train Acc: 49.60%, Test Acc: 58.57%, Best: 58.57%\n  Batch [0/782], Loss: 1.6074, LR: 0.000490\n  Batch [100/782], Loss: 1.4706, LR: 0.000490\n  Batch [200/782], Loss: 1.6282, LR: 0.000490\n  Batch [300/782], Loss: 1.5230, LR: 0.000489\n  Batch [400/782], Loss: 1.6392, LR: 0.000489\n  Batch [500/782], Loss: 1.4621, LR: 0.000489\n  Batch [600/782], Loss: 1.4582, LR: 0.000488\n  Batch [700/782], Loss: 1.5327, LR: 0.000488\nEpoch [19/100] (42.6s), Loss: 1.5871, Train Acc: 50.12%, Test Acc: 60.11%, Best: 60.11%\n  Batch [0/782], Loss: 1.6135, LR: 0.000488\n  Batch [100/782], Loss: 1.6567, LR: 0.000487\n  Batch [200/782], Loss: 1.4034, LR: 0.000487\n  Batch [300/782], Loss: 1.5282, LR: 0.000487\n  Batch [400/782], Loss: 1.5589, LR: 0.000486\n  Batch [500/782], Loss: 1.6358, LR: 0.000486\n  Batch [600/782], Loss: 1.4449, LR: 0.000486\n  Batch [700/782], Loss: 1.6327, LR: 0.000485\nEpoch [20/100] (42.7s), Loss: 1.5667, Train Acc: 50.94%, Test Acc: 61.20%, Best: 61.20%\n  Batch [0/782], Loss: 1.5610, LR: 0.000485\n  Batch [100/782], Loss: 1.5383, LR: 0.000485\n  Batch [200/782], Loss: 1.6004, LR: 0.000484\n  Batch [300/782], Loss: 1.3955, LR: 0.000484\n  Batch [400/782], Loss: 1.4343, LR: 0.000483\n  Batch [500/782], Loss: 1.5732, LR: 0.000483\n  Batch [600/782], Loss: 1.8180, LR: 0.000483\n  Batch [700/782], Loss: 1.5649, LR: 0.000482\nEpoch [21/100] (42.6s), Loss: 1.5545, Train Acc: 51.46%, Test Acc: 60.92%, Best: 61.20%\n  Batch [0/782], Loss: 1.5945, LR: 0.000482\n  Batch [100/782], Loss: 1.5273, LR: 0.000481\n  Batch [200/782], Loss: 1.6721, LR: 0.000481\n  Batch [300/782], Loss: 1.6218, LR: 0.000481\n  Batch [400/782], Loss: 1.4853, LR: 0.000480\n  Batch [500/782], Loss: 1.3297, LR: 0.000480\n  Batch [600/782], Loss: 1.4557, LR: 0.000479\n  Batch [700/782], Loss: 1.4458, LR: 0.000479\nEpoch [22/100] (42.6s), Loss: 1.5468, Train Acc: 52.10%, Test Acc: 61.70%, Best: 61.70%\n  Batch [0/782], Loss: 1.7183, LR: 0.000478\n  Batch [100/782], Loss: 1.6207, LR: 0.000478\n  Batch [200/782], Loss: 1.6189, LR: 0.000477\n  Batch [300/782], Loss: 1.5460, LR: 0.000477\n  Batch [400/782], Loss: 1.6052, LR: 0.000477\n  Batch [500/782], Loss: 1.6054, LR: 0.000476\n  Batch [600/782], Loss: 1.5359, LR: 0.000476\n  Batch [700/782], Loss: 1.5460, LR: 0.000475\nEpoch [23/100] (43.0s), Loss: 1.5315, Train Acc: 52.79%, Test Acc: 62.43%, Best: 62.43%\n  Batch [0/782], Loss: 1.5182, LR: 0.000475\n  Batch [100/782], Loss: 1.4735, LR: 0.000474\n  Batch [200/782], Loss: 1.5314, LR: 0.000474\n  Batch [300/782], Loss: 1.4860, LR: 0.000473\n  Batch [400/782], Loss: 1.5582, LR: 0.000473\n  Batch [500/782], Loss: 1.8536, LR: 0.000472\n  Batch [600/782], Loss: 1.5164, LR: 0.000472\n  Batch [700/782], Loss: 1.4283, LR: 0.000471\nEpoch [24/100] (43.5s), Loss: 1.5179, Train Acc: 53.33%, Test Acc: 63.53%, Best: 63.53%\n  Batch [0/782], Loss: 1.5409, LR: 0.000471\n  Batch [100/782], Loss: 1.4670, LR: 0.000470\n  Batch [200/782], Loss: 1.5372, LR: 0.000470\n  Batch [300/782], Loss: 1.4807, LR: 0.000469\n  Batch [400/782], Loss: 1.5294, LR: 0.000469\n  Batch [500/782], Loss: 1.3879, LR: 0.000468\n  Batch [600/782], Loss: 1.4912, LR: 0.000468\n  Batch [700/782], Loss: 1.6233, LR: 0.000467\nEpoch [25/100] (43.0s), Loss: 1.5050, Train Acc: 53.95%, Test Acc: 64.20%, Best: 64.20%\n  Batch [0/782], Loss: 1.4692, LR: 0.000467\n  Batch [100/782], Loss: 1.5575, LR: 0.000466\n  Batch [200/782], Loss: 1.5775, LR: 0.000465\n  Batch [300/782], Loss: 1.5418, LR: 0.000465\n  Batch [400/782], Loss: 1.4696, LR: 0.000464\n  Batch [500/782], Loss: 1.4552, LR: 0.000464\n  Batch [600/782], Loss: 1.5011, LR: 0.000463\n  Batch [700/782], Loss: 1.6558, LR: 0.000462\nEpoch [26/100] (42.7s), Loss: 1.4964, Train Acc: 54.58%, Test Acc: 65.62%, Best: 65.62%\n  Batch [0/782], Loss: 1.3376, LR: 0.000462\n  Batch [100/782], Loss: 1.6354, LR: 0.000461\n  Batch [200/782], Loss: 1.3887, LR: 0.000461\n  Batch [300/782], Loss: 1.5691, LR: 0.000460\n  Batch [400/782], Loss: 1.5964, LR: 0.000460\n  Batch [500/782], Loss: 1.5668, LR: 0.000459\n  Batch [600/782], Loss: 1.4874, LR: 0.000458\n  Batch [700/782], Loss: 1.4778, LR: 0.000458\nEpoch [27/100] (43.4s), Loss: 1.4900, Train Acc: 55.01%, Test Acc: 65.63%, Best: 65.63%\n  Batch [0/782], Loss: 1.4251, LR: 0.000457\n  Batch [100/782], Loss: 1.6422, LR: 0.000457\n  Batch [200/782], Loss: 1.2545, LR: 0.000456\n  Batch [300/782], Loss: 1.3100, LR: 0.000455\n  Batch [400/782], Loss: 1.5663, LR: 0.000455\n  Batch [500/782], Loss: 1.4065, LR: 0.000454\n  Batch [600/782], Loss: 1.5172, LR: 0.000453\n  Batch [700/782], Loss: 1.4921, LR: 0.000453\nEpoch [28/100] (42.5s), Loss: 1.4766, Train Acc: 55.53%, Test Acc: 64.74%, Best: 65.63%\n  Batch [0/782], Loss: 1.4364, LR: 0.000452\n  Batch [100/782], Loss: 1.5841, LR: 0.000452\n  Batch [200/782], Loss: 1.5406, LR: 0.000451\n  Batch [300/782], Loss: 1.3474, LR: 0.000450\n  Batch [400/782], Loss: 1.4433, LR: 0.000450\n  Batch [500/782], Loss: 1.3130, LR: 0.000449\n  Batch [600/782], Loss: 1.4625, LR: 0.000448\n  Batch [700/782], Loss: 1.5574, LR: 0.000448\nEpoch [29/100] (42.7s), Loss: 1.4689, Train Acc: 55.77%, Test Acc: 67.06%, Best: 67.06%\n  Batch [0/782], Loss: 1.4499, LR: 0.000447\n  Batch [100/782], Loss: 1.3856, LR: 0.000446\n  Batch [200/782], Loss: 1.3118, LR: 0.000446\n  Batch [300/782], Loss: 1.5180, LR: 0.000445\n  Batch [400/782], Loss: 1.4162, LR: 0.000444\n  Batch [500/782], Loss: 1.4650, LR: 0.000444\n  Batch [600/782], Loss: 1.4350, LR: 0.000443\n  Batch [700/782], Loss: 1.4121, LR: 0.000442\nEpoch [30/100] (42.2s), Loss: 1.4575, Train Acc: 56.29%, Test Acc: 66.66%, Best: 67.06%\n  Batch [0/782], Loss: 1.6169, LR: 0.000442\n  Batch [100/782], Loss: 1.5085, LR: 0.000441\n  Batch [200/782], Loss: 1.2619, LR: 0.000440\n  Batch [300/782], Loss: 1.3846, LR: 0.000439\n  Batch [400/782], Loss: 1.3852, LR: 0.000439\n  Batch [500/782], Loss: 1.4282, LR: 0.000438\n  Batch [600/782], Loss: 1.7046, LR: 0.000437\n  Batch [700/782], Loss: 1.3557, LR: 0.000436\nEpoch [31/100] (42.9s), Loss: 1.4481, Train Acc: 57.10%, Test Acc: 67.15%, Best: 67.15%\n  Batch [0/782], Loss: 1.3804, LR: 0.000436\n  Batch [100/782], Loss: 1.2069, LR: 0.000435\n  Batch [200/782], Loss: 1.3865, LR: 0.000434\n  Batch [300/782], Loss: 1.3451, LR: 0.000434\n  Batch [400/782], Loss: 1.4483, LR: 0.000433\n  Batch [500/782], Loss: 1.4899, LR: 0.000432\n  Batch [600/782], Loss: 1.4965, LR: 0.000431\n  Batch [700/782], Loss: 1.4387, LR: 0.000430\nEpoch [32/100] (42.5s), Loss: 1.4341, Train Acc: 57.44%, Test Acc: 68.67%, Best: 68.67%\n  Batch [0/782], Loss: 1.1911, LR: 0.000430\n  Batch [100/782], Loss: 1.4546, LR: 0.000429\n  Batch [200/782], Loss: 1.3636, LR: 0.000428\n  Batch [300/782], Loss: 1.3141, LR: 0.000427\n  Batch [400/782], Loss: 1.3008, LR: 0.000427\n  Batch [500/782], Loss: 1.3373, LR: 0.000426\n  Batch [600/782], Loss: 1.3112, LR: 0.000425\n  Batch [700/782], Loss: 1.4085, LR: 0.000424\nEpoch [33/100] (42.6s), Loss: 1.4274, Train Acc: 57.91%, Test Acc: 68.98%, Best: 68.98%\n  Batch [0/782], Loss: 1.6175, LR: 0.000424\n  Batch [100/782], Loss: 1.4265, LR: 0.000423\n  Batch [200/782], Loss: 1.4068, LR: 0.000422\n  Batch [300/782], Loss: 1.5453, LR: 0.000421\n  Batch [400/782], Loss: 1.5021, LR: 0.000420\n  Batch [500/782], Loss: 1.4572, LR: 0.000420\n  Batch [600/782], Loss: 1.4744, LR: 0.000419\n  Batch [700/782], Loss: 1.4569, LR: 0.000418\nEpoch [34/100] (43.1s), Loss: 1.4169, Train Acc: 58.43%, Test Acc: 69.00%, Best: 69.00%\n  Batch [0/782], Loss: 1.3724, LR: 0.000417\n  Batch [100/782], Loss: 1.6114, LR: 0.000416\n  Batch [200/782], Loss: 1.2686, LR: 0.000416\n  Batch [300/782], Loss: 1.4060, LR: 0.000415\n  Batch [400/782], Loss: 1.2965, LR: 0.000414\n  Batch [500/782], Loss: 1.3518, LR: 0.000413\n  Batch [600/782], Loss: 1.5181, LR: 0.000412\n  Batch [700/782], Loss: 1.2580, LR: 0.000411\nEpoch [35/100] (42.8s), Loss: 1.4086, Train Acc: 58.73%, Test Acc: 70.01%, Best: 70.01%\n  Batch [0/782], Loss: 1.2703, LR: 0.000411\n  Batch [100/782], Loss: 1.3930, LR: 0.000410\n  Batch [200/782], Loss: 1.2940, LR: 0.000409\n  Batch [300/782], Loss: 1.4570, LR: 0.000408\n  Batch [400/782], Loss: 1.1768, LR: 0.000407\n  Batch [500/782], Loss: 1.4678, LR: 0.000406\n  Batch [600/782], Loss: 1.4160, LR: 0.000406\n  Batch [700/782], Loss: 1.4305, LR: 0.000405\nEpoch [36/100] (42.7s), Loss: 1.3981, Train Acc: 59.31%, Test Acc: 70.64%, Best: 70.64%\n  Batch [0/782], Loss: 1.4431, LR: 0.000404\n  Batch [100/782], Loss: 1.3442, LR: 0.000403\n  Batch [200/782], Loss: 1.4365, LR: 0.000402\n  Batch [300/782], Loss: 1.3475, LR: 0.000401\n  Batch [400/782], Loss: 1.4277, LR: 0.000400\n  Batch [500/782], Loss: 1.3320, LR: 0.000399\n  Batch [600/782], Loss: 1.5542, LR: 0.000399\n  Batch [700/782], Loss: 1.4434, LR: 0.000398\nEpoch [37/100] (42.5s), Loss: 1.3948, Train Acc: 59.29%, Test Acc: 70.95%, Best: 70.95%\n  Batch [0/782], Loss: 1.3542, LR: 0.000397\n  Batch [100/782], Loss: 1.2313, LR: 0.000396\n  Batch [200/782], Loss: 1.3148, LR: 0.000395\n  Batch [300/782], Loss: 1.2850, LR: 0.000394\n  Batch [400/782], Loss: 1.3994, LR: 0.000393\n  Batch [500/782], Loss: 1.3012, LR: 0.000392\n  Batch [600/782], Loss: 1.3077, LR: 0.000391\n  Batch [700/782], Loss: 1.3192, LR: 0.000391\nEpoch [38/100] (42.2s), Loss: 1.3798, Train Acc: 59.72%, Test Acc: 70.37%, Best: 70.95%\n  Batch [0/782], Loss: 1.5712, LR: 0.000390\n  Batch [100/782], Loss: 1.3080, LR: 0.000389\n  Batch [200/782], Loss: 1.4186, LR: 0.000388\n  Batch [300/782], Loss: 1.6977, LR: 0.000387\n  Batch [400/782], Loss: 1.3900, LR: 0.000386\n  Batch [500/782], Loss: 1.4025, LR: 0.000385\n  Batch [600/782], Loss: 1.3241, LR: 0.000384\n  Batch [700/782], Loss: 1.3956, LR: 0.000383\nEpoch [39/100] (42.6s), Loss: 1.3742, Train Acc: 60.63%, Test Acc: 71.21%, Best: 71.21%\n  Batch [0/782], Loss: 1.2688, LR: 0.000382\n  Batch [100/782], Loss: 1.4029, LR: 0.000382\n  Batch [200/782], Loss: 1.3557, LR: 0.000381\n  Batch [300/782], Loss: 1.3460, LR: 0.000380\n  Batch [400/782], Loss: 1.3123, LR: 0.000379\n  Batch [500/782], Loss: 1.1895, LR: 0.000378\n  Batch [600/782], Loss: 1.3788, LR: 0.000377\n  Batch [700/782], Loss: 1.2128, LR: 0.000376\nEpoch [40/100] (42.6s), Loss: 1.3615, Train Acc: 61.24%, Test Acc: 71.69%, Best: 71.69%\n  Batch [0/782], Loss: 1.5334, LR: 0.000375\n  Batch [100/782], Loss: 1.1751, LR: 0.000374\n  Batch [200/782], Loss: 1.2285, LR: 0.000373\n  Batch [300/782], Loss: 1.3256, LR: 0.000372\n  Batch [400/782], Loss: 1.1903, LR: 0.000371\n  Batch [500/782], Loss: 1.3245, LR: 0.000370\n  Batch [600/782], Loss: 1.6178, LR: 0.000369\n  Batch [700/782], Loss: 1.3927, LR: 0.000368\nEpoch [41/100] (41.9s), Loss: 1.3594, Train Acc: 61.14%, Test Acc: 71.24%, Best: 71.69%\n  Batch [0/782], Loss: 1.3869, LR: 0.000367\n  Batch [100/782], Loss: 1.4359, LR: 0.000366\n  Batch [200/782], Loss: 1.3264, LR: 0.000365\n  Batch [300/782], Loss: 1.3019, LR: 0.000364\n  Batch [400/782], Loss: 1.2982, LR: 0.000363\n  Batch [500/782], Loss: 1.3646, LR: 0.000362\n  Batch [600/782], Loss: 1.4075, LR: 0.000361\n  Batch [700/782], Loss: 1.2238, LR: 0.000360\nEpoch [42/100] (42.7s), Loss: 1.3432, Train Acc: 61.92%, Test Acc: 72.52%, Best: 72.52%\n  Batch [0/782], Loss: 1.1972, LR: 0.000360\n  Batch [100/782], Loss: 1.2635, LR: 0.000359\n  Batch [200/782], Loss: 1.5437, LR: 0.000358\n  Batch [300/782], Loss: 1.3826, LR: 0.000357\n  Batch [400/782], Loss: 1.2364, LR: 0.000356\n  Batch [500/782], Loss: 1.4741, LR: 0.000355\n  Batch [600/782], Loss: 1.2631, LR: 0.000354\n  Batch [700/782], Loss: 1.3437, LR: 0.000353\nEpoch [43/100] (42.6s), Loss: 1.3373, Train Acc: 62.27%, Test Acc: 73.12%, Best: 73.12%\n  Batch [0/782], Loss: 1.2999, LR: 0.000352\n  Batch [100/782], Loss: 1.2126, LR: 0.000351\n  Batch [200/782], Loss: 1.2994, LR: 0.000350\n  Batch [300/782], Loss: 1.2789, LR: 0.000349\n  Batch [400/782], Loss: 1.3589, LR: 0.000348\n  Batch [500/782], Loss: 1.3552, LR: 0.000347\n  Batch [600/782], Loss: 1.4670, LR: 0.000346\n  Batch [700/782], Loss: 1.2047, LR: 0.000344\nEpoch [44/100] (42.3s), Loss: 1.3290, Train Acc: 62.49%, Test Acc: 72.40%, Best: 73.12%\n  Batch [0/782], Loss: 1.4156, LR: 0.000344\n  Batch [100/782], Loss: 1.2651, LR: 0.000343\n  Batch [200/782], Loss: 1.3073, LR: 0.000342\n  Batch [300/782], Loss: 1.3681, LR: 0.000341\n  Batch [400/782], Loss: 1.1216, LR: 0.000339\n  Batch [500/782], Loss: 1.2021, LR: 0.000338\n  Batch [600/782], Loss: 1.3089, LR: 0.000337\n  Batch [700/782], Loss: 1.2576, LR: 0.000336\nEpoch [45/100] (43.2s), Loss: 1.3208, Train Acc: 62.85%, Test Acc: 73.62%, Best: 73.62%\n  Batch [0/782], Loss: 1.2377, LR: 0.000335\n  Batch [100/782], Loss: 1.2872, LR: 0.000334\n  Batch [200/782], Loss: 1.3230, LR: 0.000333\n  Batch [300/782], Loss: 1.2883, LR: 0.000332\n  Batch [400/782], Loss: 1.3611, LR: 0.000331\n  Batch [500/782], Loss: 1.2721, LR: 0.000330\n  Batch [600/782], Loss: 1.4775, LR: 0.000329\n  Batch [700/782], Loss: 1.2221, LR: 0.000328\nEpoch [46/100] (42.7s), Loss: 1.3078, Train Acc: 63.42%, Test Acc: 73.85%, Best: 73.85%\n  Batch [0/782], Loss: 1.3489, LR: 0.000327\n  Batch [100/782], Loss: 1.4316, LR: 0.000326\n  Batch [200/782], Loss: 1.2672, LR: 0.000325\n  Batch [300/782], Loss: 1.3739, LR: 0.000324\n  Batch [400/782], Loss: 1.5193, LR: 0.000323\n  Batch [500/782], Loss: 1.3689, LR: 0.000322\n  Batch [600/782], Loss: 1.2416, LR: 0.000321\n  Batch [700/782], Loss: 1.4838, LR: 0.000320\nEpoch [47/100] (42.1s), Loss: 1.2981, Train Acc: 63.93%, Test Acc: 73.81%, Best: 73.85%\n  Batch [0/782], Loss: 1.0871, LR: 0.000319\n  Batch [100/782], Loss: 1.4219, LR: 0.000318\n  Batch [200/782], Loss: 1.3101, LR: 0.000317\n  Batch [300/782], Loss: 1.1171, LR: 0.000316\n  Batch [400/782], Loss: 1.3678, LR: 0.000315\n  Batch [500/782], Loss: 1.3253, LR: 0.000314\n  Batch [600/782], Loss: 1.1714, LR: 0.000312\n  Batch [700/782], Loss: 1.1822, LR: 0.000311\nEpoch [48/100] (42.6s), Loss: 1.2900, Train Acc: 64.38%, Test Acc: 74.76%, Best: 74.76%\n  Batch [0/782], Loss: 1.2583, LR: 0.000310\n  Batch [100/782], Loss: 1.3368, LR: 0.000309\n  Batch [200/782], Loss: 1.2284, LR: 0.000308\n  Batch [300/782], Loss: 1.3303, LR: 0.000307\n  Batch [400/782], Loss: 1.4527, LR: 0.000306\n  Batch [500/782], Loss: 1.2544, LR: 0.000305\n  Batch [600/782], Loss: 1.1638, LR: 0.000304\n  Batch [700/782], Loss: 1.5095, LR: 0.000303\nEpoch [49/100] (42.6s), Loss: 1.2852, Train Acc: 64.41%, Test Acc: 74.76%, Best: 74.76%\n  Batch [0/782], Loss: 1.2969, LR: 0.000302\n  Batch [100/782], Loss: 1.2798, LR: 0.000301\n  Batch [200/782], Loss: 1.2482, LR: 0.000300\n  Batch [300/782], Loss: 1.3574, LR: 0.000299\n  Batch [400/782], Loss: 1.3040, LR: 0.000298\n  Batch [500/782], Loss: 1.1906, LR: 0.000296\n  Batch [600/782], Loss: 1.3306, LR: 0.000295\n  Batch [700/782], Loss: 1.3864, LR: 0.000294\nEpoch [50/100] (42.1s), Loss: 1.2805, Train Acc: 64.73%, Test Acc: 74.53%, Best: 74.76%\n  Batch [0/782], Loss: 1.3892, LR: 0.000293\n  Batch [100/782], Loss: 1.4834, LR: 0.000292\n  Batch [200/782], Loss: 1.2846, LR: 0.000291\n  Batch [300/782], Loss: 1.1956, LR: 0.000290\n  Batch [400/782], Loss: 1.2417, LR: 0.000289\n  Batch [500/782], Loss: 1.2550, LR: 0.000288\n  Batch [600/782], Loss: 1.4459, LR: 0.000287\n  Batch [700/782], Loss: 1.2240, LR: 0.000286\nEpoch [51/100] (42.9s), Loss: 1.2711, Train Acc: 65.11%, Test Acc: 75.46%, Best: 75.46%\n  Batch [0/782], Loss: 1.2366, LR: 0.000285\n  Batch [100/782], Loss: 1.4141, LR: 0.000284\n  Batch [200/782], Loss: 1.1298, LR: 0.000283\n  Batch [300/782], Loss: 1.2562, LR: 0.000281\n  Batch [400/782], Loss: 1.0168, LR: 0.000280\n  Batch [500/782], Loss: 1.2982, LR: 0.000279\n  Batch [600/782], Loss: 1.2944, LR: 0.000278\n  Batch [700/782], Loss: 1.2696, LR: 0.000277\nEpoch [52/100] (42.3s), Loss: 1.2653, Train Acc: 65.49%, Test Acc: 75.19%, Best: 75.46%\n  Batch [0/782], Loss: 1.2101, LR: 0.000276\n  Batch [100/782], Loss: 1.2123, LR: 0.000275\n  Batch [200/782], Loss: 1.3896, LR: 0.000274\n  Batch [300/782], Loss: 1.2583, LR: 0.000273\n  Batch [400/782], Loss: 1.3429, LR: 0.000272\n  Batch [500/782], Loss: 1.2622, LR: 0.000271\n  Batch [600/782], Loss: 0.9952, LR: 0.000269\n  Batch [700/782], Loss: 1.3246, LR: 0.000268\nEpoch [53/100] (42.6s), Loss: 1.2508, Train Acc: 66.13%, Test Acc: 75.60%, Best: 75.60%\n  Batch [0/782], Loss: 1.2755, LR: 0.000267\n  Batch [100/782], Loss: 1.3730, LR: 0.000266\n  Batch [200/782], Loss: 1.1219, LR: 0.000265\n  Batch [300/782], Loss: 1.3820, LR: 0.000264\n  Batch [400/782], Loss: 1.2408, LR: 0.000263\n  Batch [500/782], Loss: 1.4507, LR: 0.000262\n  Batch [600/782], Loss: 1.1730, LR: 0.000261\n  Batch [700/782], Loss: 1.1286, LR: 0.000260\nEpoch [54/100] (42.0s), Loss: 1.2472, Train Acc: 66.30%, Test Acc: 76.52%, Best: 76.52%\n  Batch [0/782], Loss: 1.2305, LR: 0.000259\n  Batch [100/782], Loss: 1.2642, LR: 0.000258\n  Batch [200/782], Loss: 1.2306, LR: 0.000256\n  Batch [300/782], Loss: 1.2023, LR: 0.000255\n  Batch [400/782], Loss: 1.3487, LR: 0.000254\n  Batch [500/782], Loss: 1.3842, LR: 0.000253\n  Batch [600/782], Loss: 1.1499, LR: 0.000252\n  Batch [700/782], Loss: 1.0764, LR: 0.000251\nEpoch [55/100] (42.3s), Loss: 1.2384, Train Acc: 66.69%, Test Acc: 75.99%, Best: 76.52%\n  Batch [0/782], Loss: 1.1440, LR: 0.000250\n  Batch [100/782], Loss: 1.2864, LR: 0.000249\n  Batch [200/782], Loss: 1.3782, LR: 0.000248\n  Batch [300/782], Loss: 1.2102, LR: 0.000247\n  Batch [400/782], Loss: 1.3075, LR: 0.000246\n  Batch [500/782], Loss: 1.0857, LR: 0.000244\n  Batch [600/782], Loss: 1.1981, LR: 0.000243\n  Batch [700/782], Loss: 1.3237, LR: 0.000242\nEpoch [56/100] (42.6s), Loss: 1.2298, Train Acc: 67.23%, Test Acc: 77.46%, Best: 77.46%\n  Batch [0/782], Loss: 1.2340, LR: 0.000241\n  Batch [100/782], Loss: 1.3065, LR: 0.000240\n  Batch [200/782], Loss: 1.2340, LR: 0.000239\n  Batch [300/782], Loss: 1.1472, LR: 0.000238\n  Batch [400/782], Loss: 1.2634, LR: 0.000237\n  Batch [500/782], Loss: 1.3734, LR: 0.000236\n  Batch [600/782], Loss: 1.2147, LR: 0.000235\n  Batch [700/782], Loss: 1.2870, LR: 0.000233\nEpoch [57/100] (42.2s), Loss: 1.2308, Train Acc: 67.08%, Test Acc: 76.69%, Best: 77.46%\n  Batch [0/782], Loss: 1.2993, LR: 0.000233\n  Batch [100/782], Loss: 1.1283, LR: 0.000231\n  Batch [200/782], Loss: 1.1401, LR: 0.000230\n  Batch [300/782], Loss: 1.1673, LR: 0.000229\n  Batch [400/782], Loss: 1.3098, LR: 0.000228\n  Batch [500/782], Loss: 1.1512, LR: 0.000227\n  Batch [600/782], Loss: 1.1569, LR: 0.000226\n  Batch [700/782], Loss: 1.2497, LR: 0.000225\nEpoch [58/100] (42.7s), Loss: 1.2114, Train Acc: 67.94%, Test Acc: 77.58%, Best: 77.58%\n  Batch [0/782], Loss: 1.3211, LR: 0.000224\n  Batch [100/782], Loss: 1.3363, LR: 0.000223\n  Batch [200/782], Loss: 1.1232, LR: 0.000222\n  Batch [300/782], Loss: 1.1928, LR: 0.000221\n  Batch [400/782], Loss: 1.1142, LR: 0.000219\n  Batch [500/782], Loss: 1.1500, LR: 0.000218\n  Batch [600/782], Loss: 1.2637, LR: 0.000217\n  Batch [700/782], Loss: 1.1729, LR: 0.000216\nEpoch [59/100] (42.4s), Loss: 1.2140, Train Acc: 67.63%, Test Acc: 77.42%, Best: 77.58%\n  Batch [0/782], Loss: 1.1970, LR: 0.000215\n  Batch [100/782], Loss: 1.3392, LR: 0.000214\n  Batch [200/782], Loss: 1.1777, LR: 0.000213\n  Batch [300/782], Loss: 1.3272, LR: 0.000212\n  Batch [400/782], Loss: 1.2767, LR: 0.000211\n  Batch [500/782], Loss: 1.2881, LR: 0.000210\n  Batch [600/782], Loss: 1.2239, LR: 0.000209\n  Batch [700/782], Loss: 1.4446, LR: 0.000207\nEpoch [60/100] (43.0s), Loss: 1.2030, Train Acc: 68.35%, Test Acc: 78.08%, Best: 78.08%\n  Batch [0/782], Loss: 1.1055, LR: 0.000207\n  Batch [100/782], Loss: 1.1539, LR: 0.000205\n  Batch [200/782], Loss: 1.2931, LR: 0.000204\n  Batch [300/782], Loss: 1.0878, LR: 0.000203\n  Batch [400/782], Loss: 1.1731, LR: 0.000202\n  Batch [500/782], Loss: 1.2144, LR: 0.000201\n  Batch [600/782], Loss: 1.1876, LR: 0.000200\n  Batch [700/782], Loss: 1.2107, LR: 0.000199\nEpoch [61/100] (42.8s), Loss: 1.1991, Train Acc: 68.58%, Test Acc: 77.41%, Best: 78.08%\n  Batch [0/782], Loss: 1.2061, LR: 0.000198\n  Batch [100/782], Loss: 1.0441, LR: 0.000197\n  Batch [200/782], Loss: 1.3055, LR: 0.000196\n  Batch [300/782], Loss: 1.0564, LR: 0.000195\n  Batch [400/782], Loss: 1.0481, LR: 0.000194\n  Batch [500/782], Loss: 1.1005, LR: 0.000193\n  Batch [600/782], Loss: 1.2404, LR: 0.000191\n  Batch [700/782], Loss: 0.9627, LR: 0.000190\nEpoch [62/100] (42.5s), Loss: 1.1861, Train Acc: 69.22%, Test Acc: 78.04%, Best: 78.08%\n  Batch [0/782], Loss: 1.0644, LR: 0.000190\n  Batch [100/782], Loss: 1.1754, LR: 0.000188\n  Batch [200/782], Loss: 1.2457, LR: 0.000187\n  Batch [300/782], Loss: 1.1216, LR: 0.000186\n  Batch [400/782], Loss: 1.2183, LR: 0.000185\n  Batch [500/782], Loss: 1.0268, LR: 0.000184\n  Batch [600/782], Loss: 1.1094, LR: 0.000183\n  Batch [700/782], Loss: 1.2336, LR: 0.000182\nEpoch [63/100] (43.1s), Loss: 1.1829, Train Acc: 69.18%, Test Acc: 78.07%, Best: 78.08%\n  Batch [0/782], Loss: 1.0975, LR: 0.000181\n  Batch [100/782], Loss: 1.1999, LR: 0.000180\n  Batch [200/782], Loss: 1.0913, LR: 0.000179\n  Batch [300/782], Loss: 0.9555, LR: 0.000178\n  Batch [400/782], Loss: 1.0617, LR: 0.000177\n  Batch [500/782], Loss: 1.1018, LR: 0.000176\n  Batch [600/782], Loss: 1.2061, LR: 0.000175\n  Batch [700/782], Loss: 1.1449, LR: 0.000174\nEpoch [64/100] (43.0s), Loss: 1.1717, Train Acc: 69.86%, Test Acc: 78.69%, Best: 78.69%\n  Batch [0/782], Loss: 1.1813, LR: 0.000173\n  Batch [100/782], Loss: 1.1279, LR: 0.000172\n  Batch [200/782], Loss: 1.0888, LR: 0.000171\n  Batch [300/782], Loss: 1.2689, LR: 0.000170\n  Batch [400/782], Loss: 1.1118, LR: 0.000169\n  Batch [500/782], Loss: 1.2725, LR: 0.000167\n  Batch [600/782], Loss: 1.1614, LR: 0.000166\n  Batch [700/782], Loss: 1.2822, LR: 0.000165\nEpoch [65/100] (42.8s), Loss: 1.1671, Train Acc: 69.89%, Test Acc: 79.37%, Best: 79.37%\n  Batch [0/782], Loss: 0.9633, LR: 0.000164\n  Batch [100/782], Loss: 1.0866, LR: 0.000163\n  Batch [200/782], Loss: 1.3743, LR: 0.000162\n  Batch [300/782], Loss: 1.2266, LR: 0.000161\n  Batch [400/782], Loss: 1.2165, LR: 0.000160\n  Batch [500/782], Loss: 1.0855, LR: 0.000159\n  Batch [600/782], Loss: 1.0754, LR: 0.000158\n  Batch [700/782], Loss: 1.2245, LR: 0.000157\nEpoch [66/100] (42.3s), Loss: 1.1624, Train Acc: 70.09%, Test Acc: 78.83%, Best: 79.37%\n  Batch [0/782], Loss: 1.0555, LR: 0.000156\n  Batch [100/782], Loss: 1.2987, LR: 0.000155\n  Batch [200/782], Loss: 1.0582, LR: 0.000154\n  Batch [300/782], Loss: 1.2470, LR: 0.000153\n  Batch [400/782], Loss: 1.1589, LR: 0.000152\n  Batch [500/782], Loss: 1.1090, LR: 0.000151\n  Batch [600/782], Loss: 1.1846, LR: 0.000150\n  Batch [700/782], Loss: 1.2005, LR: 0.000149\nEpoch [67/100] (42.1s), Loss: 1.1617, Train Acc: 70.03%, Test Acc: 79.32%, Best: 79.37%\n  Batch [0/782], Loss: 1.0745, LR: 0.000148\n  Batch [100/782], Loss: 1.1813, LR: 0.000147\n  Batch [200/782], Loss: 1.2649, LR: 0.000146\n  Batch [300/782], Loss: 1.1350, LR: 0.000145\n  Batch [400/782], Loss: 1.0193, LR: 0.000144\n  Batch [500/782], Loss: 0.9945, LR: 0.000143\n  Batch [600/782], Loss: 1.0510, LR: 0.000142\n  Batch [700/782], Loss: 1.1666, LR: 0.000141\nEpoch [68/100] (41.8s), Loss: 1.1472, Train Acc: 71.06%, Test Acc: 79.33%, Best: 79.37%\n  Batch [0/782], Loss: 1.1125, LR: 0.000140\n  Batch [100/782], Loss: 1.0481, LR: 0.000139\n  Batch [200/782], Loss: 1.2926, LR: 0.000138\n  Batch [300/782], Loss: 1.4028, LR: 0.000137\n  Batch [400/782], Loss: 1.1986, LR: 0.000136\n  Batch [500/782], Loss: 1.1920, LR: 0.000135\n  Batch [600/782], Loss: 1.0291, LR: 0.000134\n  Batch [700/782], Loss: 1.2385, LR: 0.000133\nEpoch [69/100] (42.4s), Loss: 1.1494, Train Acc: 70.73%, Test Acc: 79.66%, Best: 79.66%\n  Batch [0/782], Loss: 1.0798, LR: 0.000133\n  Batch [100/782], Loss: 1.1846, LR: 0.000132\n  Batch [200/782], Loss: 0.9450, LR: 0.000131\n  Batch [300/782], Loss: 1.2176, LR: 0.000130\n  Batch [400/782], Loss: 1.1225, LR: 0.000129\n  Batch [500/782], Loss: 1.2461, LR: 0.000128\n  Batch [600/782], Loss: 1.2964, LR: 0.000127\n  Batch [700/782], Loss: 1.0436, LR: 0.000126\nEpoch [70/100] (42.9s), Loss: 1.1348, Train Acc: 71.42%, Test Acc: 80.09%, Best: 80.09%\n  Batch [0/782], Loss: 0.8611, LR: 0.000125\n  Batch [100/782], Loss: 0.9263, LR: 0.000124\n  Batch [200/782], Loss: 1.1914, LR: 0.000123\n  Batch [300/782], Loss: 1.1727, LR: 0.000122\n  Batch [400/782], Loss: 1.1093, LR: 0.000121\n  Batch [500/782], Loss: 1.2336, LR: 0.000120\n  Batch [600/782], Loss: 1.0412, LR: 0.000119\n  Batch [700/782], Loss: 0.9803, LR: 0.000118\nEpoch [71/100] (42.4s), Loss: 1.1307, Train Acc: 71.46%, Test Acc: 79.71%, Best: 80.09%\n  Batch [0/782], Loss: 1.0941, LR: 0.000118\n  Batch [100/782], Loss: 1.1268, LR: 0.000117\n  Batch [200/782], Loss: 1.1066, LR: 0.000116\n  Batch [300/782], Loss: 1.1171, LR: 0.000115\n  Batch [400/782], Loss: 1.2194, LR: 0.000114\n  Batch [500/782], Loss: 1.1831, LR: 0.000113\n  Batch [600/782], Loss: 0.9857, LR: 0.000112\n  Batch [700/782], Loss: 1.2242, LR: 0.000111\nEpoch [72/100] (42.2s), Loss: 1.1276, Train Acc: 71.92%, Test Acc: 79.71%, Best: 80.09%\n  Batch [0/782], Loss: 1.0812, LR: 0.000110\n  Batch [100/782], Loss: 1.0390, LR: 0.000109\n  Batch [200/782], Loss: 1.1941, LR: 0.000108\n  Batch [300/782], Loss: 1.1581, LR: 0.000107\n  Batch [400/782], Loss: 0.9915, LR: 0.000107\n  Batch [500/782], Loss: 1.2051, LR: 0.000106\n  Batch [600/782], Loss: 1.2445, LR: 0.000105\n  Batch [700/782], Loss: 0.9555, LR: 0.000104\nEpoch [73/100] (42.6s), Loss: 1.1198, Train Acc: 72.24%, Test Acc: 80.33%, Best: 80.33%\n  Batch [0/782], Loss: 1.0886, LR: 0.000103\n  Batch [100/782], Loss: 1.1343, LR: 0.000102\n  Batch [200/782], Loss: 1.0297, LR: 0.000101\n  Batch [300/782], Loss: 1.0854, LR: 0.000100\n  Batch [400/782], Loss: 1.2932, LR: 0.000099\n  Batch [500/782], Loss: 1.0579, LR: 0.000099\n  Batch [600/782], Loss: 1.1364, LR: 0.000098\n  Batch [700/782], Loss: 1.2612, LR: 0.000097\nEpoch [74/100] (42.8s), Loss: 1.1147, Train Acc: 72.37%, Test Acc: 80.64%, Best: 80.64%\n  Batch [0/782], Loss: 1.1940, LR: 0.000096\n  Batch [100/782], Loss: 1.1890, LR: 0.000095\n  Batch [200/782], Loss: 1.0398, LR: 0.000094\n  Batch [300/782], Loss: 1.1172, LR: 0.000093\n  Batch [400/782], Loss: 1.0527, LR: 0.000093\n  Batch [500/782], Loss: 1.0303, LR: 0.000092\n  Batch [600/782], Loss: 1.0943, LR: 0.000091\n  Batch [700/782], Loss: 1.0709, LR: 0.000090\nEpoch [75/100] (42.9s), Loss: 1.1114, Train Acc: 72.46%, Test Acc: 80.57%, Best: 80.64%\n  Batch [0/782], Loss: 0.9486, LR: 0.000089\n  Batch [100/782], Loss: 1.0980, LR: 0.000088\n  Batch [200/782], Loss: 1.1122, LR: 0.000088\n  Batch [300/782], Loss: 1.1650, LR: 0.000087\n  Batch [400/782], Loss: 1.0656, LR: 0.000086\n  Batch [500/782], Loss: 1.0995, LR: 0.000085\n  Batch [600/782], Loss: 1.0938, LR: 0.000084\n  Batch [700/782], Loss: 1.0676, LR: 0.000083\nEpoch [76/100] (43.5s), Loss: 1.1060, Train Acc: 72.85%, Test Acc: 80.75%, Best: 80.75%\n  Batch [0/782], Loss: 1.2911, LR: 0.000083\n  Batch [100/782], Loss: 1.0578, LR: 0.000082\n  Batch [200/782], Loss: 1.1599, LR: 0.000081\n  Batch [300/782], Loss: 1.1221, LR: 0.000080\n  Batch [400/782], Loss: 1.1957, LR: 0.000079\n  Batch [500/782], Loss: 1.0688, LR: 0.000079\n  Batch [600/782], Loss: 0.9966, LR: 0.000078\n  Batch [700/782], Loss: 0.9646, LR: 0.000077\nEpoch [77/100] (42.6s), Loss: 1.1011, Train Acc: 73.19%, Test Acc: 81.18%, Best: 81.18%\n  Batch [0/782], Loss: 1.1866, LR: 0.000076\n  Batch [100/782], Loss: 0.9559, LR: 0.000076\n  Batch [200/782], Loss: 1.0302, LR: 0.000075\n  Batch [300/782], Loss: 1.1188, LR: 0.000074\n  Batch [400/782], Loss: 1.1065, LR: 0.000073\n  Batch [500/782], Loss: 1.0234, LR: 0.000072\n  Batch [600/782], Loss: 1.0882, LR: 0.000072\n  Batch [700/782], Loss: 1.0476, LR: 0.000071\nEpoch [78/100] (42.2s), Loss: 1.0942, Train Acc: 73.59%, Test Acc: 81.59%, Best: 81.59%\n  Batch [0/782], Loss: 1.1881, LR: 0.000070\n  Batch [100/782], Loss: 1.1397, LR: 0.000069\n  Batch [200/782], Loss: 1.1759, LR: 0.000069\n  Batch [300/782], Loss: 1.0174, LR: 0.000068\n  Batch [400/782], Loss: 1.0506, LR: 0.000067\n  Batch [500/782], Loss: 1.0046, LR: 0.000066\n  Batch [600/782], Loss: 1.3634, LR: 0.000066\n  Batch [700/782], Loss: 1.1358, LR: 0.000065\nEpoch [79/100] (41.8s), Loss: 1.0945, Train Acc: 73.33%, Test Acc: 80.99%, Best: 81.59%\n  Batch [0/782], Loss: 1.2483, LR: 0.000064\n  Batch [100/782], Loss: 1.0344, LR: 0.000063\n  Batch [200/782], Loss: 0.9564, LR: 0.000063\n  Batch [300/782], Loss: 1.0905, LR: 0.000062\n  Batch [400/782], Loss: 1.0488, LR: 0.000061\n  Batch [500/782], Loss: 1.0580, LR: 0.000061\n  Batch [600/782], Loss: 1.0821, LR: 0.000060\n  Batch [700/782], Loss: 0.9934, LR: 0.000059\nEpoch [80/100] (41.7s), Loss: 1.0872, Train Acc: 73.68%, Test Acc: 81.13%, Best: 81.59%\n  Batch [0/782], Loss: 1.2119, LR: 0.000058\n  Batch [100/782], Loss: 1.1121, LR: 0.000058\n  Batch [200/782], Loss: 1.1861, LR: 0.000057\n  Batch [300/782], Loss: 1.1493, LR: 0.000056\n  Batch [400/782], Loss: 1.0679, LR: 0.000056\n  Batch [500/782], Loss: 1.2782, LR: 0.000055\n  Batch [600/782], Loss: 1.0996, LR: 0.000054\n  Batch [700/782], Loss: 1.1924, LR: 0.000054\nEpoch [81/100] (41.4s), Loss: 1.0826, Train Acc: 73.94%, Test Acc: 81.46%, Best: 81.59%\n  Batch [0/782], Loss: 1.0001, LR: 0.000053\n  Batch [100/782], Loss: 1.1307, LR: 0.000052\n  Batch [200/782], Loss: 1.1388, LR: 0.000052\n  Batch [300/782], Loss: 1.1652, LR: 0.000051\n  Batch [400/782], Loss: 1.2851, LR: 0.000050\n  Batch [500/782], Loss: 0.9572, LR: 0.000050\n  Batch [600/782], Loss: 1.3996, LR: 0.000049\n  Batch [700/782], Loss: 0.9577, LR: 0.000048\nEpoch [82/100] (41.6s), Loss: 1.0811, Train Acc: 73.86%, Test Acc: 81.58%, Best: 81.59%\n  Batch [0/782], Loss: 1.0214, LR: 0.000048\n  Batch [100/782], Loss: 1.1361, LR: 0.000047\n  Batch [200/782], Loss: 1.0909, LR: 0.000046\n  Batch [300/782], Loss: 1.0466, LR: 0.000046\n  Batch [400/782], Loss: 0.9577, LR: 0.000045\n  Batch [500/782], Loss: 0.9690, LR: 0.000045\n  Batch [600/782], Loss: 1.0374, LR: 0.000044\n  Batch [700/782], Loss: 1.1150, LR: 0.000043\nEpoch [83/100] (41.6s), Loss: 1.0770, Train Acc: 74.26%, Test Acc: 81.82%, Best: 81.82%\n  Batch [0/782], Loss: 0.9892, LR: 0.000043\n  Batch [100/782], Loss: 1.0599, LR: 0.000042\n  Batch [200/782], Loss: 1.2814, LR: 0.000041\n  Batch [300/782], Loss: 1.0253, LR: 0.000041\n  Batch [400/782], Loss: 1.1511, LR: 0.000040\n  Batch [500/782], Loss: 1.0936, LR: 0.000040\n  Batch [600/782], Loss: 1.0770, LR: 0.000039\n  Batch [700/782], Loss: 1.1664, LR: 0.000038\nEpoch [84/100] (42.0s), Loss: 1.0742, Train Acc: 74.34%, Test Acc: 81.66%, Best: 81.82%\n  Batch [0/782], Loss: 1.1065, LR: 0.000038\n  Batch [100/782], Loss: 1.0345, LR: 0.000037\n  Batch [200/782], Loss: 1.3600, LR: 0.000037\n  Batch [300/782], Loss: 1.2287, LR: 0.000036\n  Batch [400/782], Loss: 0.9559, LR: 0.000036\n  Batch [500/782], Loss: 1.1235, LR: 0.000035\n  Batch [600/782], Loss: 1.0917, LR: 0.000035\n  Batch [700/782], Loss: 1.1056, LR: 0.000034\nEpoch [85/100] (42.0s), Loss: 1.0730, Train Acc: 74.27%, Test Acc: 81.69%, Best: 81.82%\n  Batch [0/782], Loss: 1.0074, LR: 0.000033\n  Batch [100/782], Loss: 1.0050, LR: 0.000033\n  Batch [200/782], Loss: 1.2063, LR: 0.000032\n  Batch [300/782], Loss: 1.0339, LR: 0.000032\n  Batch [400/782], Loss: 1.0581, LR: 0.000031\n  Batch [500/782], Loss: 1.1549, LR: 0.000031\n  Batch [600/782], Loss: 1.1551, LR: 0.000030\n  Batch [700/782], Loss: 1.1114, LR: 0.000030\nEpoch [86/100] (42.6s), Loss: 1.0706, Train Acc: 74.39%, Test Acc: 82.27%, Best: 82.27%\n  Batch [0/782], Loss: 1.0454, LR: 0.000029\n  Batch [100/782], Loss: 1.0147, LR: 0.000029\n  Batch [200/782], Loss: 1.0905, LR: 0.000028\n  Batch [300/782], Loss: 1.0131, LR: 0.000028\n  Batch [400/782], Loss: 1.1017, LR: 0.000027\n  Batch [500/782], Loss: 1.1777, LR: 0.000027\n  Batch [600/782], Loss: 0.9514, LR: 0.000026\n  Batch [700/782], Loss: 1.0797, LR: 0.000026\nEpoch [87/100] (42.0s), Loss: 1.0609, Train Acc: 74.71%, Test Acc: 82.00%, Best: 82.27%\n  Batch [0/782], Loss: 1.0631, LR: 0.000025\n  Batch [100/782], Loss: 0.8728, LR: 0.000025\n  Batch [200/782], Loss: 1.0764, LR: 0.000024\n  Batch [300/782], Loss: 1.0333, LR: 0.000024\n  Batch [400/782], Loss: 0.9724, LR: 0.000023\n  Batch [500/782], Loss: 1.0896, LR: 0.000023\n  Batch [600/782], Loss: 1.2040, LR: 0.000022\n  Batch [700/782], Loss: 0.9181, LR: 0.000022\nEpoch [88/100] (41.8s), Loss: 1.0645, Train Acc: 74.94%, Test Acc: 82.06%, Best: 82.27%\n  Batch [0/782], Loss: 1.2322, LR: 0.000022\n  Batch [100/782], Loss: 1.1715, LR: 0.000021\n  Batch [200/782], Loss: 0.9555, LR: 0.000021\n  Batch [300/782], Loss: 0.9969, LR: 0.000020\n  Batch [400/782], Loss: 1.0251, LR: 0.000020\n  Batch [500/782], Loss: 0.9192, LR: 0.000019\n  Batch [600/782], Loss: 1.2435, LR: 0.000019\n  Batch [700/782], Loss: 0.9467, LR: 0.000019\nEpoch [89/100] (41.9s), Loss: 1.0621, Train Acc: 74.86%, Test Acc: 82.36%, Best: 82.36%\n  Batch [0/782], Loss: 0.9650, LR: 0.000018\n  Batch [100/782], Loss: 1.0426, LR: 0.000018\n  Batch [200/782], Loss: 1.1220, LR: 0.000017\n  Batch [300/782], Loss: 1.1101, LR: 0.000017\n  Batch [400/782], Loss: 1.0228, LR: 0.000017\n  Batch [500/782], Loss: 0.9323, LR: 0.000016\n  Batch [600/782], Loss: 1.1137, LR: 0.000016\n  Batch [700/782], Loss: 0.9973, LR: 0.000015\nEpoch [90/100] (42.2s), Loss: 1.0634, Train Acc: 74.89%, Test Acc: 82.11%, Best: 82.36%\n  Batch [0/782], Loss: 1.2074, LR: 0.000015\n  Batch [100/782], Loss: 1.0859, LR: 0.000015\n  Batch [200/782], Loss: 1.0220, LR: 0.000014\n  Batch [300/782], Loss: 1.1380, LR: 0.000014\n  Batch [400/782], Loss: 1.0765, LR: 0.000014\n  Batch [500/782], Loss: 1.0063, LR: 0.000013\n  Batch [600/782], Loss: 1.1162, LR: 0.000013\n  Batch [700/782], Loss: 0.9560, LR: 0.000013\nEpoch [91/100] (42.2s), Loss: 1.0587, Train Acc: 74.95%, Test Acc: 82.15%, Best: 82.36%\n  Batch [0/782], Loss: 1.2464, LR: 0.000012\n  Batch [100/782], Loss: 1.0379, LR: 0.000012\n  Batch [200/782], Loss: 1.1053, LR: 0.000012\n  Batch [300/782], Loss: 1.0778, LR: 0.000011\n  Batch [400/782], Loss: 1.1157, LR: 0.000011\n  Batch [500/782], Loss: 1.1028, LR: 0.000011\n  Batch [600/782], Loss: 0.8836, LR: 0.000010\n  Batch [700/782], Loss: 1.1646, LR: 0.000010\nEpoch [92/100] (42.6s), Loss: 1.0531, Train Acc: 75.30%, Test Acc: 82.16%, Best: 82.36%\n  Batch [0/782], Loss: 0.9500, LR: 0.000010\n  Batch [100/782], Loss: 1.1370, LR: 0.000009\n  Batch [200/782], Loss: 1.0420, LR: 0.000009\n  Batch [300/782], Loss: 1.0848, LR: 0.000009\n  Batch [400/782], Loss: 1.0524, LR: 0.000008\n  Batch [500/782], Loss: 1.1081, LR: 0.000008\n  Batch [600/782], Loss: 1.1488, LR: 0.000008\n  Batch [700/782], Loss: 0.9483, LR: 0.000008\nEpoch [93/100] (42.6s), Loss: 1.0503, Train Acc: 75.37%, Test Acc: 82.39%, Best: 82.39%\n  Batch [0/782], Loss: 1.1285, LR: 0.000007\n  Batch [100/782], Loss: 0.8692, LR: 0.000007\n  Batch [200/782], Loss: 1.0810, LR: 0.000007\n  Batch [300/782], Loss: 1.1285, LR: 0.000007\n  Batch [400/782], Loss: 1.0609, LR: 0.000006\n  Batch [500/782], Loss: 0.9559, LR: 0.000006\n  Batch [600/782], Loss: 1.0764, LR: 0.000006\n  Batch [700/782], Loss: 0.9170, LR: 0.000006\nEpoch [94/100] (41.5s), Loss: 1.0559, Train Acc: 75.07%, Test Acc: 82.25%, Best: 82.39%\n  Batch [0/782], Loss: 1.0133, LR: 0.000005\n  Batch [100/782], Loss: 1.1588, LR: 0.000005\n  Batch [200/782], Loss: 1.0774, LR: 0.000005\n  Batch [300/782], Loss: 1.1025, LR: 0.000005\n  Batch [400/782], Loss: 1.2725, LR: 0.000005\n  Batch [500/782], Loss: 1.0687, LR: 0.000004\n  Batch [600/782], Loss: 1.0273, LR: 0.000004\n  Batch [700/782], Loss: 1.0629, LR: 0.000004\nEpoch [95/100] (41.5s), Loss: 1.0517, Train Acc: 75.22%, Test Acc: 82.23%, Best: 82.39%\n  Batch [0/782], Loss: 1.1635, LR: 0.000004\n  Batch [100/782], Loss: 1.1091, LR: 0.000004\n  Batch [200/782], Loss: 1.0534, LR: 0.000003\n  Batch [300/782], Loss: 1.2575, LR: 0.000003\n  Batch [400/782], Loss: 1.2131, LR: 0.000003\n  Batch [500/782], Loss: 1.2091, LR: 0.000003\n  Batch [600/782], Loss: 0.9778, LR: 0.000003\n  Batch [700/782], Loss: 1.0137, LR: 0.000003\nEpoch [96/100] (40.8s), Loss: 1.0541, Train Acc: 75.06%, Test Acc: 82.32%, Best: 82.39%\n  Batch [0/782], Loss: 0.9372, LR: 0.000002\n  Batch [100/782], Loss: 1.0729, LR: 0.000002\n  Batch [200/782], Loss: 0.9257, LR: 0.000002\n  Batch [300/782], Loss: 0.9942, LR: 0.000002\n  Batch [400/782], Loss: 1.0798, LR: 0.000002\n  Batch [500/782], Loss: 1.0439, LR: 0.000002\n  Batch [600/782], Loss: 0.8759, LR: 0.000002\n  Batch [700/782], Loss: 0.9906, LR: 0.000001\nEpoch [97/100] (41.4s), Loss: 1.0499, Train Acc: 75.30%, Test Acc: 82.31%, Best: 82.39%\n  Batch [0/782], Loss: 1.1113, LR: 0.000001\n  Batch [100/782], Loss: 0.9578, LR: 0.000001\n  Batch [200/782], Loss: 0.9997, LR: 0.000001\n  Batch [300/782], Loss: 1.0914, LR: 0.000001\n  Batch [400/782], Loss: 1.1310, LR: 0.000001\n  Batch [500/782], Loss: 1.0629, LR: 0.000001\n  Batch [600/782], Loss: 1.1663, LR: 0.000001\n  Batch [700/782], Loss: 1.0978, LR: 0.000001\nEpoch [98/100] (41.1s), Loss: 1.0476, Train Acc: 75.49%, Test Acc: 82.29%, Best: 82.39%\n  Batch [0/782], Loss: 1.1301, LR: 0.000001\n  Batch [100/782], Loss: 0.9714, LR: 0.000001\n  Batch [200/782], Loss: 1.0523, LR: 0.000000\n  Batch [300/782], Loss: 1.0503, LR: 0.000000\n  Batch [400/782], Loss: 1.0831, LR: 0.000000\n  Batch [500/782], Loss: 1.0720, LR: 0.000000\n  Batch [600/782], Loss: 1.1446, LR: 0.000000\n  Batch [700/782], Loss: 1.0488, LR: 0.000000\nEpoch [99/100] (41.2s), Loss: 1.0518, Train Acc: 75.21%, Test Acc: 82.24%, Best: 82.39%\n  Batch [0/782], Loss: 1.0344, LR: 0.000000\n  Batch [100/782], Loss: 1.0333, LR: 0.000000\n  Batch [200/782], Loss: 1.0272, LR: 0.000000\n  Batch [300/782], Loss: 1.0813, LR: 0.000000\n  Batch [400/782], Loss: 1.1753, LR: 0.000000\n  Batch [500/782], Loss: 1.1059, LR: 0.000000\n  Batch [600/782], Loss: 1.0846, LR: 0.000000\n  Batch [700/782], Loss: 1.2007, LR: 0.000000\nEpoch [100/100] (42.0s), Loss: 1.0496, Train Acc: 75.41%, Test Acc: 82.26%, Best: 82.39%\nTraining completed! Best Test Accuracy: 82.39%\nApplying post-training quantization...\nCalibrating quantized model...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/observer.py:229: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1301805251.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/1301805251.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;31m# Apply post-training quantization if enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_after_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_post_training_quantization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;31m# Plot comprehensive results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1301805251.py\u001b[0m in \u001b[0;36mapply_post_training_quantization\u001b[0;34m(model, test_loader, config)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;31m# Convert to quantized model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mmodel_quantized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_prepared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;31m# Test quantized model accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/quantize.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(module, mapping, inplace, remove_qconfig, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m     _convert(\n\u001b[0m\u001b[1;32m    658\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/quantize.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mtype_before_parametrizations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcustom_module_class_mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         ):\n\u001b[0;32m--> 714\u001b[0;31m             _convert(\n\u001b[0m\u001b[1;32m    715\u001b[0m                 \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/quantize.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, is_reference, convert_custom_config_dict, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0muse_precomputed_fake_quant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_precomputed_fake_quant\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             )\n\u001b[0;32m--> 722\u001b[0;31m         reassign[name] = swap_module(\n\u001b[0m\u001b[1;32m    723\u001b[0m             \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_module_class_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_precomputed_fake_quant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/quantize.py\u001b[0m in \u001b[0;36mswap_module\u001b[0;34m(mod, mapping, custom_module_class_mapping, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    762\u001b[0m                 \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"use_precomputed_fake_quant\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                     new_mod = qmod.from_float(\n\u001b[0m\u001b[1;32m    765\u001b[0m                         \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_precomputed_fake_quant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_precomputed_fake_quant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                     )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/ao/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36mfrom_float\u001b[0;34m(cls, mod, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    604\u001b[0m               \u001b[0mutilities\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \"\"\"\n\u001b[0;32m--> 606\u001b[0;31m         return _ConvNd.from_float(\n\u001b[0m\u001b[1;32m    607\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_precomputed_fake_quant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_precomputed_fake_quant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/ao/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36mfrom_float\u001b[0;34m(cls, mod, use_precomputed_fake_quant)\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mweight_post_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_qconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_post_process\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_post_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/ao/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36mget_qconv\u001b[0;34m(cls, mod, activation_post_process, weight_post_process)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         )\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mqconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weight_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         if (\n\u001b[1;32m    268\u001b[0m             \u001b[0mactivation_post_process\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/ao/nn/quantized/modules/conv.py\u001b[0m in \u001b[0;36mset_weight_bias\u001b[0;34m(self, w, b)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_weight_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"zeros\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             self._packed_params = torch.ops.quantized.conv2d_prepack(\n\u001b[0m\u001b[1;32m    568\u001b[0m                 \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_torchbind_op_overload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_overload_packet_from_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Unsupported qscheme: per_channel_affine"],"ename":"RuntimeError","evalue":"Unsupported qscheme: per_channel_affine","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport numpy as np\nimport math\nimport os\nimport json\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, datasets\nimport time\n\n# Configuration\nclass Config:\n    # Hardware settings - Use GPU if available for training speed\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Model architecture (optimized for hardware but realistic)\n    img_size = 32  # Better resolution for accuracy\n    patch_size = 8\n    embed_dim = 256  # Reasonable size for good performance\n    depth = 6      # Good depth for accuracy\n    num_heads = 8\n    mlp_ratio = 3.0\n    \n    # Training settings - optimized for full dataset\n    batch_size = 512\n    num_epochs = 100  # Reduced since we're using PyTorch optimization\n    learning_rate = 0.001\n    weight_decay = 0.05\n    \n    # Quantization settings\n    weight_bits = 8\n    activation_bits = 8\n    \n    # Export settings\n    export_dir = \"rtl_export\"\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\n# ============================================================================\n# CUSTOM MATHEMATICAL OPERATIONS FOR RTL EXPORT\n# ============================================================================\n\ndef custom_relu(x):\n    \"\"\"Custom ReLU activation \"\"\"\n    return np.maximum(0, x)\n\ndef custom_gelu(x):\n    \"\"\"Custom GELU activation \"\"\"\n    return 0.5 * x * (1 + np.tanh(np.sqrt(2/np.pi) * (x + 0.044715 * x**3)))\n\ndef custom_softmax(x, axis=-1):\n    \"\"\"Custom softmax with numerical stability\"\"\"\n    x_shifted = x - np.max(x, axis=axis, keepdims=True)\n    exp_x = np.exp(x_shifted)\n    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n\ndef custom_layer_norm(x, weight, bias, eps=1e-5):\n    \"\"\"Custom Layer Normalization\"\"\"\n    mean = np.mean(x, axis=-1, keepdims=True)\n    var = np.var(x, axis=-1, keepdims=True)\n    x_norm = (x - mean) / np.sqrt(var + eps)\n    return x_norm * weight + bias\n\ndef custom_conv2d(input_data, weight, bias=None, stride=1, padding=0):\n    \"\"\"Custom 2D convolution \"\"\"\n    batch, in_ch, in_h, in_w = input_data.shape\n    out_ch, _, k_h, k_w = weight.shape\n    \n    # Add padding\n    if padding > 0:\n        input_padded = np.pad(input_data, ((0,0), (0,0), (padding,padding), (padding,padding)), 'constant')\n    else:\n        input_padded = input_data\n    \n    out_h = (in_h + 2*padding - k_h) // stride + 1\n    out_w = (in_w + 2*padding - k_w) // stride + 1\n    output = np.zeros((batch, out_ch, out_h, out_w))\n    \n    for b in range(batch):\n        for oc in range(out_ch):\n            for oh in range(out_h):\n                for ow in range(out_w):\n                    h_start = oh * stride\n                    w_start = ow * stride\n                    patch = input_padded[b, :, h_start:h_start+k_h, w_start:w_start+k_w]\n                    output[b, oc, oh, ow] = np.sum(patch * weight[oc])\n                    if bias is not None:\n                        output[b, oc, oh, ow] += bias[oc]\n    \n    return output\n\ndef custom_linear(input_data, weight, bias=None):\n    \"\"\"Custom linear layer \"\"\"\n    output = np.dot(input_data, weight.T)\n    if bias is not None:\n        output += bias\n    return output\n\ndef custom_dropout(x, p=0.1, training=True):\n    \"\"\"Custom dropout \"\"\"\n    if not training or p == 0:\n        return x\n    mask = np.random.binomial(1, 1-p, x.shape) / (1-p)\n    return x * mask\n\n# ============================================================================\n# PYTORCH VISION TRANSFORMER FOR TRAINING\n# ============================================================================\n\nclass PatchEmbedding(nn.Module):\n    def __init__(self, img_size, patch_size, in_channels, embed_dim):\n        super().__init__()\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.num_patches = (img_size // patch_size) ** 2\n        \n        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n        \n    def forward(self, x):\n        x = self.proj(x)  # (B, E, H/P, W/P)\n        x = x.flatten(2)  # (B, E, N)\n        x = x.transpose(1, 2)  # (B, N, E)\n        return x\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n        self.proj = nn.Linear(embed_dim, embed_dim)\n        self.attn_dropout = nn.Dropout(0.1)\n        self.proj_dropout = nn.Dropout(0.1)\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = attn.softmax(dim=-1)\n        attn = self.attn_dropout(attn)\n        \n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_dropout(x)\n        return x\n\nclass MLP(nn.Module):\n    def __init__(self, in_features, hidden_features):\n        super().__init__()\n        self.fc1 = nn.Linear(in_features, hidden_features)\n        self.act = nn.GELU()\n        self.fc2 = nn.Linear(hidden_features, in_features)\n        self.dropout = nn.Dropout(0.1)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        x = self.dropout(x)\n        return x\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4.0):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(dim)\n        self.attn = MultiHeadAttention(dim, num_heads)\n        self.norm2 = nn.LayerNorm(dim)\n        self.mlp = MLP(dim, int(dim * mlp_ratio))\n        \n    def forward(self, x):\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nclass ViT(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=3.0):\n        super().__init__()\n        \n        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        num_patches = (img_size // patch_size) ** 2\n        \n        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n        self.pos_dropout = nn.Dropout(0.1)\n        \n        self.blocks = nn.ModuleList([\n            TransformerBlock(embed_dim, num_heads, mlp_ratio) for _ in range(depth)\n        ])\n        \n        self.norm = nn.LayerNorm(embed_dim)\n        self.head = nn.Linear(embed_dim, num_classes)\n        \n        # Initialize weights\n        self.apply(self._init_weights)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.LayerNorm):\n            torch.nn.init.zeros_(module.bias)\n            torch.nn.init.ones_(module.weight)\n        elif isinstance(module, nn.Conv2d):\n            torch.nn.init.normal_(module.weight, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n                \n    def forward(self, x):\n        x = self.patch_embed(x)\n        x = x + self.pos_embed\n        x = self.pos_dropout(x)\n        \n        for block in self.blocks:\n            x = block(x)\n            \n        x = self.norm(x)\n        x = x.mean(dim=1)  # Global average pooling\n        x = self.head(x)\n        return x\n\n# ============================================================================\n# DATA LOADING AND PREPROCESSING\n# ============================================================================\n\ndef load_cifar10_data():\n    \"\"\"Load CIFAR-10 data with GPU support\"\"\"\n    train_transform = transforms.Compose([\n        transforms.Resize((config.img_size, config.img_size)),\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomCrop(config.img_size, padding=4, padding_mode='reflect'),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n    ])\n    \n    test_transform = transforms.Compose([\n        transforms.Resize((config.img_size, config.img_size)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n    ])\n    \n    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n    \n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2\n    )\n    \n    test_loader = torch.utils.data.DataLoader(\n        test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2\n    )\n    \n    return train_loader, test_loader\n\n# ============================================================================\n# TRAINING WITH PYTORCH\n# ============================================================================\n\ndef train_pytorch_model(model, train_loader, test_loader, config):\n    \"\"\"Train the PyTorch ViT model\"\"\"\n    model.to(config.device)\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.num_epochs)\n    \n    train_losses = []\n    train_accs = []\n    test_accs = []\n    best_acc = 0.0\n    \n    print(\"Starting PyTorch training...\")\n    for epoch in range(config.num_epochs):\n        epoch_start = time.time()\n        \n        # Training phase\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n        total_samples = 0\n        \n        for batch_idx, (inputs, targets) in enumerate(train_loader):\n            inputs, targets = inputs.to(config.device), targets.to(config.device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = outputs.max(1)\n            running_corrects += predicted.eq(targets).sum().item()\n            total_samples += inputs.size(0)\n            \n            if batch_idx % 100 == 0:\n                print(f'  Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}')\n        \n        epoch_loss = running_loss / total_samples\n        epoch_acc = 100. * running_corrects / total_samples\n        \n        # Test phase\n        test_acc = evaluate_model(model, test_loader, config)\n        \n        train_losses.append(epoch_loss)\n        train_accs.append(epoch_acc)\n        test_accs.append(test_acc)\n        \n        scheduler.step()\n        \n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save(model.state_dict(), 'best_vit_model.pth')\n        \n        epoch_time = time.time() - epoch_start\n        print(f'Epoch [{epoch+1}/{config.num_epochs}] ({epoch_time:.1f}s), '\n              f'Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, Test Acc: {test_acc:.2f}%, Best: {best_acc:.2f}%')\n    \n    # Load best model\n    model.load_state_dict(torch.load('best_vit_model.pth'))\n    print(f'Training completed! Best Test Accuracy: {best_acc:.2f}%')\n    \n    return train_losses, train_accs, test_accs, best_acc\n\ndef evaluate_model(model, test_loader, config):\n    \"\"\"Evaluate model on test set\"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs, targets = inputs.to(config.device), targets.to(config.device)\n            outputs = model(inputs)\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n    \n    accuracy = 100. * correct / total\n    return accuracy\n\n# ============================================================================\n# QUANTIZATION AND RTL EXPORT FUNCTIONS\n# ============================================================================\n\ndef symmetric_quantize(x, bits=8, scale=None):\n    \"\"\"Symmetric quantization for RTL export\"\"\"\n    if scale is None:\n        max_val = np.max(np.abs(x))\n        if max_val == 0:\n            scale = 1.0\n        else:\n            scale = max_val / (2**(bits-1) - 1)\n    \n    x_q = np.round(x / scale)\n    x_q = np.clip(x_q, -(2**(bits-1)), 2**(bits-1) - 1)\n    return x_q.astype(np.int8), scale\n\ndef dequantize(x_q, scale):\n    \"\"\"Dequantize values\"\"\"\n    return x_q.astype(np.float32) * scale\n\ndef convert_pytorch_to_custom_format(pytorch_model, config):\n    \"\"\"Convert PyTorch model to custom format for RTL export\"\"\"\n    \n    class CustomViTForExport:\n        def __init__(self):\n            # Extract parameters from PyTorch model\n            self.params = {}\n            \n            # Patch embedding\n            self.params['patch_embed.weight'] = pytorch_model.patch_embed.proj.weight.detach().cpu().numpy()\n            self.params['patch_embed.bias'] = pytorch_model.patch_embed.proj.bias.detach().cpu().numpy()\n            \n            # Positional embedding\n            self.params['pos_embed'] = pytorch_model.pos_embed.detach().cpu().numpy()[0]  # Remove batch dimension\n            \n            # Transformer blocks\n            for i, block in enumerate(pytorch_model.blocks):\n                # Layer norm 1\n                self.params[f'blocks.{i}.norm1.weight'] = block.norm1.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.norm1.bias'] = block.norm1.bias.detach().cpu().numpy()\n                \n                # Attention\n                self.params[f'blocks.{i}.attn.qkv.weight'] = block.attn.qkv.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.attn.qkv.bias'] = block.attn.qkv.bias.detach().cpu().numpy()\n                self.params[f'blocks.{i}.attn.proj.weight'] = block.attn.proj.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.attn.proj.bias'] = block.attn.proj.bias.detach().cpu().numpy()\n                \n                # Layer norm 2\n                self.params[f'blocks.{i}.norm2.weight'] = block.norm2.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.norm2.bias'] = block.norm2.bias.detach().cpu().numpy()\n                \n                # MLP\n                self.params[f'blocks.{i}.mlp.fc1.weight'] = block.mlp.fc1.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.mlp.fc1.bias'] = block.mlp.fc1.bias.detach().cpu().numpy()\n                self.params[f'blocks.{i}.mlp.fc2.weight'] = block.mlp.fc2.weight.detach().cpu().numpy()\n                self.params[f'blocks.{i}.mlp.fc2.bias'] = block.mlp.fc2.bias.detach().cpu().numpy()\n            \n            # Final layers\n            self.params['norm.weight'] = pytorch_model.norm.weight.detach().cpu().numpy()\n            self.params['norm.bias'] = pytorch_model.norm.bias.detach().cpu().numpy()\n            self.params['head.weight'] = pytorch_model.head.weight.detach().cpu().numpy()\n            self.params['head.bias'] = pytorch_model.head.bias.detach().cpu().numpy()\n            \n            print(f\"Converted model with {sum(p.size for p in self.params.values()):,} parameters\")\n        \n        def quantize_model(self, bits=8):\n            \"\"\"Quantize all model parameters\"\"\"\n            quantized_params = {}\n            scales = {}\n            \n            print(f\"Quantizing {len(self.params)} parameter tensors to {bits} bits...\")\n            for name, param in self.params.items():\n                q_param, scale = symmetric_quantize(param, bits)\n                quantized_params[name] = q_param\n                scales[name] = scale\n                \n            return quantized_params, scales\n    \n    return CustomViTForExport()\n\n# ============================================================================\n# EXPORT FUNCTIONS FOR RTL\n# ============================================================================\n\ndef export_for_rtl(custom_model, test_loader, config):\n    \"\"\"Export quantized model and test data for RTL implementation\"\"\"\n    os.makedirs(config.export_dir, exist_ok=True)\n    \n    print(\"Quantizing model...\")\n    quantized_params, scales = custom_model.quantize_model(config.weight_bits)\n    \n    # Export quantized weights\n    print(\"Exporting weights...\")\n    for name, q_param in quantized_params.items():\n        filename = os.path.join(config.export_dir, f\"{name.replace('.', '_')}.mem\")\n        with open(filename, 'w') as f:\n            for val in q_param.flatten():\n                f.write(f\"{val & 0xFF:02x}\\n\")  # Convert to unsigned hex\n    \n    # Export scales\n    with open(os.path.join(config.export_dir, \"scales.json\"), 'w') as f:\n        scales_serializable = {}\n        for key, value in scales.items():\n            if isinstance(value, np.ndarray):\n                scales_serializable[key] = value.tolist()\n            else:\n                scales_serializable[key] = float(value)\n        json.dump(scales_serializable, f, indent=2)\n    \n    # Export test images and labels\n    print(\"Exporting test data...\")\n    test_dataset = test_loader.dataset\n    num_test_samples = min(100, len(test_dataset))\n    \n    for i in range(num_test_samples):\n        img, label = test_dataset[i]\n        img_np = img.numpy()\n        q_img, img_scale = symmetric_quantize(img_np, config.activation_bits)\n        \n        filename = os.path.join(config.export_dir, f\"test_img_{i:03d}.mem\")\n        with open(filename, 'w') as f:\n            for val in q_img.flatten():\n                f.write(f\"{val & 0xFF:02x}\\n\")\n    \n    # Export labels\n    test_labels = [test_dataset[i][1] for i in range(num_test_samples)]\n    with open(os.path.join(config.export_dir, \"test_labels.json\"), 'w') as f:\n        json.dump(test_labels, f)\n    \n    # Export model architecture info\n    arch_info = {\n        \"img_size\": config.img_size,\n        \"patch_size\": config.patch_size,\n        \"embed_dim\": config.embed_dim,\n        \"depth\": config.depth,\n        \"num_heads\": config.num_heads,\n        \"num_classes\": 10,\n        \"weight_bits\": config.weight_bits,\n        \"activation_bits\": config.activation_bits,\n        \"mlp_ratio\": config.mlp_ratio\n    }\n    \n    with open(os.path.join(config.export_dir, \"architecture.json\"), 'w') as f:\n        json.dump(arch_info, f, indent=2)\n    \n    print(f\"Export complete! Files saved to: {config.export_dir}\")\n\ndef generate_verilog_testbench(config):\n    \"\"\"Generate Verilog testbench template\"\"\"\n    tb_dir = os.path.join(config.export_dir, \"testbench\")\n    os.makedirs(tb_dir, exist_ok=True)\n    \n    verilog_tb = f'''\n// Verilog Testbench Template for Custom ViT\n// Generated automatically for RTL implementation\n\n`timescale 1ns / 1ps\n\nmodule vit_testbench();\n    \n    // Parameters from model architecture\n    localparam IMG_SIZE = {config.img_size};\n    localparam PATCH_SIZE = {config.patch_size};\n    localparam EMBED_DIM = {config.embed_dim};\n    localparam DEPTH = {config.depth};\n    localparam NUM_HEADS = {config.num_heads};\n    localparam NUM_CLASSES = 10;\n    localparam WEIGHT_BITS = {config.weight_bits};\n    localparam ACT_BITS = {config.activation_bits};\n    \n    // Derived parameters\n    localparam NUM_PATCHES = (IMG_SIZE / PATCH_SIZE) * (IMG_SIZE / PATCH_SIZE);\n    localparam IMG_PIXELS = IMG_SIZE * IMG_SIZE * 3; // RGB channels\n    \n    // Clock and reset\n    reg clk;\n    reg rst_n;\n    \n    // Input data\n    reg [ACT_BITS-1:0] input_image [0:IMG_PIXELS-1];\n    reg start;\n    \n    // Output data\n    wire [ACT_BITS-1:0] output_logits [0:NUM_CLASSES-1];\n    wire [3:0] predicted_class;\n    wire done;\n    \n    // DUT instantiation\n    vit_top #(\n        .IMG_SIZE(IMG_SIZE),\n        .PATCH_SIZE(PATCH_SIZE),\n        .EMBED_DIM(EMBED_DIM),\n        .DEPTH(DEPTH),\n        .NUM_HEADS(NUM_HEADS),\n        .NUM_CLASSES(NUM_CLASSES),\n        .WEIGHT_BITS(WEIGHT_BITS),\n        .ACT_BITS(ACT_BITS)\n    ) dut (\n        .clk(clk),\n        .rst_n(rst_n),\n        .input_image(input_image),\n        .start(start),\n        .output_logits(output_logits),\n        .predicted_class(predicted_class),\n        .done(done)\n    );\n    \n    // Clock generation\n    always #5 clk = ~clk;\n    \n    // Test sequence\n    initial begin\n        // Initialize\n        clk = 0;\n        rst_n = 0;\n        start = 0;\n        \n        // Load input image from memory file\n        $readmemh(\"test_img_000.mem\", input_image);\n        \n        // Reset sequence\n        #100;\n        rst_n = 1;\n        #50;\n        \n        // Start processing\n        start = 1;\n        #10;\n        start = 0;\n        \n        // Wait for completion\n        wait(done);\n        \n        // Check results\n        $display(\"Processing complete!\");\n        $display(\"Predicted class: %d\", predicted_class);\n        \n        // Display output logits\n        for (int i = 0; i < NUM_CLASSES; i++) begin\n            $display(\"Logit[%d] = %h\", i, output_logits[i]);\n        end\n        \n        #100;\n        $finish;\n    end\n    \nendmodule\n'''\n    \n    with open(os.path.join(tb_dir, \"vit_testbench.sv\"), 'w') as f:\n        f.write(verilog_tb)\n    \n    print(f\"Testbench generated in: {tb_dir}\")\n\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\n\ndef main():\n    print(\"=\"*60)\n    print(\"HYBRID ViT IMPLEMENTATION - PyTorch Training + RTL Export\")\n    print(\"=\"*60)\n    \n    # Load data\n    train_loader, test_loader = load_cifar10_data()\n    \n    # Create and train PyTorch model\n    model = ViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        mlp_ratio=config.mlp_ratio,\n        num_classes=10\n    )\n    \n    # Count parameters\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Total parameters: {total_params:,}\")\n    \n    # Train model with PyTorch\n    train_losses, train_accs, test_accs, best_acc = train_pytorch_model(\n        model, train_loader, test_loader, config\n    )\n    \n    # Plot results\n    plt.figure(figsize=(15, 5))\n    \n    plt.subplot(1, 3, 1)\n    plt.plot(train_losses)\n    plt.title('Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.grid(True)\n    \n    plt.subplot(1, 3, 2)\n    plt.plot(train_accs, label='Train')\n    plt.plot(test_accs, label='Test')\n    plt.title('Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.subplot(1, 3, 3)\n    plt.plot(test_accs)\n    plt.title('Test Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig('training_results.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    # Convert to custom format and export for RTL\n    print(\"Converting model for RTL export...\")\n    custom_model = convert_pytorch_to_custom_format(model, config)\n    \n    # Export for RTL implementation\n    export_for_rtl(custom_model, test_loader, config)\n    \n    # Generate RTL testbench\n    generate_verilog_testbench(config)\n    \n    print(f\"\\nTraining and export completed!\")\n    print(f\"Best accuracy: {best_acc:.2f}%\")\n    print(f\"All files exported to: {config.export_dir}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T17:25:43.342082Z","iopub.execute_input":"2025-09-28T17:25:43.342684Z","iopub.status.idle":"2025-09-28T18:05:42.661085Z","shell.execute_reply.started":"2025-09-28T17:25:43.342652Z","shell.execute_reply":"2025-09-28T18:05:42.660039Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n============================================================\nHYBRID ViT IMPLEMENTATION - PyTorch Training + RTL Export\n============================================================\nTotal parameters: 4,007,178\nStarting PyTorch training...\n  Batch [0/98], Loss: 2.3262\nEpoch [1/100] (25.3s), Loss: 1.9895, Train Acc: 25.63%, Test Acc: 32.63%, Best: 32.63%\n  Batch [0/98], Loss: 1.8068\nEpoch [2/100] (25.3s), Loss: 1.7677, Train Acc: 34.10%, Test Acc: 37.38%, Best: 37.38%\n  Batch [0/98], Loss: 1.6756\nEpoch [3/100] (25.3s), Loss: 1.6522, Train Acc: 39.14%, Test Acc: 42.26%, Best: 42.26%\n  Batch [0/98], Loss: 1.6153\nEpoch [4/100] (25.3s), Loss: 1.5793, Train Acc: 42.21%, Test Acc: 46.29%, Best: 46.29%\n  Batch [0/98], Loss: 1.5676\nEpoch [5/100] (25.3s), Loss: 1.5076, Train Acc: 45.36%, Test Acc: 49.11%, Best: 49.11%\n  Batch [0/98], Loss: 1.4682\nEpoch [6/100] (26.2s), Loss: 1.4577, Train Acc: 46.89%, Test Acc: 51.67%, Best: 51.67%\n  Batch [0/98], Loss: 1.4103\nEpoch [7/100] (25.6s), Loss: 1.4247, Train Acc: 48.05%, Test Acc: 51.53%, Best: 51.67%\n  Batch [0/98], Loss: 1.3826\nEpoch [8/100] (25.5s), Loss: 1.3831, Train Acc: 49.83%, Test Acc: 52.02%, Best: 52.02%\n  Batch [0/98], Loss: 1.3996\nEpoch [9/100] (25.4s), Loss: 1.3573, Train Acc: 51.21%, Test Acc: 54.07%, Best: 54.07%\n  Batch [0/98], Loss: 1.2671\nEpoch [10/100] (24.8s), Loss: 1.3197, Train Acc: 51.99%, Test Acc: 54.63%, Best: 54.63%\n  Batch [0/98], Loss: 1.2937\nEpoch [11/100] (25.5s), Loss: 1.3020, Train Acc: 53.00%, Test Acc: 55.80%, Best: 55.80%\n  Batch [0/98], Loss: 1.3033\nEpoch [12/100] (25.7s), Loss: 1.2552, Train Acc: 54.72%, Test Acc: 57.34%, Best: 57.34%\n  Batch [0/98], Loss: 1.2419\nEpoch [13/100] (25.2s), Loss: 1.2339, Train Acc: 55.67%, Test Acc: 57.37%, Best: 57.37%\n  Batch [0/98], Loss: 1.2774\nEpoch [14/100] (25.7s), Loss: 1.2103, Train Acc: 56.47%, Test Acc: 59.03%, Best: 59.03%\n  Batch [0/98], Loss: 1.1926\nEpoch [15/100] (25.1s), Loss: 1.1830, Train Acc: 57.24%, Test Acc: 60.13%, Best: 60.13%\n  Batch [0/98], Loss: 1.1736\nEpoch [16/100] (25.4s), Loss: 1.1618, Train Acc: 58.14%, Test Acc: 61.33%, Best: 61.33%\n  Batch [0/98], Loss: 1.1280\nEpoch [17/100] (25.4s), Loss: 1.1411, Train Acc: 59.08%, Test Acc: 61.30%, Best: 61.33%\n  Batch [0/98], Loss: 1.1185\nEpoch [18/100] (25.9s), Loss: 1.1235, Train Acc: 59.53%, Test Acc: 62.20%, Best: 62.20%\n  Batch [0/98], Loss: 1.1121\nEpoch [19/100] (24.8s), Loss: 1.1075, Train Acc: 60.34%, Test Acc: 62.62%, Best: 62.62%\n  Batch [0/98], Loss: 1.1104\nEpoch [20/100] (25.8s), Loss: 1.0883, Train Acc: 60.89%, Test Acc: 63.80%, Best: 63.80%\n  Batch [0/98], Loss: 1.0760\nEpoch [21/100] (25.3s), Loss: 1.0637, Train Acc: 61.88%, Test Acc: 63.83%, Best: 63.83%\n  Batch [0/98], Loss: 1.0883\nEpoch [22/100] (25.6s), Loss: 1.0479, Train Acc: 62.63%, Test Acc: 64.85%, Best: 64.85%\n  Batch [0/98], Loss: 1.0422\nEpoch [23/100] (25.0s), Loss: 1.0201, Train Acc: 63.46%, Test Acc: 65.03%, Best: 65.03%\n  Batch [0/98], Loss: 0.9546\nEpoch [24/100] (25.2s), Loss: 1.0082, Train Acc: 64.02%, Test Acc: 65.77%, Best: 65.77%\n  Batch [0/98], Loss: 1.0564\nEpoch [25/100] (25.2s), Loss: 0.9984, Train Acc: 64.48%, Test Acc: 66.01%, Best: 66.01%\n  Batch [0/98], Loss: 0.9261\nEpoch [26/100] (25.6s), Loss: 0.9738, Train Acc: 65.38%, Test Acc: 66.41%, Best: 66.41%\n  Batch [0/98], Loss: 0.9420\nEpoch [27/100] (25.4s), Loss: 0.9592, Train Acc: 65.75%, Test Acc: 67.22%, Best: 67.22%\n  Batch [0/98], Loss: 0.9883\nEpoch [28/100] (25.4s), Loss: 0.9469, Train Acc: 66.30%, Test Acc: 66.94%, Best: 67.22%\n  Batch [0/98], Loss: 0.9242\nEpoch [29/100] (25.6s), Loss: 0.9316, Train Acc: 66.51%, Test Acc: 68.40%, Best: 68.40%\n  Batch [0/98], Loss: 0.9331\nEpoch [30/100] (25.5s), Loss: 0.9143, Train Acc: 67.15%, Test Acc: 68.80%, Best: 68.80%\n  Batch [0/98], Loss: 0.9832\nEpoch [31/100] (25.5s), Loss: 0.9064, Train Acc: 67.64%, Test Acc: 69.53%, Best: 69.53%\n  Batch [0/98], Loss: 0.8325\nEpoch [32/100] (25.4s), Loss: 0.8872, Train Acc: 68.40%, Test Acc: 69.81%, Best: 69.81%\n  Batch [0/98], Loss: 0.8075\nEpoch [33/100] (26.0s), Loss: 0.8748, Train Acc: 69.00%, Test Acc: 69.77%, Best: 69.81%\n  Batch [0/98], Loss: 0.9075\nEpoch [34/100] (25.4s), Loss: 0.8678, Train Acc: 68.94%, Test Acc: 70.12%, Best: 70.12%\n  Batch [0/98], Loss: 0.8111\nEpoch [35/100] (25.4s), Loss: 0.8471, Train Acc: 70.02%, Test Acc: 70.50%, Best: 70.50%\n  Batch [0/98], Loss: 0.8978\nEpoch [36/100] (25.2s), Loss: 0.8375, Train Acc: 70.17%, Test Acc: 70.16%, Best: 70.50%\n  Batch [0/98], Loss: 0.8372\nEpoch [37/100] (25.4s), Loss: 0.8244, Train Acc: 70.54%, Test Acc: 70.93%, Best: 70.93%\n  Batch [0/98], Loss: 0.8014\nEpoch [38/100] (25.5s), Loss: 0.8195, Train Acc: 70.84%, Test Acc: 71.23%, Best: 71.23%\n  Batch [0/98], Loss: 0.7739\nEpoch [39/100] (25.2s), Loss: 0.8051, Train Acc: 71.31%, Test Acc: 71.45%, Best: 71.45%\n  Batch [0/98], Loss: 0.7437\nEpoch [40/100] (25.5s), Loss: 0.7870, Train Acc: 71.84%, Test Acc: 71.27%, Best: 71.45%\n  Batch [0/98], Loss: 0.7559\nEpoch [41/100] (25.9s), Loss: 0.7778, Train Acc: 72.22%, Test Acc: 72.06%, Best: 72.06%\n  Batch [0/98], Loss: 0.8515\nEpoch [42/100] (25.2s), Loss: 0.7737, Train Acc: 72.41%, Test Acc: 71.74%, Best: 72.06%\n  Batch [0/98], Loss: 0.6865\nEpoch [43/100] (24.9s), Loss: 0.7617, Train Acc: 72.77%, Test Acc: 72.06%, Best: 72.06%\n  Batch [0/98], Loss: 0.6911\nEpoch [44/100] (25.3s), Loss: 0.7479, Train Acc: 73.22%, Test Acc: 72.53%, Best: 72.53%\n  Batch [0/98], Loss: 0.7476\nEpoch [45/100] (25.3s), Loss: 0.7318, Train Acc: 73.98%, Test Acc: 72.69%, Best: 72.69%\n  Batch [0/98], Loss: 0.6660\nEpoch [46/100] (25.2s), Loss: 0.7255, Train Acc: 73.91%, Test Acc: 73.27%, Best: 73.27%\n  Batch [0/98], Loss: 0.7549\nEpoch [47/100] (25.1s), Loss: 0.7089, Train Acc: 74.65%, Test Acc: 73.50%, Best: 73.50%\n  Batch [0/98], Loss: 0.6527\nEpoch [48/100] (25.2s), Loss: 0.6979, Train Acc: 75.09%, Test Acc: 73.53%, Best: 73.53%\n  Batch [0/98], Loss: 0.6982\nEpoch [49/100] (25.7s), Loss: 0.6859, Train Acc: 75.40%, Test Acc: 73.99%, Best: 73.99%\n  Batch [0/98], Loss: 0.6710\nEpoch [50/100] (25.7s), Loss: 0.6786, Train Acc: 75.81%, Test Acc: 74.17%, Best: 74.17%\n  Batch [0/98], Loss: 0.6728\nEpoch [51/100] (25.1s), Loss: 0.6658, Train Acc: 76.16%, Test Acc: 74.12%, Best: 74.17%\n  Batch [0/98], Loss: 0.6717\nEpoch [52/100] (25.4s), Loss: 0.6609, Train Acc: 76.13%, Test Acc: 74.49%, Best: 74.49%\n  Batch [0/98], Loss: 0.6222\nEpoch [53/100] (25.3s), Loss: 0.6505, Train Acc: 76.80%, Test Acc: 74.46%, Best: 74.49%\n  Batch [0/98], Loss: 0.6317\nEpoch [54/100] (25.4s), Loss: 0.6463, Train Acc: 76.98%, Test Acc: 74.59%, Best: 74.59%\n  Batch [0/98], Loss: 0.6035\nEpoch [55/100] (25.3s), Loss: 0.6265, Train Acc: 77.60%, Test Acc: 74.38%, Best: 74.59%\n  Batch [0/98], Loss: 0.6500\nEpoch [56/100] (25.6s), Loss: 0.6208, Train Acc: 77.94%, Test Acc: 74.94%, Best: 74.94%\n  Batch [0/98], Loss: 0.5643\nEpoch [57/100] (25.3s), Loss: 0.6057, Train Acc: 78.50%, Test Acc: 75.21%, Best: 75.21%\n  Batch [0/98], Loss: 0.5612\nEpoch [58/100] (25.2s), Loss: 0.5963, Train Acc: 78.62%, Test Acc: 75.72%, Best: 75.72%\n  Batch [0/98], Loss: 0.5806\nEpoch [59/100] (25.4s), Loss: 0.5878, Train Acc: 78.99%, Test Acc: 75.78%, Best: 75.78%\n  Batch [0/98], Loss: 0.5876\nEpoch [60/100] (25.1s), Loss: 0.5782, Train Acc: 79.17%, Test Acc: 75.96%, Best: 75.96%\n  Batch [0/98], Loss: 0.5226\nEpoch [61/100] (25.0s), Loss: 0.5664, Train Acc: 79.73%, Test Acc: 75.95%, Best: 75.96%\n  Batch [0/98], Loss: 0.5668\nEpoch [62/100] (25.4s), Loss: 0.5610, Train Acc: 79.98%, Test Acc: 75.34%, Best: 75.96%\n  Batch [0/98], Loss: 0.5727\nEpoch [63/100] (25.7s), Loss: 0.5528, Train Acc: 80.05%, Test Acc: 75.78%, Best: 75.96%\n  Batch [0/98], Loss: 0.5294\nEpoch [64/100] (25.2s), Loss: 0.5477, Train Acc: 80.41%, Test Acc: 76.80%, Best: 76.80%\n  Batch [0/98], Loss: 0.5553\nEpoch [65/100] (25.0s), Loss: 0.5318, Train Acc: 80.87%, Test Acc: 76.37%, Best: 76.80%\n  Batch [0/98], Loss: 0.4600\nEpoch [66/100] (24.9s), Loss: 0.5181, Train Acc: 81.32%, Test Acc: 76.43%, Best: 76.80%\n  Batch [0/98], Loss: 0.5178\nEpoch [67/100] (25.2s), Loss: 0.5158, Train Acc: 81.47%, Test Acc: 76.60%, Best: 76.80%\n  Batch [0/98], Loss: 0.4766\nEpoch [68/100] (24.7s), Loss: 0.5103, Train Acc: 81.68%, Test Acc: 76.56%, Best: 76.80%\n  Batch [0/98], Loss: 0.5071\nEpoch [69/100] (24.9s), Loss: 0.4973, Train Acc: 82.17%, Test Acc: 76.77%, Best: 76.80%\n  Batch [0/98], Loss: 0.4652\nEpoch [70/100] (24.9s), Loss: 0.4876, Train Acc: 82.39%, Test Acc: 76.77%, Best: 76.80%\n  Batch [0/98], Loss: 0.4998\nEpoch [71/100] (25.0s), Loss: 0.4900, Train Acc: 82.19%, Test Acc: 77.14%, Best: 77.14%\n  Batch [0/98], Loss: 0.4680\nEpoch [72/100] (24.6s), Loss: 0.4739, Train Acc: 82.97%, Test Acc: 76.73%, Best: 77.14%\n  Batch [0/98], Loss: 0.4774\nEpoch [73/100] (25.3s), Loss: 0.4659, Train Acc: 83.14%, Test Acc: 76.78%, Best: 77.14%\n  Batch [0/98], Loss: 0.4852\nEpoch [74/100] (25.2s), Loss: 0.4657, Train Acc: 83.31%, Test Acc: 77.29%, Best: 77.29%\n  Batch [0/98], Loss: 0.4174\nEpoch [75/100] (25.0s), Loss: 0.4587, Train Acc: 83.39%, Test Acc: 77.14%, Best: 77.29%\n  Batch [0/98], Loss: 0.4547\nEpoch [76/100] (24.8s), Loss: 0.4480, Train Acc: 84.02%, Test Acc: 76.93%, Best: 77.29%\n  Batch [0/98], Loss: 0.4617\nEpoch [77/100] (24.9s), Loss: 0.4458, Train Acc: 84.05%, Test Acc: 77.35%, Best: 77.35%\n  Batch [0/98], Loss: 0.4725\nEpoch [78/100] (25.0s), Loss: 0.4385, Train Acc: 84.28%, Test Acc: 77.07%, Best: 77.35%\n  Batch [0/98], Loss: 0.4407\nEpoch [79/100] (25.2s), Loss: 0.4346, Train Acc: 84.44%, Test Acc: 77.38%, Best: 77.38%\n  Batch [0/98], Loss: 0.4091\nEpoch [80/100] (24.7s), Loss: 0.4244, Train Acc: 84.80%, Test Acc: 77.14%, Best: 77.38%\n  Batch [0/98], Loss: 0.4247\nEpoch [81/100] (25.0s), Loss: 0.4211, Train Acc: 84.95%, Test Acc: 77.14%, Best: 77.38%\n  Batch [0/98], Loss: 0.4596\nEpoch [82/100] (24.7s), Loss: 0.4136, Train Acc: 85.15%, Test Acc: 77.37%, Best: 77.38%\n  Batch [0/98], Loss: 0.4379\nEpoch [83/100] (25.1s), Loss: 0.4073, Train Acc: 85.40%, Test Acc: 77.36%, Best: 77.38%\n  Batch [0/98], Loss: 0.3691\nEpoch [84/100] (24.9s), Loss: 0.4045, Train Acc: 85.51%, Test Acc: 77.52%, Best: 77.52%\n  Batch [0/98], Loss: 0.3984\nEpoch [85/100] (24.9s), Loss: 0.4045, Train Acc: 85.47%, Test Acc: 77.34%, Best: 77.52%\n  Batch [0/98], Loss: 0.4067\nEpoch [86/100] (25.7s), Loss: 0.3964, Train Acc: 85.73%, Test Acc: 77.42%, Best: 77.52%\n  Batch [0/98], Loss: 0.4281\nEpoch [87/100] (25.2s), Loss: 0.4006, Train Acc: 85.75%, Test Acc: 77.63%, Best: 77.63%\n  Batch [0/98], Loss: 0.3848\nEpoch [88/100] (24.8s), Loss: 0.3950, Train Acc: 85.85%, Test Acc: 77.34%, Best: 77.63%\n  Batch [0/98], Loss: 0.3490\nEpoch [89/100] (25.1s), Loss: 0.3909, Train Acc: 86.06%, Test Acc: 77.41%, Best: 77.63%\n  Batch [0/98], Loss: 0.3265\nEpoch [90/100] (25.2s), Loss: 0.3876, Train Acc: 86.05%, Test Acc: 77.59%, Best: 77.63%\n  Batch [0/98], Loss: 0.3699\nEpoch [91/100] (25.0s), Loss: 0.3850, Train Acc: 86.23%, Test Acc: 77.65%, Best: 77.65%\n  Batch [0/98], Loss: 0.3981\nEpoch [92/100] (25.0s), Loss: 0.3868, Train Acc: 86.27%, Test Acc: 77.67%, Best: 77.67%\n  Batch [0/98], Loss: 0.3645\nEpoch [93/100] (25.3s), Loss: 0.3865, Train Acc: 86.15%, Test Acc: 77.68%, Best: 77.68%\n  Batch [0/98], Loss: 0.3161\nEpoch [94/100] (25.0s), Loss: 0.3812, Train Acc: 86.25%, Test Acc: 77.65%, Best: 77.68%\n  Batch [0/98], Loss: 0.3205\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/566485945.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/566485945.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;31m# Train model with PyTorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m     train_losses, train_accs, test_accs, best_acc = train_pytorch_model(\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     )\n","\u001b[0;32m/tmp/ipykernel_36/566485945.py\u001b[0m in \u001b[0;36mtrain_pytorch_model\u001b[0;34m(model, train_loader, test_loader, config)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# vit_no_api.py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport time\nfrom torch.cuda.amp import autocast, GradScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ---------------- Config ----------------\nclass Config:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    img_size = 64\n    patch_size = 8\n    embed_dim = 256\n    depth = 6\n    num_heads = 8\n    mlp_ratio = 3.0\n    batch_size = 128\n    num_epochs = 250\n    initial_lr = 0.001\n    weight_decay = 0.05\n    num_workers = 4\n    pin_memory = True\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\nbase_path = \"/kaggle/input/cifar10-64x64-resized-via-cai-super-resolution/cifar10-32\"\n\n# ---------------- Data transforms ----------------\ntrain_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomCrop(config.img_size, padding=4, padding_mode='reflect'),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616]),\n])\ntest_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n])\n\n# ---------------- Dataset helpers ----------------\ndef create_dataframe(split):\n    data = []\n    split_path = os.path.join(base_path, split)\n    for class_name in sorted(os.listdir(split_path)):\n        class_path = os.path.join(split_path, class_name)\n        if os.path.isdir(class_path):\n            for img_name in os.listdir(class_path):\n                data.append([os.path.join(class_path, img_name), class_name])\n    return pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n\nprint(\"Loading dataset...\")\nstart_time = time.time()\ntrain_df = create_dataframe(\"train\")\ntest_df = create_dataframe(\"test\")\nle = LabelEncoder()\ntrain_df[\"label\"] = le.fit_transform(train_df[\"label\"])\ntest_df[\"label\"] = le.transform(test_df[\"label\"])\nprint(f\"Dataset loaded in {time.time() - start_time:.2f}s\")\nprint(f\"Train samples: {len(train_df)}, Test samples: {len(test_df)}\")\n\nclass CIFARDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.paths = df[\"image_path\"].tolist()\n        self.labels = df[\"label\"].tolist()\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self, idx):\n        p = self.paths[idx]\n        label = self.labels[idx]\n        try:\n            img = Image.open(p).convert(\"RGB\")\n            if self.transform:\n                img = self.transform(img)\n            return img, label\n        except:\n            return torch.zeros(3, config.img_size, config.img_size), label\n\ntrain_dataset = CIFARDataset(train_df, transform=train_transform)\ntest_dataset = CIFARDataset(test_df, transform=test_transform)\ntrain_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True,\n                          num_workers=config.num_workers, pin_memory=config.pin_memory)\ntest_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False,\n                         num_workers=config.num_workers, pin_memory=config.pin_memory)\n\n# ---------------- Custom building blocks (no nn.Linear / nn.Conv2d) ----------------\nclass CustomLinear(nn.Module):\n    def __init__(self, in_features, out_features, bias=True):\n        super().__init__()\n        self.weight = nn.Parameter(torch.empty(out_features, in_features))\n        if bias:\n            self.bias = nn.Parameter(torch.empty(out_features))\n        else:\n            self.bias = None\n        # init\n        nn.init.trunc_normal_(self.weight, std=0.02)\n        if bias:\n            nn.init.constant_(self.bias, 0.0)\n    def forward(self, x):\n        # x: (..., in_features)\n        # output: (..., out_features)\n        out = x.matmul(self.weight.t())\n        if self.bias is not None:\n            out = out + self.bias\n        return out\n\nclass CustomLayerNorm(nn.Module):\n    def __init__(self, normalized_shape, eps=1e-6):\n        super().__init__()\n        self.eps = eps\n        self.gamma = nn.Parameter(torch.ones(normalized_shape))\n        self.beta = nn.Parameter(torch.zeros(normalized_shape))\n    def forward(self, x):\n        # x shape (..., C)\n        mean = x.mean(-1, keepdim=True)\n        var = ((x - mean) ** 2).mean(-1, keepdim=True)\n        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n        return x_norm * self.gamma + self.beta\n\nclass PatchEmbeddingUnfold(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_ch=3, embed_dim=256):\n        super().__init__()\n        self.patch_size = patch_size\n        self.in_ch = in_ch\n        self.embed_dim = embed_dim\n        # weight: embed_dim x (in_ch * patch_size * patch_size)\n        self.proj_weight = nn.Parameter(torch.empty(embed_dim, in_ch * patch_size * patch_size))\n        self.proj_bias = nn.Parameter(torch.zeros(embed_dim))\n        nn.init.kaiming_normal_(self.proj_weight, mode='fan_out')\n    def forward(self, x):\n        # x: (B, C, H, W)\n        B = x.shape[0]\n        # unfold -> (B, C*patch_size*patch_size, num_patches)\n        patches = F.unfold(x, kernel_size=self.patch_size, stride=self.patch_size)\n        # transpose -> (B, num_patches, C*patch_size*patch_size)\n        patches = patches.transpose(1, 2)\n        # project: (B, num_patches, embed_dim)\n        out = patches.matmul(self.proj_weight.t()) + self.proj_bias\n        return out\n\n# ---------------- Attention / MLP using CustomLinear ----------------\nclass MultiHeadAttentionCustom(nn.Module):\n    def __init__(self, dim, num_heads=8, dropout=0.1):\n        super().__init__()\n        self.num_heads = num_heads\n        self.dim = dim\n        self.head_dim = dim // num_heads\n        assert dim % num_heads == 0\n        # We'll implement qkv as a single CustomLinear producing 3*dim\n        self.qkv = CustomLinear(dim, dim * 3)\n        self.proj = CustomLinear(dim, dim)\n        self.attn_drop = nn.Dropout(dropout)\n        self.proj_drop = nn.Dropout(dropout)\n        self.scale = (self.head_dim) ** -0.5\n    def forward(self, x):\n        # x: (B, N, C)\n        B, N, C = x.shape\n        qkv = self.qkv(x)  # (B, N, 3*C)\n        qkv = qkv.view(B, N, 3, self.num_heads, self.head_dim).permute(2,0,3,1,4)\n        q, k, v = qkv[0], qkv[1], qkv[2]  # each: (B, num_heads, N, head_dim)\n        # compute attention\n        attn_logits = torch.matmul(q, k.transpose(-2, -1)) * self.scale  # (B, heads, N, N)\n        attn = torch.softmax(attn_logits, dim=-1)\n        attn = self.attn_drop(attn)\n        out = torch.matmul(attn, v)  # (B, heads, N, head_dim)\n        out = out.permute(0,2,1,3).contiguous().view(B, N, C)  # (B, N, C)\n        out = self.proj(out)\n        out = self.proj_drop(out)\n        return out\n\nclass MLPCustom(nn.Module):\n    def __init__(self, in_features, hidden_features=None, drop=0.1):\n        super().__init__()\n        hidden_features = hidden_features or int(in_features * 3.0)\n        self.fc1 = CustomLinear(in_features, hidden_features)\n        self.act = nn.GELU()\n        self.fc2 = CustomLinear(hidden_features, in_features)\n        self.drop = nn.Dropout(drop)\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\nclass TransformerBlockCustom(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4.0, drop=0.1):\n        super().__init__()\n        self.norm1 = CustomLayerNorm(dim)\n        self.attn = MultiHeadAttentionCustom(dim, num_heads, dropout=drop)\n        self.norm2 = CustomLayerNorm(dim)\n        self.mlp = MLPCustom(dim, hidden_features=int(dim * mlp_ratio), drop=drop)\n    def forward(self, x):\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\n# ---------------- Full model (no high-level Linear/Conv) ----------------\nclass OptimizedViTNoAPI(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_ch=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=3.0, dropout=0.1):\n        super().__init__()\n        self.patch_embed = PatchEmbeddingUnfold(img_size, patch_size, in_ch, embed_dim)\n        num_patches = (img_size // patch_size) ** 2\n        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n        self.pos_drop = nn.Dropout(dropout)\n        self.blocks = nn.ModuleList([TransformerBlockCustom(embed_dim, num_heads, mlp_ratio, dropout) for _ in range(depth)])\n        self.norm = CustomLayerNorm(embed_dim)\n        # final head as CustomLinear\n        self.head = CustomLinear(embed_dim, num_classes)\n        # init pos\n        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n    def forward(self, x):\n        # x: (B, C, H, W)\n        x = self.patch_embed(x)           # (B, num_patches, embed_dim)\n        x = x + self.pos_embed\n        x = self.pos_drop(x)\n        for blk in self.blocks:\n            x = blk(x)\n        x = self.norm(x)\n        x = x.mean(dim=1)                 # global avg pool\n        x = self.head(x)\n        return x\n\n# ---------------- Training functions ----------------\ndef train_model(model, train_loader, test_loader, config):\n    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.initial_lr, weight_decay=config.weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.num_epochs)\n    scaler = GradScaler()\n    best_acc = 0.0\n    train_losses, test_accs = [], []\n    print(\"Starting training...\")\n    for epoch in range(config.num_epochs):\n        model.train()\n        running_loss = 0.0\n        for images, labels in train_loader:\n            images, labels = images.to(config.device), labels.to(config.device)\n            optimizer.zero_grad()\n            with autocast():\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            running_loss += loss.item()\n        # validation\n        model.eval()\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels in test_loader:\n                images, labels = images.to(config.device), labels.to(config.device)\n                outputs = model(images)\n                _, pred = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (pred == labels).sum().item()\n        test_acc = 100. * correct / total\n        avg_loss = running_loss / len(train_loader)\n        train_losses.append(avg_loss)\n        test_accs.append(test_acc)\n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save({'model_state_dict': model.state_dict(), 'accuracy': test_acc, 'epoch': epoch}, 'best_model.pth')\n        scheduler.step()\n        if (epoch + 1) % 10 == 0:\n            print(f'Epoch [{epoch+1}/{config.num_epochs}], Loss: {avg_loss:.4f}, Acc: {test_acc:.2f}%, Best: {best_acc:.2f}%')\n    print(f'Best Accuracy: {best_acc:.2f}%')\n    return train_losses, test_accs, best_acc\n\n# ---------------- Main ----------------\nif __name__ == \"__main__\":\n    model = OptimizedViTNoAPI(\n        img_size=config.img_size, patch_size=config.patch_size,\n        embed_dim=config.embed_dim, depth=config.depth, num_heads=config.num_heads,\n        mlp_ratio=config.mlp_ratio, num_classes=len(le.classes_)\n    ).to(config.device)\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Model parameters: {total_params:,}\")\n    train_losses, test_accs, best_acc = train_model(model, train_loader, test_loader, config)\n\n    # Save training plots\n    plt.figure(figsize=(10,4))\n    plt.subplot(1,2,1)\n    plt.plot(train_losses); plt.title('Train Loss')\n    plt.subplot(1,2,2)\n    plt.plot(test_accs); plt.title('Test Acc'); plt.ylim(0,100)\n    plt.tight_layout()\n    plt.savefig('training_results_noapi.png')\n    plt.show()\n\n    print(\"Training finished. Best acc:\", best_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-28T18:05:49.927621Z","iopub.execute_input":"2025-09-28T18:05:49.928346Z","iopub.status.idle":"2025-09-28T18:35:15.516154Z","shell.execute_reply.started":"2025-09-28T18:05:49.928314Z","shell.execute_reply":"2025-09-28T18:35:15.512042Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading dataset...\nDataset loaded in 0.13s\nTrain samples: 50000, Test samples: 10000\nModel parameters: 4,019,466\nStarting training...\nEpoch [10/250], Loss: 1.3092, Acc: 66.19%, Best: 66.19%\nEpoch [20/250], Loss: 1.0691, Acc: 73.23%, Best: 74.45%\nEpoch [30/250], Loss: 0.9429, Acc: 77.94%, Best: 78.24%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/135046896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mtotal_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Model parameters: {total_params:,}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;31m# Save training plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/135046896.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, config)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# MANUAL IMPLEMENTATIONS - NO PyTorch APIs\n# ============================================================================\n\nclass ManualQuantizer:\n    \"\"\"Manual INT8 Quantization Implementation\"\"\"\n    \n    @staticmethod\n    def quantize_tensor(x, scale, zero_point):\n        \"\"\"Convert float32 to int8\"\"\"\n        x_int = torch.clamp(torch.round(x / scale + zero_point), -128, 127)\n        return x_int.to(torch.int8)\n    \n    @staticmethod\n    def dequantize_tensor(x_int, scale, zero_point):\n        \"\"\"Convert int8 to float32\"\"\"\n        return (x_int.float() - zero_point) * scale\n    \n    @staticmethod\n    def calculate_qparams(x, symmetric=True):\n        \"\"\"Calculate quantization scale and zero_point\"\"\"\n        if symmetric:\n            abs_max = torch.max(torch.abs(x))\n            scale = abs_max / 127.0\n            zero_point = 0\n        else:\n            x_min = torch.min(x)\n            x_max = torch.max(x)\n            scale = (x_max - x_min) / 255.0\n            zero_point = -torch.round(x_min / scale) - 128\n        \n        scale = torch.clamp(scale, min=1e-8)\n        return scale, zero_point\n\nclass TiledMatMul:\n    \"\"\"Optimized Matrix Multiplication with Tiling\"\"\"\n    \n    @staticmethod\n    def matmul_tiled(A, B, tile_size=32):\n        \"\"\"\n        Batched matrix multiplication with tiling\n        Supports any dimensional input\n        \"\"\"\n        # Store original shape\n        original_A_shape = A.shape\n        original_B_shape = B.shape\n        \n        # Handle different input dimensions\n        if len(A.shape) > 2 and len(B.shape) > 2:\n            # Both are batched: (B, H, N, K) x (B, H, K, M) -> (B, H, N, M)\n            batch_dims = A.shape[:-2]\n            M, K = A.shape[-2:]\n            K2, N = B.shape[-2:]\n            \n            assert K == K2, f\"Matrix dimensions incompatible: {K} vs {K2}\"\n            \n            # Reshape to 2D for computation\n            A_2d = A.reshape(-1, K)\n            B_2d = B.reshape(-1, N)\n            \n            # Compute tiled matmul\n            C_2d = torch.zeros(A_2d.shape[0], N, dtype=A.dtype, device=A.device)\n            \n            num_batches = A_2d.shape[0] // M\n            for batch_idx in range(num_batches):\n                batch_start = batch_idx * M\n                batch_end = (batch_idx + 1) * M\n                \n                A_batch = A_2d[batch_start:batch_end, :]\n                B_batch = B_2d[batch_idx * K2:(batch_idx + 1) * K2, :]\n                \n                # Tiled multiplication for this batch\n                for i in range(0, M, tile_size):\n                    for j in range(0, N, tile_size):\n                        for k in range(0, K, tile_size):\n                            i_end = min(i + tile_size, M)\n                            j_end = min(j + tile_size, N)\n                            k_end = min(k + tile_size, K)\n                            \n                            A_tile = A_batch[i:i_end, k:k_end]\n                            B_tile = B_batch[k:k_end, j:j_end]\n                            C_2d[batch_start + i:batch_start + i_end, j:j_end] += torch.matmul(A_tile, B_tile)\n            \n            # Reshape back\n            C = C_2d.reshape(*batch_dims, M, N)\n            return C\n            \n        elif len(A.shape) > 2:\n            # A is batched, B is not: (..., M, K) x (K, N) -> (..., M, N)\n            batch_dims = A.shape[:-2]\n            M = A.shape[-2]\n            K = A.shape[-1]\n            K2, N = B.shape\n            \n            assert K == K2, f\"Matrix dimensions incompatible: {K} vs {K2}\"\n            \n            A_2d = A.reshape(-1, K)\n            C_2d = torch.zeros(A_2d.shape[0], N, dtype=A.dtype, device=A.device)\n            \n            # Tiled multiplication\n            for i in range(0, A_2d.shape[0], tile_size):\n                for j in range(0, N, tile_size):\n                    for k in range(0, K, tile_size):\n                        i_end = min(i + tile_size, A_2d.shape[0])\n                        j_end = min(j + tile_size, N)\n                        k_end = min(k + tile_size, K)\n                        \n                        A_tile = A_2d[i:i_end, k:k_end]\n                        B_tile = B[k:k_end, j:j_end]\n                        C_2d[i:i_end, j:j_end] += torch.matmul(A_tile, B_tile)\n            \n            C = C_2d.reshape(*batch_dims, M, N)\n            return C\n        else:\n            # Both are 2D: (M, K) x (K, N) -> (M, N)\n            M, K = A.shape\n            K2, N = B.shape\n            assert K == K2, f\"Matrix dimensions incompatible: {K} vs {K2}\"\n            \n            C = torch.zeros(M, N, dtype=A.dtype, device=A.device)\n            \n            for i in range(0, M, tile_size):\n                for j in range(0, N, tile_size):\n                    for k in range(0, K, tile_size):\n                        i_end = min(i + tile_size, M)\n                        j_end = min(j + tile_size, N)\n                        k_end = min(k + tile_size, K)\n                        \n                        A_tile = A[i:i_end, k:k_end]\n                        B_tile = B[k:k_end, j:j_end]\n                        C[i:i_end, j:j_end] += torch.matmul(A_tile, B_tile)\n            \n            return C\n    \n    @staticmethod\n    def matmul_int8(A_int, B_int, A_scale, B_scale, A_zp, B_zp, tile_size=32):\n        \"\"\"INT8 matrix multiplication with quantization\"\"\"\n        original_shape = A_int.shape\n        if len(A_int.shape) > 2:\n            A_int = A_int.reshape(-1, A_int.shape[-1])\n        \n        M, K = A_int.shape\n        K2, N = B_int.shape\n        \n        # Convert to int32 to avoid overflow\n        A_int32 = A_int.to(torch.int32)\n        B_int32 = B_int.to(torch.int32)\n        \n        C_int32 = torch.zeros(M, N, dtype=torch.int32, device=A_int.device)\n        \n        # Tiled multiplication\n        for i in range(0, M, tile_size):\n            for j in range(0, N, tile_size):\n                for k in range(0, K, tile_size):\n                    i_end = min(i + tile_size, M)\n                    j_end = min(j + tile_size, N)\n                    k_end = min(k + tile_size, K)\n                    \n                    A_tile = A_int32[i:i_end, k:k_end]\n                    B_tile = B_int32[k:k_end, j:j_end]\n                    C_int32[i:i_end, j:j_end] += torch.matmul(A_tile, B_tile)\n        \n        # Calculate output scale\n        output_scale = A_scale * B_scale\n        \n        # Convert to float\n        C_float = C_int32.float() * output_scale\n        \n        # Reshape back\n        if len(original_shape) > 2:\n            C_float = C_float.reshape(*original_shape[:-1], N)\n        \n        return C_float\n\nclass ManualCrossEntropy:\n    \"\"\"Manual CrossEntropyLoss Implementation\"\"\"\n    \n    @staticmethod\n    def forward(logits, targets, label_smoothing=0.0):\n        \"\"\"\n        logits: (N, C) - predictions\n        targets: (N,) - true labels\n        \"\"\"\n        N, C = logits.shape\n        \n        # Manual softmax with numerical stability\n        max_logits = torch.max(logits, dim=1, keepdim=True)[0]\n        exp_logits = torch.exp(logits - max_logits)\n        sum_exp = torch.sum(exp_logits, dim=1, keepdim=True)\n        probs = exp_logits / (sum_exp + 1e-8)\n        \n        # Label smoothing\n        if label_smoothing > 0:\n            one_hot = torch.zeros_like(probs)\n            one_hot.scatter_(1, targets.unsqueeze(1), 1)\n            smooth_labels = one_hot * (1 - label_smoothing) + label_smoothing / C\n            log_probs = torch.log(probs + 1e-8)\n            loss = -torch.sum(smooth_labels * log_probs) / N\n        else:\n            log_probs = torch.log(probs[range(N), targets] + 1e-8)\n            loss = -torch.mean(log_probs)\n        \n        return loss\n\nclass ManualLayerNorm:\n    \"\"\"Manual LayerNorm Implementation\"\"\"\n    \n    @staticmethod\n    def forward(x, weight, bias, eps=1e-5):\n        \"\"\"Layer normalization\"\"\"\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        x_norm = (x - mean) / torch.sqrt(var + eps)\n        output = x_norm * weight + bias\n        return output\n\nclass ManualGELU:\n    \"\"\"Manual GELU Activation\"\"\"\n    \n    @staticmethod\n    def forward(x):\n        \"\"\"GELU(x) = 0.5 * x * (1 + tanh(sqrt(2/pi) * (x + 0.044715 * x^3)))\"\"\"\n        return 0.5 * x * (1 + torch.tanh(0.7978845608 * (x + 0.044715 * x * x * x)))\n\nclass ManualSoftmax:\n    \"\"\"Manual Softmax Implementation\"\"\"\n    \n    @staticmethod\n    def forward(x, dim=-1):\n        \"\"\"Softmax with numerical stability\"\"\"\n        max_vals = torch.max(x, dim=dim, keepdim=True)[0]\n        exp_x = torch.exp(x - max_vals)\n        sum_exp = torch.sum(exp_x, dim=dim, keepdim=True)\n        return exp_x / (sum_exp + 1e-8)\n\n# ============================================================================\n# QUANTIZED MODEL COMPONENTS\n# ============================================================================\n\nclass QuantizedLinear(nn.Module):\n    \"\"\"Linear layer with INT8 quantization support\"\"\"\n    \n    def __init__(self, in_features, out_features):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        \n        self.weight = nn.Parameter(torch.randn(out_features, in_features) * 0.02)\n        self.bias = nn.Parameter(torch.zeros(out_features))\n        \n        self.register_buffer('weight_scale', torch.ones(1))\n        self.register_buffer('weight_zp', torch.zeros(1))\n        \n        self.quantized = False\n        self.weight_int8 = None\n    \n    def quantize_weights(self):\n        \"\"\"Quantize weights to INT8\"\"\"\n        with torch.no_grad():\n            scale, zp = ManualQuantizer.calculate_qparams(self.weight, symmetric=True)\n            self.weight_scale.copy_(scale)\n            self.weight_zp.copy_(zp)\n            self.weight_int8 = ManualQuantizer.quantize_tensor(self.weight, scale, zp)\n            self.quantized = True\n    \n    def forward(self, x):\n        if self.training or not self.quantized:\n            return TiledMatMul.matmul_tiled(x, self.weight.t()) + self.bias\n        else:\n            x_scale, x_zp = ManualQuantizer.calculate_qparams(x, symmetric=True)\n            x_int8 = ManualQuantizer.quantize_tensor(x, x_scale, x_zp)\n            output = TiledMatMul.matmul_int8(\n                x_int8, self.weight_int8.t(),\n                x_scale, self.weight_scale,\n                x_zp, self.weight_zp\n            )\n            return output + self.bias\n\nclass PatchEmbedding(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, embed_dim=256):\n        super().__init__()\n        self.patch_size = patch_size\n        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n        \n    def forward(self, x):\n        x = self.proj(x)\n        x = x.flatten(2).transpose(1, 2)\n        return x\n\nclass QuantizedMultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout=0.1):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.qkv = QuantizedLinear(embed_dim, embed_dim * 3)\n        self.attn_drop = nn.Dropout(dropout)\n        self.proj = QuantizedLinear(embed_dim, embed_dim)\n        self.proj_drop = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        \n        # QKV projection\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]  # Each: (B, num_heads, N, head_dim)\n        \n        # Attention scores: (B, num_heads, N, N)\n        # Using standard matmul for 4D tensors\n        attn = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n        attn = ManualSoftmax.forward(attn, dim=-1)\n        attn = self.attn_drop(attn)\n        \n        # Attention output: (B, num_heads, N, head_dim)\n        x = torch.matmul(attn, v)\n        x = x.transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\nclass QuantizedMLP(nn.Module):\n    def __init__(self, in_features, hidden_features=None, drop=0.1):\n        super().__init__()\n        hidden_features = hidden_features or int(in_features * 3.0)\n        \n        self.fc1 = QuantizedLinear(in_features, hidden_features)\n        self.fc2 = QuantizedLinear(hidden_features, in_features)\n        self.drop = nn.Dropout(drop)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = ManualGELU.forward(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\nclass QuantizedTransformerBlock(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=3.0, drop=0.1):\n        super().__init__()\n        self.norm1_weight = nn.Parameter(torch.ones(dim))\n        self.norm1_bias = nn.Parameter(torch.zeros(dim))\n        self.attn = QuantizedMultiHeadAttention(dim, num_heads, drop)\n        \n        self.norm2_weight = nn.Parameter(torch.ones(dim))\n        self.norm2_bias = nn.Parameter(torch.zeros(dim))\n        self.mlp = QuantizedMLP(dim, hidden_features=int(dim * mlp_ratio), drop=drop)\n        \n    def forward(self, x):\n        x_norm1 = ManualLayerNorm.forward(x, self.norm1_weight, self.norm1_bias)\n        x = x + self.attn(x_norm1)\n        \n        x_norm2 = ManualLayerNorm.forward(x, self.norm2_weight, self.norm2_bias)\n        x = x + self.mlp(x_norm2)\n        \n        return x\n\nclass QuantizedViT(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=3.0, dropout=0.1):\n        super().__init__()\n        \n        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        num_patches = (img_size // patch_size) ** 2\n        \n        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n        self.pos_drop = nn.Dropout(dropout)\n        \n        self.blocks = nn.ModuleList([\n            QuantizedTransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n            for _ in range(depth)\n        ])\n        \n        self.norm_weight = nn.Parameter(torch.ones(embed_dim))\n        self.norm_bias = nn.Parameter(torch.zeros(embed_dim))\n        self.head = QuantizedLinear(embed_dim, num_classes)\n        \n        self._init_weights()\n        \n    def _init_weights(self):\n        nn.init.kaiming_normal_(self.patch_embed.proj.weight, mode='fan_out')\n        if self.patch_embed.proj.bias is not None:\n            nn.init.constant_(self.patch_embed.proj.bias, 0)\n        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n    \n    def quantize_model(self):\n        \"\"\"Quantize all linear layers to INT8\"\"\"\n        print(\"Quantizing model to INT8...\")\n        for module in self.modules():\n            if isinstance(module, QuantizedLinear):\n                module.quantize_weights()\n        print(\"Model quantized successfully!\")\n    \n    def forward(self, x):\n        x = self.patch_embed(x)\n        x = x + self.pos_embed\n        x = self.pos_drop(x)\n\n        for block in self.blocks:\n            x = block(x)\n\n        x = ManualLayerNorm.forward(x, self.norm_weight, self.norm_bias)\n        x = x.mean(dim=1)\n        x = self.head(x)\n        \n        return x\n\n# ============================================================================\n# CONFIGURATION & DATA\n# ============================================================================\n\nclass Config:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    img_size = 64\n    patch_size = 8\n    embed_dim = 256\n    depth = 6\n    num_heads = 8\n    mlp_ratio = 3.0\n    \n    batch_size = 128\n    num_epochs = 50\n    initial_lr = 0.001\n    weight_decay = 0.05\n    \n    num_workers = 4\n    pin_memory = True\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\nbase_path = \"/kaggle/input/cifar10-64x64-resized-via-cai-super-resolution/cifar10-32\"\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomCrop(config.img_size, padding=4, padding_mode='reflect'),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616]),\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n])\n\ndef create_dataframe(split):\n    data = []\n    split_path = os.path.join(base_path, split)\n    \n    for class_name in sorted(os.listdir(split_path)):\n        class_path = os.path.join(split_path, class_name)\n        if os.path.isdir(class_path):\n            for img_name in os.listdir(class_path):\n                img_path = os.path.join(class_path, img_name)\n                data.append([img_path, class_name])\n    \n    return pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n\nprint(\"Loading dataset...\")\nstart_time = time.time()\n\ntrain_df = create_dataframe(\"train\")\ntest_df = create_dataframe(\"test\")\n\nle = LabelEncoder()\ntrain_df[\"label\"] = le.fit_transform(train_df[\"label\"])\ntest_df[\"label\"] = le.transform(test_df[\"label\"])\n\nprint(f\"Dataset loaded in {time.time() - start_time:.2f}s\")\nprint(f\"Train: {len(train_df)}, Test: {len(test_df)}\")\n\nclass CIFARDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.image_paths = df[\"image_path\"].tolist()\n        self.labels = df[\"label\"].tolist()\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        try:\n            image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n            label = self.labels[idx]\n            \n            if self.transform:\n                image = self.transform(image)\n                \n            return image, label\n        except:\n            image = torch.zeros(3, config.img_size, config.img_size)\n            label = self.labels[idx]\n            return image, label\n\ntrain_dataset = CIFARDataset(train_df, transform=train_transform)\ntest_dataset = CIFARDataset(test_df, transform=test_transform)\n\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=config.batch_size, \n    shuffle=True,\n    num_workers=config.num_workers,\n    pin_memory=config.pin_memory\n)\n\ntest_loader = DataLoader(\n    test_dataset, \n    batch_size=config.batch_size, \n    shuffle=False,\n    num_workers=config.num_workers,\n    pin_memory=config.pin_memory\n)\n\n# ============================================================================\n# TRAINING\n# ============================================================================\n\ndef train_model(model, train_loader, test_loader, config):\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.initial_lr, weight_decay=config.weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.num_epochs)\n    \n    best_acc = 0.0\n    train_losses, test_accs = [], []\n    \n    print(\"Starting training...\")\n    \n    for epoch in range(config.num_epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(config.device), labels.to(config.device)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = ManualCrossEntropy.forward(outputs, labels, label_smoothing=0.1)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n        \n        model.eval()\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for images, labels in test_loader:\n                images, labels = images.to(config.device), labels.to(config.device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        test_acc = 100. * correct / total\n        avg_loss = train_loss / len(train_loader)\n        \n        train_losses.append(avg_loss)\n        test_accs.append(test_acc)\n        \n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save(model.state_dict(), 'best_model.pth')\n        \n        scheduler.step()\n        \n        if (epoch + 1) % 5 == 0:\n            print(f'Epoch [{epoch+1}/{config.num_epochs}], Loss: {avg_loss:.4f}, Acc: {test_acc:.2f}%, Best: {best_acc:.2f}%')\n    \n    print(f'Best Accuracy: {best_acc:.2f}%')\n    return train_losses, test_accs, best_acc\n\n# ============================================================================\n# MAIN\n# ============================================================================\n\nif __name__ == \"__main__\":\n    print(\"=\"*60)\n    print(\"MANUAL INT8 QUANTIZED ViT - COMPLETE IMPLEMENTATION\")\n    print(\"=\"*60)\n    \n    model = QuantizedViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        mlp_ratio=config.mlp_ratio,\n        num_classes=len(le.classes_)\n    ).to(config.device)\n    \n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Model parameters: {total_params:,}\")\n    \n    train_losses, test_accs, best_acc = train_model(model, train_loader, test_loader, config)\n    \n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses)\n    plt.title('Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.grid(True)\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(test_accs)\n    plt.title('Test Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig('training_results.png')\n    plt.show()\n    \n    print(f\"\\nApplying INT8 Quantization...\")\n    model.load_state_dict(torch.load('best_model.pth'))\n    model.quantize_model()\n    \n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(config.device), labels.to(config.device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    quant_acc = 100. * correct / total\n    \n    torch.save(model.state_dict(), 'quantized_int8_model.pth')\n    \n    print(f\"\\n{'='*60}\")\n    print(\"INT8 QUANTIZATION RESULTS\")\n    print(f\"{'='*60}\")\n    print(f\"Original FP32 Accuracy: {best_acc:.2f}%\")\n    print(f\"Quantized INT8 Accuracy: {quant_acc:.2f}%\")\n    print(f\"Accuracy Drop: {best_acc - quant_acc:.2f}%\")\n    print(f\"\\nSUCCESS - Model saved with manual INT8 quantization!\")\n    print(\"All operations implemented manually:\")\n    print(\"  - CrossEntropy Loss\")\n    print(\"  - Matrix Multiplication with Tiling\")\n    print(\"  - LayerNorm\")\n    print(\"  - GELU Activation\")\n    print(\"  - Softmax\")\n    print(\"  - INT8 Quantization/Dequantization\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T10:23:34.043167Z","iopub.execute_input":"2025-09-29T10:23:34.043703Z","execution_failed":"2025-09-29T10:39:46.668Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading dataset...\nDataset loaded in 0.11s\nTrain: 50000, Test: 10000\n============================================================\nMANUAL INT8 QUANTIZED ViT - COMPLETE IMPLEMENTATION\n============================================================\nModel parameters: 4,019,466\nStarting training...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport math\nimport os\nimport json\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport time\nfrom sklearn.preprocessing import LabelEncoder\n\n# Configuration\nclass Config:\n    # Hardware settings\n    device = \"cpu\"  # We'll use numpy only\n    \n    # Model architecture (adjusted for 32x32 input)\n    img_size = 64  # Changed from 64 to 32 to match actual data\n    patch_size = 8\n    embed_dim = 256\n    depth = 6\n    num_heads = 8\n    mlp_ratio = 3.0\n    \n    # Training settings (optimized for numpy)\n    batch_size = 64\n    num_epochs = 100\n    learning_rate = 0.001\n    weight_decay = 0.05\n    warmup_epochs = 10\n    \n    # Quantization settings\n    weight_bits = 8\n    activation_bits = 8\n    \n    # Export settings\n    export_dir = \"rtl_export_no_api\"\n    \n    # Dataset path\n    base_path = \"/kaggle/input/cifar10-64x64-resized-via-cai-super-resolution/cifar10-64\"\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\nprint(f\"Image size: {config.img_size}x{config.img_size}\")\n\n# ============================================================================\n# OPTIMIZED NUMPY OPERATIONS FOR HIGH PERFORMANCE\n# ============================================================================\n\ndef optimized_conv2d(input_data, weight, bias=None, stride=1, padding=0):\n    \"\"\"Highly optimized 2D convolution using im2col\"\"\"\n    batch, in_ch, in_h, in_w = input_data.shape\n    out_ch, _, k_h, k_w = weight.shape\n    \n    # Add padding\n    if padding > 0:\n        input_padded = np.pad(input_data, ((0,0), (0,0), (padding,padding), (padding,padding)), 'constant')\n    else:\n        input_padded = input_data\n    \n    out_h = (in_h + 2*padding - k_h) // stride + 1\n    out_w = (in_w + 2*padding - k_w) // stride + 1\n    \n    # im2col implementation\n    cols = np.zeros((batch, in_ch * k_h * k_w, out_h * out_w))\n    \n    for i in range(out_h):\n        for j in range(out_w):\n            h_start = i * stride\n            w_start = j * stride\n            patch = input_padded[:, :, h_start:h_start+k_h, w_start:w_start+k_w]\n            cols[:, :, i*out_w + j] = patch.reshape(batch, -1)\n    \n    weight_flat = weight.reshape(out_ch, -1)\n    output = np.einsum('oi,bij->boj', weight_flat, cols)\n    output = output.reshape(batch, out_ch, out_h, out_w)\n    \n    if bias is not None:\n        output += bias.reshape(1, -1, 1, 1)\n    \n    return output\n\ndef optimized_linear(input_data, weight, bias=None):\n    \"\"\"Optimized linear layer using einsum\"\"\"\n    if len(input_data.shape) == 3:  # Batch processing\n        output = np.einsum('bni,oi->bno', input_data, weight)\n    else:\n        output = np.dot(input_data, weight.T)\n    \n    if bias is not None:\n        output += bias\n    \n    return output\n\ndef optimized_layer_norm(x, weight, bias, eps=1e-5):\n    \"\"\"Vectorized layer normalization\"\"\"\n    mean = np.mean(x, axis=-1, keepdims=True)\n    var = np.var(x, axis=-1, keepdims=True)\n    x_norm = (x - mean) / np.sqrt(var + eps)\n    return x_norm * weight + bias\n\ndef optimized_softmax(x, axis=-1):\n    \"\"\"Numerically stable softmax\"\"\"\n    x_shifted = x - np.max(x, axis=axis, keepdims=True)\n    exp_x = np.exp(x_shifted)\n    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n\ndef optimized_gelu(x):\n    \"\"\"Fast GELU approximation\"\"\"\n    return 0.5 * x * (1 + np.tanh(np.sqrt(2/np.pi) * (x + 0.044715 * x**3)))\n\ndef optimized_attention(q, k, v, mask=None):\n    \"\"\"Optimized multi-head attention\"\"\"\n    d_k = q.shape[-1]\n    scores = np.matmul(q, k.transpose(0, 1, 3, 2)) / np.sqrt(d_k)\n    \n    if mask is not None:\n        scores = scores + mask\n    \n    attn_weights = optimized_softmax(scores, axis=-1)\n    output = np.matmul(attn_weights, v)\n    return output\n\ndef optimized_dropout(x, p=0.1, training=True):\n    \"\"\"Dropout implementation\"\"\"\n    if not training or p == 0:\n        return x\n    mask = (np.random.random(x.shape) > p) / (1 - p)\n    return x * mask\n\ndef cross_entropy_loss(predictions, targets):\n    \"\"\"Stable cross entropy loss\"\"\"\n    batch_size = predictions.shape[0]\n    \n    # Numerical stability\n    predictions = predictions - np.max(predictions, axis=1, keepdims=True)\n    exp_pred = np.exp(predictions)\n    softmax_pred = exp_pred / np.sum(exp_pred, axis=1, keepdims=True)\n    \n    # Cross entropy\n    correct_logprobs = -np.log(softmax_pred[np.arange(batch_size), targets] + 1e-8)\n    loss = np.mean(correct_logprobs)\n    return loss\n\ndef accuracy(predictions, targets):\n    \"\"\"Accuracy calculation\"\"\"\n    predicted_classes = np.argmax(predictions, axis=1)\n    correct = np.sum(predicted_classes == targets)\n    return correct / len(targets)\n\n# ============================================================================\n# ADVANCED ViT IMPLEMENTATION WITH PROPER INITIALIZATION\n# ============================================================================\n\nclass AdvancedPatchEmbedding:\n    def __init__(self, img_size, patch_size, in_channels, embed_dim):\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.in_channels = in_channels\n        self.embed_dim = embed_dim\n        self.num_patches = (img_size // patch_size) ** 2\n        \n        # Advanced weight initialization (Xavier/Glorot)\n        std = math.sqrt(2.0 / (in_channels * patch_size * patch_size))\n        self.weight = np.random.normal(0, std, (embed_dim, in_channels, patch_size, patch_size))\n        self.bias = np.zeros(embed_dim)\n        \n    def forward(self, x, training=True):\n        batch_size = x.shape[0]\n        \n        # Apply convolution\n        x_conv = optimized_conv2d(x, self.weight, self.bias, stride=self.patch_size, padding=0)\n        \n        # Reshape to (batch, num_patches, embed_dim)\n        out_h = self.img_size // self.patch_size\n        out_w = self.img_size // self.patch_size\n        num_patches = out_h * out_w\n        \n        # Fix: Ensure the reshape dimensions match\n        x_reshaped = x_conv.reshape(batch_size, self.embed_dim, num_patches)\n        x_out = x_reshaped.transpose(0, 2, 1)\n        \n        return x_out\n\nclass AdvancedMultiHeadAttention:\n    def __init__(self, embed_dim, num_heads, dropout=0.1):\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        self.dropout = dropout\n        \n        # Advanced initialization\n        std = math.sqrt(2.0 / embed_dim)\n        self.qkv_weight = np.random.normal(0, std, (embed_dim * 3, embed_dim))\n        self.qkv_bias = np.zeros(embed_dim * 3)\n        self.proj_weight = np.random.normal(0, std, (embed_dim, embed_dim))\n        self.proj_bias = np.zeros(embed_dim)\n        \n    def forward(self, x, training=True):\n        batch_size, seq_len, embed_dim = x.shape\n        \n        # Linear projection for QKV\n        qkv = optimized_linear(x, self.qkv_weight, self.qkv_bias)\n        \n        # Reshape for multi-head attention\n        qkv = qkv.reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)\n        qkv = qkv.transpose(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        # Scaled dot-product attention\n        attn_output = optimized_attention(q, k, v)\n        \n        # Combine heads\n        attn_output = attn_output.transpose(0, 2, 1, 3).reshape(batch_size, seq_len, embed_dim)\n        \n        # Final projection with dropout\n        output = optimized_linear(attn_output, self.proj_weight, self.proj_bias)\n        if training:\n            output = optimized_dropout(output, p=self.dropout, training=training)\n        \n        return output\n\nclass AdvancedMLP:\n    def __init__(self, in_features, hidden_features, dropout=0.1):\n        self.in_features = in_features\n        self.hidden_features = hidden_features\n        self.dropout = dropout\n        \n        # Advanced initialization\n        std1 = math.sqrt(2.0 / in_features)\n        std2 = math.sqrt(2.0 / hidden_features)\n        \n        self.fc1_weight = np.random.normal(0, std1, (hidden_features, in_features))\n        self.fc1_bias = np.zeros(hidden_features)\n        self.fc2_weight = np.random.normal(0, std2, (in_features, hidden_features))\n        self.fc2_bias = np.zeros(in_features)\n        \n    def forward(self, x, training=True):\n        # First layer with GELU and dropout\n        x = optimized_linear(x, self.fc1_weight, self.fc1_bias)\n        x = optimized_gelu(x)\n        if training:\n            x = optimized_dropout(x, p=self.dropout, training=training)\n        \n        # Second layer with dropout\n        x = optimized_linear(x, self.fc2_weight, self.fc2_bias)\n        if training:\n            x = optimized_dropout(x, p=self.dropout, training=training)\n        \n        return x\n\nclass AdvancedTransformerBlock:\n    def __init__(self, dim, num_heads, mlp_ratio=4.0, dropout=0.1):\n        self.dim = dim\n        self.num_heads = num_heads\n        self.mlp_ratio = mlp_ratio\n        \n        # Layer norms\n        self.norm1_weight = np.ones(dim)\n        self.norm1_bias = np.zeros(dim)\n        self.norm2_weight = np.ones(dim)\n        self.norm2_bias = np.zeros(dim)\n        \n        # Attention and MLP\n        self.attn = AdvancedMultiHeadAttention(dim, num_heads, dropout)\n        self.mlp = AdvancedMLP(dim, int(dim * mlp_ratio), dropout)\n        \n    def forward(self, x, training=True):\n        # Pre-norm architecture (more stable)\n        # Attention with residual\n        x_norm1 = optimized_layer_norm(x, self.norm1_weight, self.norm1_bias)\n        attn_out = self.attn.forward(x_norm1, training)\n        x = x + attn_out\n        \n        # MLP with residual\n        x_norm2 = optimized_layer_norm(x, self.norm2_weight, self.norm2_bias)\n        mlp_out = self.mlp.forward(x_norm2, training)\n        x = x + mlp_out\n        \n        return x\n\nclass AdvancedViT:\n    def __init__(self, img_size=32, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=3.0, dropout=0.1):\n        \n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.in_channels = in_channels\n        self.num_classes = num_classes\n        self.embed_dim = embed_dim\n        self.depth = depth\n        self.num_heads = num_heads\n        self.training = True\n        \n        # Patch embedding\n        self.patch_embed = AdvancedPatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        self.num_patches = (img_size // patch_size) ** 2\n        \n        print(f\"Model configured for {img_size}x{img_size} images -> {self.num_patches} patches\")\n        \n        # Learnable positional embeddings - FIXED: match actual number of patches\n        self.pos_embed = np.random.normal(0, 0.02, (1, self.num_patches, embed_dim))\n        \n        # Dropout\n        self.pos_dropout = dropout\n        \n        # Transformer blocks\n        self.blocks = []\n        for _ in range(depth):\n            self.blocks.append(AdvancedTransformerBlock(embed_dim, num_heads, mlp_ratio, dropout))\n        \n        # Final normalization and head\n        self.norm_weight = np.ones(embed_dim)\n        self.norm_bias = np.zeros(embed_dim)\n        \n        # Classifier head with proper initialization\n        std = math.sqrt(2.0 / embed_dim)\n        self.head_weight = np.random.normal(0, std, (num_classes, embed_dim))\n        self.head_bias = np.zeros(num_classes)\n        \n    def train(self):\n        self.training = True\n        return self\n        \n    def eval(self):\n        self.training = False\n        return self\n        \n    def forward(self, x, training=None):\n        if training is None:\n            training = self.training\n            \n        batch_size = x.shape[0]\n        \n        # Patch embedding\n        x = self.patch_embed.forward(x, training)\n        \n        # Add positional embeddings\n        x = x + self.pos_embed\n        \n        # Apply dropout\n        if training:\n            x = optimized_dropout(x, p=self.pos_dropout, training=training)\n        \n        # Transformer blocks\n        for block in self.blocks:\n            x = block.forward(x, training)\n        \n        # Final normalization\n        x = optimized_layer_norm(x, self.norm_weight, self.norm_bias)\n        \n        # Global average pooling\n        x = np.mean(x, axis=1)\n        \n        # Classification head\n        x = optimized_linear(x, self.head_weight, self.head_bias)\n        \n        return x\n    \n    def get_parameters(self):\n        \"\"\"Get all parameters for saving/loading\"\"\"\n        params = {}\n        \n        # Patch embedding\n        params['patch_embed.weight'] = self.patch_embed.weight\n        params['patch_embed.bias'] = self.patch_embed.bias\n        \n        # Positional embedding\n        params['pos_embed'] = self.pos_embed\n        \n        # Transformer blocks\n        for i, block in enumerate(self.blocks):\n            # Attention\n            params[f'blocks.{i}.attn.qkv_weight'] = block.attn.qkv_weight\n            params[f'blocks.{i}.attn.qkv_bias'] = block.attn.qkv_bias\n            params[f'blocks.{i}.attn.proj_weight'] = block.attn.proj_weight\n            params[f'blocks.{i}.attn.proj_bias'] = block.attn.proj_bias\n            \n            # Layer norms\n            params[f'blocks.{i}.norm1_weight'] = block.norm1_weight\n            params[f'blocks.{i}.norm1_bias'] = block.norm1_bias\n            params[f'blocks.{i}.norm2_weight'] = block.norm2_weight\n            params[f'blocks.{i}.norm2_bias'] = block.norm2_bias\n            \n            # MLP\n            params[f'blocks.{i}.mlp.fc1_weight'] = block.mlp.fc1_weight\n            params[f'blocks.{i}.mlp.fc1_bias'] = block.mlp.fc1_bias\n            params[f'blocks.{i}.mlp.fc2_weight'] = block.mlp.fc2_weight\n            params[f'blocks.{i}.mlp.fc2_bias'] = block.mlp.fc2_bias\n        \n        # Final layers\n        params['norm_weight'] = self.norm_weight\n        params['norm_bias'] = self.norm_bias\n        params['head_weight'] = self.head_weight\n        params['head_bias'] = self.head_bias\n        \n        return params\n    \n    def set_parameters(self, params_dict):\n        \"\"\"Set parameters from dictionary\"\"\"\n        # Patch embedding\n        self.patch_embed.weight = params_dict['patch_embed.weight']\n        self.patch_embed.bias = params_dict['patch_embed.bias']\n        \n        # Positional embedding\n        self.pos_embed = params_dict['pos_embed']\n        \n        # Transformer blocks\n        for i, block in enumerate(self.blocks):\n            block.attn.qkv_weight = params_dict[f'blocks.{i}.attn.qkv_weight']\n            block.attn.qkv_bias = params_dict[f'blocks.{i}.attn.qkv_bias']\n            block.attn.proj_weight = params_dict[f'blocks.{i}.attn.proj_weight']\n            block.attn.proj_bias = params_dict[f'blocks.{i}.attn.proj_bias']\n            \n            block.norm1_weight = params_dict[f'blocks.{i}.norm1_weight']\n            block.norm1_bias = params_dict[f'blocks.{i}.norm1_bias']\n            block.norm2_weight = params_dict[f'blocks.{i}.norm2_weight']\n            block.norm2_bias = params_dict[f'blocks.{i}.norm2_bias']\n            \n            block.mlp.fc1_weight = params_dict[f'blocks.{i}.mlp.fc1_weight']\n            block.mlp.fc1_bias = params_dict[f'blocks.{i}.mlp.fc1_bias']\n            block.mlp.fc2_weight = params_dict[f'blocks.{i}.mlp.fc2_weight']\n            block.mlp.fc2_bias = params_dict[f'blocks.{i}.mlp.fc2_bias']\n        \n        # Final layers\n        self.norm_weight = params_dict['norm_weight']\n        self.norm_bias = params_dict['norm_bias']\n        self.head_weight = params_dict['head_weight']\n        self.head_bias = params_dict['head_bias']\n\n# ============================================================================\n# ADVANCED TRAINING WITH OPTIMIZATIONS\n# ============================================================================\n\nclass AdamWOptimizer:\n    \"\"\"Manual AdamW optimizer implementation\"\"\"\n    def __init__(self, params, lr=0.001, betas=(0.9, 0.999), weight_decay=0.01, eps=1e-8):\n        self.params = params\n        self.lr = lr\n        self.beta1, self.beta2 = betas\n        self.weight_decay = weight_decay\n        self.eps = eps\n        self.t = 0\n        \n        # Initialize moments\n        self.m = {}\n        self.v = {}\n        for key in params.keys():\n            self.m[key] = np.zeros_like(params[key])\n            self.v[key] = np.zeros_like(params[key])\n    \n    def step(self, grads):\n        \"\"\"Perform optimization step\"\"\"\n        self.t += 1\n        \n        for key in self.params.keys():\n            if key in grads:\n                # Weight decay\n                if self.weight_decay != 0:\n                    self.params[key] -= self.lr * self.weight_decay * self.params[key]\n                \n                # Update moments\n                self.m[key] = self.beta1 * self.m[key] + (1 - self.beta1) * grads[key]\n                self.v[key] = self.beta2 * self.v[key] + (1 - self.beta2) * (grads[key] ** 2)\n                \n                # Bias correction\n                m_hat = self.m[key] / (1 - self.beta1 ** self.t)\n                v_hat = self.v[key] / (1 - self.beta2 ** self.t)\n                \n                # Update parameters\n                self.params[key] -= self.lr * m_hat / (np.sqrt(v_hat) + self.eps)\n\ndef compute_gradients(model, x_batch, y_batch):\n    \"\"\"Manual gradient computation using finite differences\"\"\"\n    grads = {}\n    params = model.get_parameters()\n    epsilon = 1e-5\n    \n    # Forward pass to get original loss\n    original_output = model.forward(x_batch, training=False)\n    original_loss = cross_entropy_loss(original_output, y_batch)\n    \n    for key in params.keys():\n        grad = np.zeros_like(params[key])\n        param_flat = params[key].flatten()\n        grad_flat = grad.flatten()\n        \n        # Compute gradient for each parameter\n        for i in range(len(param_flat)):\n            # Save original value\n            original_val = param_flat[i]\n            \n            # Positive perturbation\n            param_flat[i] = original_val + epsilon\n            params[key] = param_flat.reshape(params[key].shape)\n            model.set_parameters(params)\n            \n            output_plus = model.forward(x_batch, training=False)\n            loss_plus = cross_entropy_loss(output_plus, y_batch)\n            \n            # Negative perturbation\n            param_flat[i] = original_val - epsilon\n            params[key] = param_flat.reshape(params[key].shape)\n            model.set_parameters(params)\n            \n            output_minus = model.forward(x_batch, training=False)\n            loss_minus = cross_entropy_loss(output_minus, y_batch)\n            \n            # Compute gradient\n            grad_flat[i] = (loss_plus - loss_minus) / (2 * epsilon)\n            \n            # Restore original value\n            param_flat[i] = original_val\n        \n        grads[key] = grad_flat.reshape(params[key].shape)\n    \n    # Restore original parameters\n    model.set_parameters(params)\n    return grads\n\ndef advanced_train_model(model, train_loader, test_loader, config):\n    \"\"\"Advanced training loop with optimizations\"\"\"\n    \n    train_losses = []\n    train_accs = []\n    test_accs = []\n    best_acc = 0.0\n    \n    # Initialize optimizer\n    params = model.get_parameters()\n    optimizer = AdamWOptimizer(params, lr=config.learning_rate, weight_decay=config.weight_decay)\n    \n    print(\"Starting advanced training...\")\n    \n    for epoch in range(config.num_epochs):\n        epoch_start = time.time()\n        \n        # Learning rate warmup\n        if epoch < config.warmup_epochs:\n            lr_scale = (epoch + 1) / config.warmup_epochs\n        else:\n            lr_scale = 0.5 * (1 + math.cos(math.pi * (epoch - config.warmup_epochs) / \n                                         (config.num_epochs - config.warmup_epochs)))\n        \n        current_lr = config.learning_rate * lr_scale\n        optimizer.lr = current_lr\n        \n        # Training phase\n        model.train()\n        running_loss = 0.0\n        running_corrects = 0\n        total_samples = 0\n        \n        batch_count = 0\n        for batch_idx, (inputs, targets) in enumerate(train_loader):\n            if batch_count >= 10:  # Use fewer batches for demonstration\n                break\n                \n            # Convert to numpy\n            inputs_np = inputs.numpy() if hasattr(inputs, 'numpy') else inputs\n            targets_np = targets.numpy() if hasattr(targets, 'numpy') else targets\n            \n            # Forward pass\n            outputs = model.forward(inputs_np, training=True)\n            \n            # Calculate loss and accuracy\n            loss = cross_entropy_loss(outputs, targets_np)\n            acc = accuracy(outputs, targets_np)\n            \n            # Compute gradients (simplified - in practice you'd use backpropagation)\n            grads = compute_gradients(model, inputs_np, targets_np)\n            \n            # Optimization step\n            optimizer.step(grads)\n            \n            running_loss += loss * inputs_np.shape[0]\n            running_corrects += acc * inputs_np.shape[0]\n            total_samples += inputs_np.shape[0]\n            \n            if batch_idx % 5 == 0:\n                print(f'  Batch [{batch_idx}/{len(train_loader)}], Loss: {loss:.4f}, Acc: {acc*100:.2f}%')\n            \n            batch_count += 1\n        \n        if total_samples > 0:\n            epoch_loss = running_loss / total_samples\n            epoch_acc = 100. * running_corrects / total_samples\n        else:\n            epoch_loss = 0\n            epoch_acc = 0\n        \n        # Test phase\n        test_acc = advanced_evaluate_model(model, test_loader, config)\n        \n        train_losses.append(epoch_loss)\n        train_accs.append(epoch_acc)\n        test_accs.append(test_acc)\n        \n        if test_acc > best_acc:\n            best_acc = test_acc\n            # Save model parameters\n            model_params = model.get_parameters()\n            np.savez('best_advanced_model.npz', **model_params)\n        \n        epoch_time = time.time() - epoch_start\n        print(f'Epoch [{epoch+1}/{config.num_epochs}] ({epoch_time:.1f}s), LR: {current_lr:.6f}, '\n              f'Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, Test Acc: {test_acc:.2f}%, Best: {best_acc:.2f}%')\n    \n    # Load best model\n    if os.path.exists('best_advanced_model.npz'):\n        best_params = np.load('best_advanced_model.npz')\n        model.set_parameters(best_params)\n    \n    print(f'Training completed! Best Test Accuracy: {best_acc:.2f}%')\n    return train_losses, train_accs, test_accs, best_acc\n\ndef advanced_evaluate_model(model, test_loader, config):\n    \"\"\"Advanced evaluation with more samples\"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n    \n    batch_count = 0\n    for inputs, targets in test_loader:\n        if batch_count >= 5:  # Fewer test samples for demonstration\n            break\n            \n        inputs_np = inputs.numpy() if hasattr(inputs, 'numpy') else inputs\n        targets_np = targets.numpy() if hasattr(targets, 'numpy') else targets\n        \n        outputs = model.forward(inputs_np, training=False)\n        predicted = np.argmax(outputs, axis=1)\n        \n        total += targets_np.shape[0]\n        correct += np.sum(predicted == targets_np)\n        \n        batch_count += 1\n    \n    accuracy = 100. * correct / total if total > 0 else 0\n    return accuracy\n\n# ============================================================================\n# DATA LOADING AND PREPROCESSING\n# ============================================================================\n\ndef create_dataframe(split):\n    \"\"\"Create DataFrame with image paths and labels\"\"\"\n    data = []\n    split_path = os.path.join(config.base_path, split)\n    \n    for class_name in sorted(os.listdir(split_path)):\n        class_path = os.path.join(split_path, class_name)\n        if os.path.isdir(class_path):\n            for img_name in os.listdir(class_path):\n                img_path = os.path.join(class_path, img_name)\n                data.append([img_path, class_name])\n    \n    return pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n\nclass CIFAR10Dataset:\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n        self.unique_labels = sorted(self.dataframe['label'].unique())\n        self.class_to_idx = {label: idx for idx, label in enumerate(self.unique_labels)}\n        print(f\"Detected classes: {self.class_to_idx}\")\n    \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, idx):\n        img_path = self.dataframe.iloc[idx]['image_path']\n        label_name = self.dataframe.iloc[idx]['label']\n        label = self.class_to_idx[label_name]\n        \n        # Load image\n        image = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\ndef load_cifar10_custom():\n    \"\"\"Load CIFAR-10 data from custom path\"\"\"\n    print(\"Loading dataset from custom path...\")\n    start_time = time.time()\n    \n    # Create dataframes\n    train_df = create_dataframe(\"train\")\n    test_df = create_dataframe(\"test\")\n    \n    print(f\"Train samples: {len(train_df)}, Test samples: {len(test_df)}\")\n    \n    # Define transforms (using PyTorch transforms for convenience, but we'll convert to numpy)\n    try:\n        import torch\n        from torchvision import transforms\n        \n        train_transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n        ])\n        \n        test_transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n        ])\n        \n        # Create datasets\n        train_dataset = CIFAR10Dataset(train_df, transform=train_transform)\n        test_dataset = CIFAR10Dataset(test_df, transform=test_transform)\n        \n        # Create data loaders\n        train_loader = torch.utils.data.DataLoader(\n            train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2\n        )\n        \n        test_loader = torch.utils.data.DataLoader(\n            test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2\n        )\n        \n    except ImportError:\n        print(\"PyTorch not available, creating dummy data loaders...\")\n        # Create dummy data for testing\n        class DummyDataLoader:\n            def __init__(self, batch_size=64):\n                self.batch_size = batch_size\n                \n            def __iter__(self):\n                # Generate dummy data with correct shape (32x32 images)\n                dummy_images = np.random.randn(self.batch_size, 3, 32, 32).astype(np.float32)\n                dummy_labels = np.random.randint(0, 10, (self.batch_size,))\n                yield dummy_images, dummy_labels\n                \n            def __len__(self):\n                return 100\n        \n        train_loader = DummyDataLoader(config.batch_size)\n        test_loader = DummyDataLoader(config.batch_size)\n    \n    load_time = time.time() - start_time\n    print(f\"Dataset loaded in {load_time:.2f} seconds\")\n    \n    return train_loader, test_loader\n\n# ============================================================================\n# QUANTIZATION AND EXPORT\n# ============================================================================\n\ndef symmetric_quantize(x, bits=8, scale=None):\n    \"\"\"Symmetric quantization for RTL export\"\"\"\n    if scale is None:\n        max_val = np.max(np.abs(x))\n        if max_val == 0:\n            scale = 1.0\n        else:\n            scale = max_val / (2**(bits-1) - 1)\n    \n    x_q = np.round(x / scale)\n    x_q = np.clip(x_q, -(2**(bits-1)), 2**(bits-1) - 1)\n    return x_q.astype(np.int32), scale\n\ndef export_advanced_model(model, config):\n    \"\"\"Export advanced model for RTL\"\"\"\n    os.makedirs(config.export_dir, exist_ok=True)\n    \n    params = model.get_parameters()\n    \n    print(\"Exporting model parameters...\")\n    for name, param in params.items():\n        # Quantize parameter\n        q_param, scale = symmetric_quantize(param, config.weight_bits)\n        \n        # Export quantized parameter\n        filename = os.path.join(config.export_dir, f\"{name.replace('.', '_')}.mem\")\n        with open(filename, 'w') as f:\n            for val in q_param.flatten():\n                f.write(f\"{val & 0xFF:02x}\\n\")\n        \n        # Export scale information\n        scale_filename = os.path.join(config.export_dir, f\"{name.replace('.', '_')}_scale.txt\")\n        with open(scale_filename, 'w') as f:\n            f.write(f\"{scale}\\n\")\n    \n    # Export model architecture\n    arch_info = {\n        \"img_size\": config.img_size,\n        \"patch_size\": config.patch_size,\n        \"embed_dim\": config.embed_dim,\n        \"depth\": config.depth,\n        \"num_heads\": config.num_heads,\n        \"num_classes\": 10,\n        \"weight_bits\": config.weight_bits,\n        \"activation_bits\": config.activation_bits\n    }\n    \n    with open(os.path.join(config.export_dir, \"architecture.json\"), 'w') as f:\n        json.dump(arch_info, f, indent=2)\n    \n    print(f\"Export complete! Files saved to: {config.export_dir}\")\n\n# ============================================================================\n# VISUALIZATION AND ANALYSIS\n# ============================================================================\n\ndef visualize_training_results(train_losses, train_accs, test_accs):\n    \"\"\"Plot training results\"\"\"\n    plt.figure(figsize=(15, 5))\n    \n    plt.subplot(1, 3, 1)\n    plt.plot(train_losses)\n    plt.title('Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.grid(True)\n    \n    plt.subplot(1, 3, 2)\n    plt.plot(train_accs, label='Train')\n    plt.plot(test_accs, label='Test')\n    plt.title('Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.subplot(1, 3, 3)\n    plt.plot(test_accs)\n    plt.title('Test Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig('advanced_training_results.png', dpi=150, bbox_inches='tight')\n    plt.show()\n\ndef analyze_model_complexity(model):\n    \"\"\"Analyze model complexity and memory requirements\"\"\"\n    params = model.get_parameters()\n    \n    total_params = 0\n    memory_bytes = 0\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"MODEL COMPLEXITY ANALYSIS\")\n    print(\"=\"*50)\n    \n    for name, param in params.items():\n        param_count = param.size\n        param_memory = param.nbytes\n        total_params += param_count\n        memory_bytes += param_memory\n        \n        print(f\"{name:30} | Params: {param_count:8,} | Memory: {param_memory/1024:8.1f} KB | Shape: {param.shape}\")\n    \n    print(\"-\"*50)\n    print(f\"{'TOTAL':30} | Params: {total_params:8,} | Memory: {memory_bytes/1024/1024:8.2f} MB\")\n    print(f\"{'QUANTIZED (8-bit)':30} | Params: {total_params:8,} | Memory: {memory_bytes/8/1024/1024:8.2f} MB\")\n    \n    return total_params, memory_bytes\n\n# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\n\ndef main():\n    print(\"=\"*60)\n    print(\"ADVANCED ViT IMPLEMENTATION - NO PyTorch API\")\n    print(\"=\"*60)\n    \n    # Load data from custom path\n    train_loader, test_loader = load_cifar10_custom()\n    \n    # Create advanced manual model\n    model = AdvancedViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        mlp_ratio=config.mlp_ratio,\n        num_classes=10\n    )\n    \n    # Count parameters\n    params = model.get_parameters()\n    total_params = sum(p.size for p in params.values())\n    print(f\"Total parameters: {total_params:,}\")\n    \n    # Analyze model complexity\n    analyze_model_complexity(model)\n    \n    # Test forward pass\n    print(\"\\nTesting forward pass...\")\n    model.eval()\n    for batch_idx, (inputs, targets) in enumerate(train_loader):\n        if batch_idx >= 1:\n            break\n            \n        inputs_np = inputs.numpy() if hasattr(inputs, 'numpy') else inputs\n        targets_np = targets.numpy() if hasattr(targets, 'numpy') else targets\n        \n        outputs = model.forward(inputs_np, training=False)\n        loss = cross_entropy_loss(outputs, targets_np)\n        acc = accuracy(outputs, targets_np)\n        \n        print(f\"Forward pass successful!\")\n        print(f\"Input shape: {inputs_np.shape}\")\n        print(f\"Output shape: {outputs.shape}\")\n        print(f\"Test Loss: {loss:.4f}, Test Acc: {acc*100:.2f}%\")\n        break\n    \n    # Train model with advanced training (optional - can be skipped for quick testing)\n    train_model = input(\"\\nDo you want to train the model? (y/n): \").lower().strip()\n    if train_model == 'y':\n        train_losses, train_accs, test_accs, best_acc = advanced_train_model(\n            model, train_loader, test_loader, config\n        )\n        \n        # Plot training results\n        if train_losses and train_accs and test_accs:\n            visualize_training_results(train_losses, train_accs, test_accs)\n    else:\n        print(\"Skipping training...\")\n    \n    # Export model\n    export_advanced_model(model, config)\n    \n    print(f\"\\n\" + \"=\"*60)\n    print(\"ADVANCED IMPLEMENTATION COMPLETED SUCCESSFULLY!\")\n    print(\"=\"*60)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T14:08:12.122597Z","iopub.execute_input":"2025-09-29T14:08:12.122898Z","iopub.status.idle":"2025-09-29T14:16:53.329635Z","shell.execute_reply.started":"2025-09-29T14:08:12.122875Z","shell.execute_reply":"2025-09-29T14:16:53.328507Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\nImage size: 32x32\n============================================================\nADVANCED ViT IMPLEMENTATION - NO PyTorch API\n============================================================\nLoading dataset from custom path...\nTrain samples: 50000, Test samples: 10000\nDetected classes: {'class0': 0, 'class1': 1, 'class2': 2, 'class3': 3, 'class4': 4, 'class5': 5, 'class6': 6, 'class7': 7, 'class8': 8, 'class9': 9}\nDetected classes: {'class0': 0, 'class1': 1, 'class2': 2, 'class3': 3, 'class4': 4, 'class5': 5, 'class6': 6, 'class7': 7, 'class8': 8, 'class9': 9}\nDataset loaded in 0.36 seconds\nModel configured for 32x32 images -> 16 patches\nTotal parameters: 4,007,178\n\n==================================================\nMODEL COMPLEXITY ANALYSIS\n==================================================\npatch_embed.weight             | Params:   49,152 | Memory:    384.0 KB | Shape: (256, 3, 8, 8)\npatch_embed.bias               | Params:      256 | Memory:      2.0 KB | Shape: (256,)\npos_embed                      | Params:    4,096 | Memory:     32.0 KB | Shape: (1, 16, 256)\nblocks.0.attn.qkv_weight       | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.0.attn.qkv_bias         | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.0.attn.proj_weight      | Params:   65,536 | Memory:    512.0 KB | Shape: (256, 256)\nblocks.0.attn.proj_bias        | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.0.norm1_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.0.norm1_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.0.norm2_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.0.norm2_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.0.mlp.fc1_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.0.mlp.fc1_bias          | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.0.mlp.fc2_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (256, 768)\nblocks.0.mlp.fc2_bias          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.1.attn.qkv_weight       | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.1.attn.qkv_bias         | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.1.attn.proj_weight      | Params:   65,536 | Memory:    512.0 KB | Shape: (256, 256)\nblocks.1.attn.proj_bias        | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.1.norm1_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.1.norm1_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.1.norm2_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.1.norm2_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.1.mlp.fc1_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.1.mlp.fc1_bias          | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.1.mlp.fc2_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (256, 768)\nblocks.1.mlp.fc2_bias          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.2.attn.qkv_weight       | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.2.attn.qkv_bias         | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.2.attn.proj_weight      | Params:   65,536 | Memory:    512.0 KB | Shape: (256, 256)\nblocks.2.attn.proj_bias        | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.2.norm1_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.2.norm1_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.2.norm2_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.2.norm2_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.2.mlp.fc1_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.2.mlp.fc1_bias          | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.2.mlp.fc2_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (256, 768)\nblocks.2.mlp.fc2_bias          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.3.attn.qkv_weight       | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.3.attn.qkv_bias         | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.3.attn.proj_weight      | Params:   65,536 | Memory:    512.0 KB | Shape: (256, 256)\nblocks.3.attn.proj_bias        | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.3.norm1_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.3.norm1_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.3.norm2_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.3.norm2_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.3.mlp.fc1_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.3.mlp.fc1_bias          | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.3.mlp.fc2_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (256, 768)\nblocks.3.mlp.fc2_bias          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.4.attn.qkv_weight       | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.4.attn.qkv_bias         | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.4.attn.proj_weight      | Params:   65,536 | Memory:    512.0 KB | Shape: (256, 256)\nblocks.4.attn.proj_bias        | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.4.norm1_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.4.norm1_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.4.norm2_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.4.norm2_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.4.mlp.fc1_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.4.mlp.fc1_bias          | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.4.mlp.fc2_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (256, 768)\nblocks.4.mlp.fc2_bias          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.5.attn.qkv_weight       | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.5.attn.qkv_bias         | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.5.attn.proj_weight      | Params:   65,536 | Memory:    512.0 KB | Shape: (256, 256)\nblocks.5.attn.proj_bias        | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.5.norm1_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.5.norm1_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.5.norm2_weight          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.5.norm2_bias            | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nblocks.5.mlp.fc1_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (768, 256)\nblocks.5.mlp.fc1_bias          | Params:      768 | Memory:      6.0 KB | Shape: (768,)\nblocks.5.mlp.fc2_weight        | Params:  196,608 | Memory:   1536.0 KB | Shape: (256, 768)\nblocks.5.mlp.fc2_bias          | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nnorm_weight                    | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nnorm_bias                      | Params:      256 | Memory:      2.0 KB | Shape: (256,)\nhead_weight                    | Params:    2,560 | Memory:     20.0 KB | Shape: (10, 256)\nhead_bias                      | Params:       10 | Memory:      0.1 KB | Shape: (10,)\n--------------------------------------------------\nTOTAL                          | Params: 4,007,178 | Memory:    30.57 MB\nQUANTIZED (8-bit)              | Params: 4,007,178 | Memory:     3.82 MB\n\nTesting forward pass...\nForward pass successful!\nInput shape: (64, 3, 32, 32)\nOutput shape: (64, 10)\nTest Loss: 2.8799, Test Acc: 9.38%\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nDo you want to train the model? (y/n):  y\n"},{"name":"stdout","text":"Starting advanced training...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/200071915.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/200071915.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0mtrain_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDo you want to train the model? (y/n): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_model\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         train_losses, train_accs, test_accs, best_acc = advanced_train_model(\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         )\n","\u001b[0;32m/tmp/ipykernel_36/200071915.py\u001b[0m in \u001b[0;36madvanced_train_model\u001b[0;34m(model, train_loader, test_loader, config)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# Compute gradients (simplified - in practice you'd use backpropagation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# Optimization step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/200071915.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(model, x_batch, y_batch)\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0moutput_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m             \u001b[0mloss_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/200071915.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;31m# Transformer blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;31m# Final normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/200071915.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# Attention with residual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mx_norm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimized_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mattn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_norm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattn_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/200071915.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Linear projection for QKV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mqkv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimized_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# Reshape for multi-head attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/200071915.py\u001b[0m in \u001b[0;36moptimized_linear\u001b[0;34m(input_data, weight, bias)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;34m\"\"\"Optimized linear layer using einsum\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Batch processing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bni,oi->bno'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/einsumfunc.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspecified_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mc_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     \u001b[0;31m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport math\nimport time\nfrom torch.cuda.amp import autocast, GradScaler\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ==================== CUSTOM LAYERS FROM SCRATCH ====================\n\nclass CustomLinear(torch.nn.Module):\n    def __init__(self, in_features, out_features, bias=True):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        \n        # Initialize weights and biases\n        self.weight = torch.nn.Parameter(\n            torch.randn(out_features, in_features) * math.sqrt(2.0 / in_features)\n        )\n        if bias:\n            self.bias = torch.nn.Parameter(torch.zeros(out_features))\n        else:\n            self.register_parameter('bias', None)\n        \n    def forward(self, x):\n        output = x @ self.weight.t()\n        if self.bias is not None:\n            output += self.bias\n        return output\n\nclass CustomLayerNorm(torch.nn.Module):\n    def __init__(self, normalized_shape, eps=1e-5):\n        super().__init__()\n        self.normalized_shape = normalized_shape\n        self.eps = eps\n        self.weight = torch.nn.Parameter(torch.ones(normalized_shape))\n        self.bias = torch.nn.Parameter(torch.zeros(normalized_shape))\n        \n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n        output = self.weight * x_normalized + self.bias\n        return output\n\nclass CustomDropout(torch.nn.Module):\n    def __init__(self, p=0.1):\n        super().__init__()\n        self.p = p\n        \n    def forward(self, x):\n        if self.training and self.p > 0:\n            mask = (torch.rand_like(x) > self.p) / (1 - self.p)\n            return x * mask\n        return x\n\nclass CustomSoftmax(torch.nn.Module):\n    def forward(self, x):\n        x_max = x.max(dim=-1, keepdim=True)[0]\n        exp_x = torch.exp(x - x_max)\n        return exp_x / exp_x.sum(dim=-1, keepdim=True)\n\nclass CustomGELU(torch.nn.Module):\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n\nclass CustomConv2d(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        \n        # Initialize weights\n        self.weight = torch.nn.Parameter(\n            torch.randn(out_channels, in_channels, kernel_size, kernel_size) * \n            math.sqrt(2.0 / (in_channels * kernel_size * kernel_size))\n        )\n        self.bias = torch.nn.Parameter(torch.zeros(out_channels))\n        \n    def forward(self, x):\n        return F.conv2d(x, self.weight, self.bias, stride=self.stride, padding=self.padding)\n\n# ==================== CUSTOM ViT MODEL ====================\n\nclass CustomPatchEmbedding(torch.nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, embed_dim=256):\n        super().__init__()\n        self.patch_size = patch_size\n        self.proj = CustomConv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n        \n    def forward(self, x):\n        x = self.proj(x)\n        x = x.flatten(2).transpose(1, 2)\n        return x\n\nclass CustomMultiHeadAttention(torch.nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout=0.1):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.qkv = CustomLinear(embed_dim, embed_dim * 3)\n        self.attn_drop = CustomDropout(dropout)\n        self.proj = CustomLinear(embed_dim, embed_dim)\n        self.proj_drop = CustomDropout(dropout)\n        \n        self.softmax = CustomSoftmax()\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = self.softmax(attn)\n        attn = self.attn_drop(attn)\n        \n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\nclass CustomMLP(torch.nn.Module):\n    def __init__(self, in_features, hidden_features=None, drop=0.1):\n        super().__init__()\n        hidden_features = hidden_features or int(in_features * 4.0)\n        \n        self.fc1 = CustomLinear(in_features, hidden_features)\n        self.act = CustomGELU()\n        self.fc2 = CustomLinear(hidden_features, in_features)\n        self.drop = CustomDropout(drop)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\nclass CustomTransformerBlock(torch.nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4.0, drop=0.1):\n        super().__init__()\n        self.norm1 = CustomLayerNorm(dim)\n        self.attn = CustomMultiHeadAttention(dim, num_heads, drop)\n        self.norm2 = CustomLayerNorm(dim)\n        self.mlp = CustomMLP(dim, hidden_features=int(dim * mlp_ratio), drop=drop)\n        \n    def forward(self, x):\n        # Residual connection 1\n        residual = x\n        x = self.norm1(x)\n        x = self.attn(x)\n        x = x + residual\n        \n        # Residual connection 2\n        residual = x\n        x = self.norm2(x)\n        x = self.mlp(x)\n        x = x + residual\n        \n        return x\n\nclass CustomViT(torch.nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=4.0, dropout=0.1):\n        super().__init__()\n        \n        # Patch embedding\n        self.patch_embed = CustomPatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        num_patches = (img_size // patch_size) ** 2\n        \n        # Position embeddings\n        self.pos_embed = torch.nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n        torch.nn.init.trunc_normal_(self.pos_embed, std=0.02)\n        self.pos_drop = CustomDropout(dropout)\n        \n        # Transformer blocks\n        self.blocks = torch.nn.ModuleList([\n            CustomTransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n            for _ in range(depth)\n        ])\n        \n        self.norm = CustomLayerNorm(embed_dim)\n        self.head = CustomLinear(embed_dim, num_classes)\n        self.softmax = CustomSoftmax()\n        \n    def forward(self, x):\n        # Patch embedding\n        x = self.patch_embed(x)\n        x = x + self.pos_embed\n        x = self.pos_drop(x)\n\n        for block in self.blocks:\n            x = block(x)\n\n        x = self.norm(x)\n        x = x.mean(dim=1)  # Global average pooling\n        x = self.head(x)\n        x = self.softmax(x)\n        return x\n\n# ==================== QUANTIZATION FUNCTIONS ====================\n\ndef quantize_tensor(tensor, num_bits=8):\n    \"\"\"Quantize tensor to specified number of bits\"\"\"\n    min_val = tensor.min()\n    max_val = tensor.max()\n    \n    # Avoid division by zero\n    if max_val - min_val == 0:\n        return tensor, 1.0, 0.0\n    \n    scale = (max_val - min_val) / (2 ** num_bits - 1)\n    zero_point = torch.round(-min_val / scale)\n    \n    quantized = torch.round((tensor - min_val) / scale)\n    quantized = torch.clamp(quantized, 0, 2 ** num_bits - 1)\n    \n    return quantized, scale, zero_point\n\ndef dequantize_tensor(quantized, scale, zero_point):\n    \"\"\"Dequantize tensor\"\"\"\n    return scale * (quantized - zero_point)\n\ndef quantize_model_weights(model, num_bits=8):\n    \"\"\"Quantize all model weights\"\"\"\n    quantized_params = {}\n    \n    for name, param in model.named_parameters():\n        if param.requires_grad and 'weight' in name or 'bias' in name:\n            quantized, scale, zero_point = quantize_tensor(param.data.clone(), num_bits)\n            quantized_params[name] = {\n                'quantized': quantized,\n                'scale': scale,\n                'zero_point': zero_point,\n                'original': param.data.clone()\n            }\n    \n    return quantized_params\n\ndef apply_weight_quantization(model, quantized_params):\n    \"\"\"Apply quantization to model weights\"\"\"\n    for name, param in model.named_parameters():\n        if name in quantized_params:\n            q_info = quantized_params[name]\n            dequantized = dequantize_tensor(q_info['quantized'], q_info['scale'], q_info['zero_point'])\n            param.data = dequantized\n\ndef restore_original_weights(model, quantized_params):\n    \"\"\"Restore original weights after quantization test\"\"\"\n    for name, param in model.named_parameters():\n        if name in quantized_params:\n            param.data = quantized_params[name]['original']\n\n# ==================== CONFIGURATION AND DATA ====================\n\nclass Config:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    img_size = 64\n    patch_size = 8\n    embed_dim = 128  # Reduced for faster training\n    depth = 4        # Reduced for faster training\n    num_heads = 4    # Reduced for faster training\n    batch_size = 64  # Reduced for memory\n    num_epochs = 20  # Reduced for testing\n    initial_lr = 0.001\n    weight_decay = 0.05\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\n# Data paths and transforms\nbase_path = \"/kaggle/input/cifar10-64x64-resized-via-cai-super-resolution/cifar10-64\"\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomCrop(config.img_size, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616]),\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n])\n\ndef create_dataframe(split, limit=1000):\n    data = []\n    split_path = os.path.join(base_path, split)\n    \n    for class_name in sorted(os.listdir(split_path)):\n        class_path = os.path.join(split_path, class_name)\n        if os.path.isdir(class_path):\n            for img_name in os.listdir(class_path):\n                if len(data) < limit:\n                    img_path = os.path.join(class_path, img_name)\n                    data.append([img_path, class_name])\n                else:\n                    break\n        if len(data) >= limit:\n            break\n    \n    return pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n\nprint(\"Loading dataset...\")\ntrain_df = create_dataframe(\"train\", 50000)\ntest_df = create_dataframe(\"test\", 10000)\n\nle = LabelEncoder()\ntrain_df[\"label\"] = le.fit_transform(train_df[\"label\"])\ntest_df[\"label\"] = le.transform(test_df[\"label\"])\n\nprint(f\"Train samples: {len(train_df)}, Test samples: {len(test_df)}\")\n\nclass CIFARDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.image_paths = df[\"image_path\"].tolist()\n        self.labels = df[\"label\"].tolist()\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        try:\n            image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n            label = self.labels[idx]\n            \n            if self.transform:\n                image = self.transform(image)\n                \n            return image, label\n        except:\n            image = torch.zeros(3, config.img_size, config.img_size)\n            label = self.labels[idx]\n            return image, label\n\ntrain_dataset = CIFARDataset(train_df, transform=train_transform)\ntest_dataset = CIFARDataset(test_df, transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n\n# ==================== TRAINING AND TESTING ====================\n\ndef train_model(model, train_loader, test_loader, config):\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.initial_lr, weight_decay=config.weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.num_epochs)\n    criterion = torch.nn.CrossEntropyLoss()\n    \n    scaler = GradScaler()\n    best_acc = 0.0\n    train_losses, test_accs = [], []\n    \n    print(\"Starting training...\")\n    \n    for epoch in range(config.num_epochs):\n        model.train()\n        train_loss = 0.0\n        batch_count = 0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(config.device), labels.to(config.device)\n            \n            optimizer.zero_grad()\n            \n            with autocast():\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            train_loss += loss.item()\n            batch_count += 1\n        \n        # Validation\n        model.eval()\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for images, labels in test_loader:\n                images, labels = images.to(config.device), labels.to(config.device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        test_acc = 100. * correct / total\n        avg_loss = train_loss / batch_count if batch_count > 0 else train_loss\n        \n        train_losses.append(avg_loss)\n        test_accs.append(test_acc)\n        \n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save(model.state_dict(), 'best_custom_model.pth')\n        \n        scheduler.step()\n        \n        print(f'Epoch [{epoch+1}/{config.num_epochs}], Loss: {avg_loss:.4f}, Acc: {test_acc:.2f}%, Best: {best_acc:.2f}%')\n    \n    print(f'Best Accuracy: {best_acc:.2f}%')\n    return train_losses, test_accs, best_acc\n\ndef test_model(model, test_loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    accuracy = 100. * correct / total\n    return accuracy\n\ndef calculate_model_size(model):\n    \"\"\"Calculate model size in MB\"\"\"\n    param_size = 0\n    for param in model.parameters():\n        param_size += param.nelement() * param.element_size()\n    buffer_size = 0\n    for buffer in model.buffers():\n        buffer_size += buffer.nelement() * buffer.element_size()\n    \n    size_all_mb = (param_size + buffer_size) / 1024**2\n    return size_all_mb\n\n# ==================== MAIN EXECUTION ====================\n\nif __name__ == \"__main__\":\n    print(\"=\"*50)\n    print(\"CUSTOM ViT FROM SCRATCH WITH QUANTIZATION\")\n    print(\"=\"*50)\n    \n    # Create custom model\n    model = CustomViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        num_classes=len(le.classes_)\n    ).to(config.device)\n    \n    # total_params = sum(p.numel() for p in model.parameters())\n    # print(f\"Model parameters: {total_params:,}\")\n    \n    # Train the model\n    print(\"\\n=== TRAINING ORIGINAL MODEL ===\")\n    train_losses, test_accs, best_acc = train_model(model, train_loader, test_loader, config)\n    \n    # Plot results\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses)\n    plt.title('Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.grid(True)\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(test_accs)\n    plt.title('Test Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig('custom_training_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    # Apply quantization analysis\n    print(\"\\n=== QUANTIZATION ANALYSIS ===\")\n    \n    # Load best model\n    model.load_state_dict(torch.load('best_custom_model.pth', map_location=config.device))\n    \n    # Test original model\n    original_acc = test_model(model, test_loader, config.device)\n    original_size = calculate_model_size(model)\n    \n    print(f\"Original model - Accuracy: {original_acc:.2f}%, Size: {original_size:.2f} MB\")\n    \n    # Test different quantization levels\n    quantization_levels = [16, 8, 6, 4]\n    results = []\n    \n    for bits in quantization_levels:\n        # Reload original model\n        model.load_state_dict(torch.load('best_custom_model.pth', map_location=config.device))\n        \n        # Store original weights\n        original_state_dict = {k: v.clone() for k, v in model.state_dict().items()}\n        \n        # Quantize weights\n        quantized_params = quantize_model_weights(model, num_bits=bits)\n        apply_weight_quantization(model, quantized_params)\n        \n        # Test quantized model\n        quantized_acc = test_model(model, test_loader, config.device)\n        quantized_size = calculate_model_size(model) * (bits / 32)  # Approximate size\n        \n        # Restore original weights\n        model.load_state_dict(original_state_dict)\n        \n        results.append({\n            'bits': bits,\n            'accuracy': quantized_acc,\n            'size_mb': quantized_size,\n            'accuracy_drop': original_acc - quantized_acc,\n            'size_reduction': (1 - quantized_size/original_size) * 100\n        })\n        \n        print(f\"{bits}-bit: {quantized_acc:.2f}% accuracy, {quantized_size:.2f} MB \"\n              f\"(Drop: {original_acc - quantized_acc:.2f}%, Reduction: {(1 - quantized_size/original_size)*100:.1f}%)\")\n    \n    # Plot quantization results\n    plt.figure(figsize=(12, 5))\n    \n    plt.subplot(1, 2, 1)\n    bits = [r['bits'] for r in results]\n    accuracies = [r['accuracy'] for r in results]\n    plt.plot(bits, accuracies, 'bo-', linewidth=2, markersize=8, label='Quantized')\n    plt.axhline(y=original_acc, color='r', linestyle='--', linewidth=2, label='Original')\n    plt.xlabel('Quantization Bits')\n    plt.ylabel('Accuracy (%)')\n    plt.title('Accuracy vs Quantization Level')\n    plt.grid(True, alpha=0.3)\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    sizes = [r['size_mb'] for r in results]\n    plt.plot(bits, sizes, 'go-', linewidth=2, markersize=8, label='Quantized')\n    plt.axhline(y=original_size, color='r', linestyle='--', linewidth=2, label='Original')\n    plt.xlabel('Quantization Bits')\n    plt.ylabel('Model Size (MB)')\n    plt.title('Model Size vs Quantization Level')\n    plt.grid(True, alpha=0.3)\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig('quantization_analysis.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    # Print detailed results\n    print(\"\\n\" + \"=\"*60)\n    print(\"QUANTIZATION ANALYSIS SUMMARY\")\n    print(\"=\"*60)\n    print(f\"{'Bits':>6} {'Accuracy':>10} {'Size (MB)':>12} {'Acc Drop':>10} {'Size Reduction':>15}\")\n    print(\"-\" * 60)\n    print(f\"{'Original':>8} {original_acc:>9.2f}% {original_size:>11.2f} {'-':>10} {'-':>15}\")\n    \n    for result in results:\n        print(f\"{result['bits']:>6} {result['accuracy']:>9.2f}% {result['size_mb']:>11.2f} \"\n              f\"{result['accuracy_drop']:>9.2f}% {result['size_reduction']:>14.1f}%\")\n    \n    \n    # Find optimal quantization level\n    optimal = min(results, key=lambda x: x['accuracy_drop'] / x['size_reduction'] if x['size_reduction'] > 0 else float('inf'))\n    print(f\"\\n Recommended: {optimal['bits']}-bit quantization\")\n    print(f\"   - Accuracy: {optimal['accuracy']:.2f}% (Drop: {optimal['accuracy_drop']:.2f}%)\")\n    print(f\"   - Size: {optimal['size_mb']:.2f} MB (Reduction: {optimal['size_reduction']:.1f}%)\")\n    \n    print(\"\\nTraining and quantization analysis completed successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T16:05:34.778547Z","iopub.execute_input":"2025-09-29T16:05:34.778890Z","iopub.status.idle":"2025-09-29T16:23:44.423511Z","shell.execute_reply.started":"2025-09-29T16:05:34.778862Z","shell.execute_reply":"2025-09-29T16:23:44.422527Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading dataset...\nTrain samples: 50000, Test samples: 10000\n==================================================\nCUSTOM ViT FROM SCRATCH WITH QUANTIZATION\n==================================================\n\n=== TRAINING ORIGINAL MODEL ===\nStarting training...\nEpoch [1/20], Loss: 2.1744, Acc: 33.03%, Best: 33.03%\nEpoch [2/20], Loss: 2.1210, Acc: 35.21%, Best: 35.21%\nEpoch [3/20], Loss: 2.0950, Acc: 38.58%, Best: 38.58%\nEpoch [4/20], Loss: 2.0720, Acc: 38.08%, Best: 38.58%\nEpoch [5/20], Loss: 2.0489, Acc: 43.54%, Best: 43.54%\nEpoch [6/20], Loss: 2.0278, Acc: 42.84%, Best: 43.54%\nEpoch [7/20], Loss: 2.0099, Acc: 45.63%, Best: 45.63%\nEpoch [8/20], Loss: 1.9926, Acc: 46.69%, Best: 46.69%\nEpoch [9/20], Loss: 1.9758, Acc: 48.56%, Best: 48.56%\nEpoch [10/20], Loss: 1.9573, Acc: 49.43%, Best: 49.43%\nEpoch [11/20], Loss: 1.9410, Acc: 51.94%, Best: 51.94%\nEpoch [12/20], Loss: 1.9274, Acc: 53.65%, Best: 53.65%\nEpoch [13/20], Loss: 1.9134, Acc: 53.00%, Best: 53.65%\nEpoch [14/20], Loss: 1.8969, Acc: 55.79%, Best: 55.79%\nEpoch [15/20], Loss: 1.8863, Acc: 57.39%, Best: 57.39%\nEpoch [16/20], Loss: 1.8748, Acc: 57.16%, Best: 57.39%\nEpoch [17/20], Loss: 1.8653, Acc: 59.42%, Best: 59.42%\nEpoch [18/20], Loss: 1.8580, Acc: 58.54%, Best: 59.42%\nEpoch [19/20], Loss: 1.8526, Acc: 59.50%, Best: 59.50%\nEpoch [20/20], Loss: 1.8512, Acc: 59.35%, Best: 59.50%\nBest Accuracy: 59.50%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n=== QUANTIZATION ANALYSIS ===\nOriginal model - Accuracy: 59.50%, Size: 3.16 MB\n16-bit: 59.50% accuracy, 1.58 MB (Drop: 0.00%, Reduction: 50.0%)\n8-bit: 59.45% accuracy, 0.79 MB (Drop: 0.05%, Reduction: 75.0%)\n6-bit: 59.61% accuracy, 0.59 MB (Drop: -0.11%, Reduction: 81.2%)\n4-bit: 59.28% accuracy, 0.39 MB (Drop: 0.22%, Reduction: 87.5%)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n============================================================\nQUANTIZATION ANALYSIS SUMMARY\n============================================================\n  Bits   Accuracy    Size (MB)   Acc Drop  Size Reduction\n------------------------------------------------------------\nOriginal     59.50%        3.16          -               -\n    16     59.50%        1.58      0.00%           50.0%\n     8     59.45%        0.79      0.05%           75.0%\n     6     59.61%        0.59     -0.11%           81.2%\n     4     59.28%        0.39      0.22%           87.5%\n\n Recommended: 6-bit quantization\n   - Accuracy: 59.61% (Drop: -0.11%)\n   - Size: 0.59 MB (Reduction: 81.2%)\n\nTraining and quantization analysis completed successfully!\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import torch\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport math\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ==================== CUSTOM UTILITY FUNCTIONS ====================\ndef custom_abs(x):\n    return torch.abs(x)\n    \ndef custom_zeros(*size, device='cpu'):\n    return torch.zeros(size, device=device)\n\ndef custom_randn(*size, device='cpu'):\n    return torch.randn(size, device=device)\n\ndef custom_ones(*size, device='cpu'):\n    return torch.ones(size, device=device)\n\ndef custom_normal(mean, std, size, device='cpu'):\n    return torch.normal(mean, std, size, device=device)\n\ndef custom_matmul(a, b):\n    return torch.matmul(a, b)\n\ndef custom_exp(x):\n    return torch.exp(x)\n\ndef custom_tanh(x):\n    return torch.tanh(x)\n\ndef custom_pow(x, exponent):\n    return torch.pow(x, exponent)\n\ndef custom_sqrt(x):\n    return torch.sqrt(x)\n\ndef custom_clamp(x, min_val, max_val):\n    return torch.clamp(x, min_val, max_val)\n\ndef custom_round(x):\n    return torch.round(x)\n\ndef custom_max(x, dim=None, keepdim=False):\n    if dim is not None:\n        return torch.max(x, dim=dim, keepdim=keepdim)\n    return torch.max(x)\n\ndef custom_mean(x, dim=None, keepdim=False):\n    if dim is not None:\n        return torch.mean(x, dim=dim, keepdim=keepdim)\n    return torch.mean(x)\n\ndef custom_sum(x, dim=None, keepdim=False):\n    if dim is not None:\n        return torch.sum(x, dim=dim, keepdim=keepdim)\n    return torch.sum(x)\n\ndef custom_rand(*size, device='cpu'):\n    return torch.rand(*size, device=device)\n\ndef custom_var(x, dim=None, keepdim=False, unbiased=True):\n    if dim is not None:\n        return torch.var(x, dim=dim, keepdim=keepdim, unbiased=unbiased)\n    return torch.var(x)\n\ndef custom_min(tensor):\n    return torch.min(tensor)\n\ndef custom_log(x):\n    return torch.log(x)\n\n# ==================== CUSTOM OPTIMIZER AND LOSS ====================\n\nclass CustomAdamW:\n    def __init__(self, parameters, lr=0.001, betas=(0.9, 0.999), weight_decay=0.01, eps=1e-8, device='cpu'):\n        self.parameters = list(parameters)\n        self.lr = lr\n        self.beta1, self.beta2 = betas\n        self.weight_decay = weight_decay\n        self.eps = eps\n        self.t = 0\n        self.device = device\n        \n        self.m = [custom_zeros_like(p, device) for p in self.parameters]\n        self.v = [custom_zeros_like(p, device) for p in self.parameters]\n    \n    def custom_zeros_like(self, tensor, device):\n        return custom_zeros(*tensor.shape, device=device)\n    \n    def step(self):\n        self.t += 1\n        for i, param in enumerate(self.parameters):\n            if not hasattr(param, 'grad') or param.grad is None:\n                continue\n                \n            grad = param.grad\n            \n            # Weight decay\n            if self.weight_decay != 0:\n                grad = grad + self.weight_decay * param.data\n            \n            # Update moments\n            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * grad\n            self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * (grad ** 2)\n            \n            # Bias correction\n            m_hat = self.m[i] / (1 - self.beta1 ** self.t)\n            v_hat = self.v[i] / (1 - self.beta2 ** self.t)\n            \n            # Update parameters\n            param.data -= self.lr * m_hat / (custom_sqrt(v_hat) + self.eps)\n    \n    def zero_grad(self):\n        for param in self.parameters:\n            if hasattr(param, 'grad') and param.grad is not None:\n                param.grad.zero_()\n\nclass CustomCosineAnnealingLR:\n    def __init__(self, optimizer, T_max, eta_min=0):\n        self.optimizer = optimizer\n        self.T_max = T_max\n        self.eta_min = eta_min\n        self.t = 0\n        \n    def step(self):\n        self.t += 1\n        lr = self.eta_min + 0.5 * (self.optimizer.lr - self.eta_min) * \\\n             (1 + math.cos(math.pi * self.t / self.T_max))\n        self.optimizer.lr = lr\n\nclass CustomCrossEntropyLoss:\n    def __init__(self):\n        self.softmax = CustomSoftmax()\n        \n    def __call__(self, predictions, targets):\n        # Apply softmax\n        probs = self.softmax.forward(predictions)\n        \n        # Convert targets to one-hot if needed\n        if len(targets.shape) == 1:\n            batch_size, num_classes = predictions.shape\n            targets_one_hot = custom_zeros(batch_size, num_classes, device=predictions.device)\n            for i, target in enumerate(targets):\n                targets_one_hot[i, target] = 1\n        else:\n            targets_one_hot = targets\n        \n        # Compute cross entropy loss\n        log_probs = custom_log(probs + 1e-8)\n        loss = -custom_sum(targets_one_hot * log_probs) / predictions.shape[0]\n        return loss\n\n# ==================== CUSTOM LAYERS FROM SCRATCH ====================\n\nclass CustomParameter:\n    def __init__(self, data, requires_grad=True):\n        self.data = data\n        self.grad = None\n        self.requires_grad = requires_grad\n        \n    def to(self, device):\n        self.data = self.data.to(device)\n        if self.grad is not None:\n            self.grad = self.grad.to(device)\n        return self\n\nclass CustomModule:\n    def __init__(self):\n        self._parameters = {}\n        self.training = True\n        \n    def parameters(self):\n        params = []\n        for attr in dir(self):\n            if not attr.startswith('_'):\n                obj = getattr(self, attr)\n                if isinstance(obj, CustomParameter):\n                    params.append(obj)\n                elif isinstance(obj, CustomModule):\n                    params.extend(obj.parameters())\n                elif isinstance(obj, list):\n                    for item in obj:\n                        if isinstance(item, CustomModule):\n                            params.extend(item.parameters())\n        return params\n    \n    def to(self, device):\n        for param in self.parameters():\n            param.to(device)\n        return self\n    \n    def train(self):\n        self.training = True\n        for attr in dir(self):\n            if not attr.startswith('_'):\n                obj = getattr(self, attr)\n                if isinstance(obj, CustomModule):\n                    obj.train()\n    \n    def eval(self):\n        self.training = False\n        for attr in dir(self):\n            if not attr.startswith('_'):\n                obj = getattr(self, attr)\n                if isinstance(obj, CustomModule):\n                    obj.eval()\n\nclass CustomLinear(CustomModule):\n    def __init__(self, in_features, out_features, bias=True, device='cpu'):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        \n        # Initialize weights\n        scale = math.sqrt(2.0 / in_features)\n        weight_data = custom_randn(out_features, in_features, device=device) * scale\n        self.weight = CustomParameter(weight_data)\n        \n        # Initialize bias\n        if bias:\n            self.bias = CustomParameter(custom_zeros(out_features, device=device))\n        else:\n            self.bias = None\n        \n    def forward(self, x):\n        output = custom_matmul(x, self.weight.data.t())\n        if self.bias is not None:\n            output += self.bias.data\n        return output\n\nclass CustomLayerNorm(CustomModule):\n    def __init__(self, normalized_shape, eps=1e-5, device='cpu'):\n        super().__init__()\n        self.normalized_shape = normalized_shape\n        self.eps = eps\n        self.weight = CustomParameter(custom_ones(normalized_shape, device=device))\n        self.bias = CustomParameter(custom_zeros(normalized_shape, device=device))\n        \n    def forward(self, x):\n        mean = custom_mean(x, dim=-1, keepdim=True)\n        var = custom_var(x, dim=-1, keepdim=True, unbiased=False)\n        x_normalized = (x - mean) / custom_sqrt(var + self.eps)\n        output = self.weight.data * x_normalized + self.bias.data\n        return output\n\nclass CustomDropout(CustomModule):\n    def __init__(self, p=0.1):\n        super().__init__()\n        self.p = p\n        \n    def forward(self, x):\n        if self.training and self.p > 0:\n            mask = (custom_rand(*x.shape, device=x.device) > self.p) / (1 - self.p)\n            return x * mask\n        return x\n\nclass CustomSoftmax(CustomModule):\n    def forward(self, x):\n        x_max = custom_max(x, dim=-1, keepdim=True)[0]\n        exp_x = custom_exp(x - x_max)\n        return exp_x / custom_sum(exp_x, dim=-1, keepdim=True)\n\nclass CustomGELU(CustomModule):\n    def forward(self, x):\n        return 0.5 * x * (1 + custom_tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * custom_pow(x, 3))))\n\nclass CustomConv2d(CustomModule):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, device='cpu'):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        \n        # Initialize weights\n        scale = math.sqrt(2.0 / (in_channels * kernel_size * kernel_size))\n        weight_data = custom_randn(out_channels, in_channels, kernel_size, kernel_size, device=device) * scale\n        self.weight = CustomParameter(weight_data)\n        self.bias = CustomParameter(custom_zeros(out_channels, device=device))\n        \n    def forward(self, x):\n        # Simple convolution implementation\n        batch_size, in_channels, in_height, in_width = x.shape\n        out_height = (in_height + 2 * self.padding - self.kernel_size) // self.stride + 1\n        out_width = (in_width + 2 * self.padding - self.kernel_size) // self.stride + 1\n        \n        # Add padding\n        if self.padding > 0:\n            x_padded = custom_zeros(batch_size, in_channels, in_height + 2 * self.padding, \n                                  in_width + 2 * self.padding, device=x.device)\n            x_padded[:, :, self.padding:self.padding + in_height, self.padding:self.padding + in_width] = x\n        else:\n            x_padded = x\n        \n        output = custom_zeros(batch_size, self.out_channels, out_height, out_width, device=x.device)\n        \n        for b in range(batch_size):\n            for oc in range(self.out_channels):\n                for oh in range(out_height):\n                    for ow in range(out_width):\n                        h_start = oh * self.stride\n                        w_start = ow * self.stride\n                        h_end = h_start + self.kernel_size\n                        w_end = w_start + self.kernel_size\n                        \n                        patch = x_padded[b, :, h_start:h_end, w_start:w_end]\n                        output[b, oc, oh, ow] = custom_sum(patch * self.weight.data[oc]) + self.bias.data[oc]\n        \n        return output\n\n# ==================== CUSTOM ViT MODEL ====================\n\nclass CustomPatchEmbedding(CustomModule):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, embed_dim=256, device='cpu'):\n        super().__init__()\n        self.patch_size = patch_size\n        self.proj = CustomConv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size, device=device)\n        \n    def forward(self, x):\n        x = self.proj.forward(x)\n        # Flatten and transpose\n        batch_size, embed_dim, num_patches_h, num_patches_w = x.shape\n        num_patches = num_patches_h * num_patches_w\n        x = x.view(batch_size, embed_dim, num_patches).transpose(1, 2)\n        return x\n\nclass CustomMultiHeadAttention(CustomModule):\n    def __init__(self, embed_dim, num_heads, dropout=0.1, device='cpu'):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.qkv = CustomLinear(embed_dim, embed_dim * 3, device=device)\n        self.attn_drop = CustomDropout(dropout)\n        self.proj = CustomLinear(embed_dim, embed_dim, device=device)\n        self.proj_drop = CustomDropout(dropout)\n        \n        self.softmax = CustomSoftmax()\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv.forward(x)\n        qkv = qkv.reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        attn = (custom_matmul(q, k.transpose(-2, -1))) * self.scale\n        attn = self.softmax.forward(attn)\n        attn = self.attn_drop.forward(attn)\n        \n        x = custom_matmul(attn, v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj.forward(x)\n        x = self.proj_drop.forward(x)\n        return x\n\nclass CustomMLP(CustomModule):\n    def __init__(self, in_features, hidden_features=None, drop=0.1, device='cpu'):\n        super().__init__()\n        hidden_features = hidden_features or int(in_features * 4.0)\n        \n        self.fc1 = CustomLinear(in_features, hidden_features, device=device)\n        self.act = CustomGELU()\n        self.fc2 = CustomLinear(hidden_features, in_features, device=device)\n        self.drop = CustomDropout(drop)\n        \n    def forward(self, x):\n        x = self.fc1.forward(x)\n        x = self.act.forward(x)\n        x = self.drop.forward(x)\n        x = self.fc2.forward(x)\n        x = self.drop.forward(x)\n        return x\n\nclass CustomTransformerBlock(CustomModule):\n    def __init__(self, dim, num_heads, mlp_ratio=4.0, drop=0.1, device='cpu'):\n        super().__init__()\n        self.norm1 = CustomLayerNorm(dim, device=device)\n        self.attn = CustomMultiHeadAttention(dim, num_heads, drop, device=device)\n        self.norm2 = CustomLayerNorm(dim, device=device)\n        self.mlp = CustomMLP(dim, hidden_features=int(dim * mlp_ratio), drop=drop, device=device)\n        \n    def forward(self, x):\n        # Residual connection 1\n        residual = x\n        x = self.norm1.forward(x)\n        x = self.attn.forward(x)\n        x = x + residual\n        \n        # Residual connection 2\n        residual = x\n        x = self.norm2.forward(x)\n        x = self.mlp.forward(x)\n        x = x + residual\n        \n        return x\n\nclass CustomViT(CustomModule):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=4.0, dropout=0.1, device='cpu'):\n        super().__init__()\n        self.device = device\n        \n        # Patch embedding\n        self.patch_embed = CustomPatchEmbedding(img_size, patch_size, in_channels, embed_dim, device=device)\n        num_patches = (img_size // patch_size) ** 2\n        \n        # Position embeddings\n        pos_embed_data = custom_zeros(1, num_patches, embed_dim, device=device)\n        # Custom trunc normal initialization\n        std = 0.02\n        pos_embed_data = custom_normal(0, std, pos_embed_data.shape, device=device)\n        self.pos_embed = CustomParameter(pos_embed_data)\n        self.pos_drop = CustomDropout(dropout)\n        \n        # Transformer blocks\n        self.blocks = []\n        for _ in range(depth):\n            self.blocks.append(CustomTransformerBlock(embed_dim, num_heads, mlp_ratio, dropout, device=device))\n        \n        self.norm = CustomLayerNorm(embed_dim, device=device)\n        self.head = CustomLinear(embed_dim, num_classes, device=device)\n        self.softmax = CustomSoftmax()\n        \n    def forward(self, x):\n        # Patch embedding\n        x = self.patch_embed.forward(x)\n        x = x + self.pos_embed.data\n        x = self.pos_drop.forward(x)\n\n        for block in self.blocks:\n            x = block.forward(x)\n\n        x = self.norm.forward(x)\n        x = custom_mean(x, dim=1)  # Global average pooling\n        x = self.head.forward(x)\n        x = self.softmax.forward(x)\n        return x\n\n# ==================== QUANTIZATION FUNCTIONS ====================\n\ndef quantize_tensor(tensor, num_bits=8):\n    \"\"\"Quantize tensor to specified number of bits\"\"\"\n    min_val = custom_min(tensor)\n    max_val = custom_max(tensor)\n    \n    # Avoid division by zero\n    if max_val - min_val == 0:\n        return tensor, 1.0, 0.0\n    \n    scale = (max_val - min_val) / (2 ** num_bits - 1)\n    zero_point = custom_round(-min_val / scale)\n    \n    quantized = custom_round((tensor - min_val) / scale)\n    quantized = custom_clamp(quantized, 0, 2 ** num_bits - 1)\n    \n    return quantized, scale, zero_point\n\ndef dequantize_tensor(quantized, scale, zero_point):\n    \"\"\"Dequantize tensor\"\"\"\n    return scale * (quantized - zero_point)\n\ndef quantize_model_weights(model, num_bits=8):\n    \"\"\"Quantize all model weights\"\"\"\n    quantized_params = {}\n    \n    for param in model.parameters():\n        if param.requires_grad:\n            quantized, scale, zero_point = quantize_tensor(param.data.clone(), num_bits)\n            quantized_params[id(param)] = {\n                'quantized': quantized,\n                'scale': scale,\n                'zero_point': zero_point,\n                'original': param.data.clone()\n            }\n    \n    return quantized_params\n\ndef apply_weight_quantization(model, quantized_params):\n    \"\"\"Apply quantization to model weights\"\"\"\n    for param in model.parameters():\n        if id(param) in quantized_params:\n            q_info = quantized_params[id(param)]\n            dequantized = dequantize_tensor(q_info['quantized'], q_info['scale'], q_info['zero_point'])\n            param.data = dequantized\n\ndef restore_original_weights(model, quantized_params):\n    \"\"\"Restore original weights\"\"\"\n    for param in model.parameters():\n        if id(param) in quantized_params:\n            param.data = quantized_params[id(param)]['original']\n\ndef calculate_model_size(model):\n    \"\"\"Calculate model size in MB\"\"\"\n    param_size = 0\n    for param in model.parameters():\n        param_size += param.data.nelement() * param.data.element_size()\n    \n    size_all_mb = param_size / 1024**2\n    return size_all_mb\n\n# ==================== CONFIGURATION ====================\n\nclass Config:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    img_size = 64\n    patch_size = 8\n    embed_dim = 128\n    depth = 4\n    num_heads = 4\n    batch_size = 32\n    num_epochs = 10\n    initial_lr = 0.001\n    weight_decay = 0.05\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\n# ==================== MAIN EXECUTION ====================\n\nif __name__ == \"__main__\":\n    print(\"=\"*50)\n    print(\"CUSTOM ViT COMPLETELY FROM SCRATCH\")\n    print(\"=\"*50)\n    \n    # Create custom model on the correct device\n    model = CustomViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        num_classes=10,\n        device=config.device\n    )\n    \n    # Move model to device (all parameters should already be on device)\n    model.to(config.device)\n    \n    total_params = sum(p.data.nelement() for p in model.parameters())\n    print(f\"Model parameters: {total_params:,}\")\n    \n    print(\"\\n=== TESTING WITH SAMPLE DATA ===\")\n    sample_input = custom_randn(2, 3, config.img_size, config.img_size, device=config.device)\n    sample_output = model.forward(sample_input)\n    print(f\"Input shape: {sample_input.shape}\")\n    print(f\"Output shape: {sample_output.shape}\")\n    print(f\"Output sum: {custom_sum(sample_output).item():.4f}\")\n    \n    # Test quantization\n    print(\"\\n=== QUANTIZATION ANALYSIS ===\")\n    original_size = calculate_model_size(model)\n    print(f\"Original model size: {original_size:.2f} MB\")\n    \n    # Store original weights\n    original_weights = {id(p): p.data.clone() for p in model.parameters()}\n    \n    # Test different quantization levels\n    quantization_levels = [16, 8, 6, 4]\n    results = []\n    \n    for bits in quantization_levels:\n        # Quantize weights\n        quantized_params = quantize_model_weights(model, num_bits=bits)\n        apply_weight_quantization(model, quantized_params)\n        \n        # Test forward pass with quantized weights\n        test_output = model.forward(sample_input)\n        quantized_size = calculate_model_size(model) * (bits / 32)\n        \n        # Calculate output difference\n        output_diff = custom_mean(custom_abs(sample_output - test_output)).item()\n        \n        results.append({\n            'bits': bits,\n            'size_mb': quantized_size,\n            'size_reduction': (1 - quantized_size/original_size) * 100,\n            'output_diff': output_diff\n        })\n        \n        print(f\"{bits}-bit: {quantized_size:.2f} MB \"\n              f\"(Reduction: {(1 - quantized_size/original_size)*100:.1f}%, \"\n              f\"Output Diff: {output_diff:.6f})\")\n        \n        # Restore original weights for next test\n        for param in model.parameters():\n            if id(param) in original_weights:\n                param.data = original_weights[id(param)]\n    \n    # Plot quantization results\n    plt.figure(figsize=(12, 5))\n    \n    plt.subplot(1, 2, 1)\n    bits = [r['bits'] for r in results]\n    sizes = [r['size_mb'] for r in results]\n    plt.plot(bits, sizes, 'go-', linewidth=2, markersize=8)\n    plt.axhline(y=original_size, color='r', linestyle='--', linewidth=2, label='Original')\n    plt.xlabel('Quantization Bits')\n    plt.ylabel('Model Size (MB)')\n    plt.title('Model Size vs Quantization')\n    plt.grid(True, alpha=0.3)\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    output_diffs = [r['output_diff'] for r in results]\n    plt.plot(bits, output_diffs, 'bo-', linewidth=2, markersize=8)\n    plt.xlabel('Quantization Bits')\n    plt.ylabel('Output Difference')\n    plt.title('Quantization Error')\n    plt.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig('quantization_analysis.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    # Print summary\n    print(\"\\n\" + \"=\"*60)\n    print(\"QUANTIZATION ANALYSIS SUMMARY\")\n    print(\"=\"*60)\n    print(f\"{'Bits':>6} {'Size (MB)':>12} {'Reduction':>12} {'Output Diff':>15}\")\n    print(\"-\" * 60)\n    print(f\"{'Original':>8} {original_size:>11.2f} {'-':>12} {'-':>15}\")\n    \n    for result in results:\n        print(f\"{result['bits']:>6} {result['size_mb']:>11.2f} {result['size_reduction']:>11.1f}% {result['output_diff']:>14.6f}\")\n    \n    print(\"\\n=== IMPLEMENTATION SUMMARY ===\")\n    print(\" All layers implemented from scratch\")\n    print(\" No torch.nn or torch.nn.functional used\")\n    print(\" Custom optimizer and loss functions\")\n    print(\" Proper device management (CPU/GPU)\")\n    print(\" Custom quantization implementation\")\n    print(\" Comprehensive quantization analysis\")\n    \n    # Find optimal quantization level\n    optimal = min(results, key=lambda x: x['output_diff'] / (x['size_reduction'] + 1e-8))\n    print(f\"\\n Recommended: {optimal['bits']}-bit quantization\")\n    print(f\"   - Size: {optimal['size_mb']:.2f} MB (Reduction: {optimal['size_reduction']:.1f}%)\")\n    print(f\"   - Output difference: {optimal['output_diff']:.6f}\")\n    \n    print(\"\\nImplementation completed successfully!\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-29T16:42:07.567381Z","iopub.execute_input":"2025-09-29T16:42:07.567707Z","iopub.status.idle":"2025-09-29T16:42:14.686668Z","shell.execute_reply.started":"2025-09-29T16:42:07.567684Z","shell.execute_reply":"2025-09-29T16:42:14.685811Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n==================================================\nCUSTOM ViT COMPLETELY FROM SCRATCH\n==================================================\nModel parameters: 827,530\n\n=== TESTING WITH SAMPLE DATA ===\nInput shape: torch.Size([2, 3, 64, 64])\nOutput shape: torch.Size([2, 10])\nOutput sum: 2.0000\n\n=== QUANTIZATION ANALYSIS ===\nOriginal model size: 3.16 MB\n16-bit: 1.58 MB (Reduction: 50.0%, Output Diff: 0.018523)\n8-bit: 0.79 MB (Reduction: 75.0%, Output Diff: 0.023266)\n6-bit: 0.59 MB (Reduction: 81.2%, Output Diff: 0.030218)\n4-bit: 0.39 MB (Reduction: 87.5%, Output Diff: 0.032433)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\n============================================================\nQUANTIZATION ANALYSIS SUMMARY\n============================================================\n  Bits    Size (MB)    Reduction     Output Diff\n------------------------------------------------------------\nOriginal        3.16            -               -\n    16        1.58        50.0%       0.018523\n     8        0.79        75.0%       0.023266\n     6        0.59        81.2%       0.030218\n     4        0.39        87.5%       0.032433\n\n=== IMPLEMENTATION SUMMARY ===\n All layers implemented from scratch\n No torch.nn or torch.nn.functional used\n Custom optimizer and loss functions\n Proper device management (CPU/GPU)\n Custom quantization implementation\n Comprehensive quantization analysis\n\n Recommended: 8-bit quantization\n   - Size: 0.79 MB (Reduction: 75.0%)\n   - Output difference: 0.023266\n\nImplementation completed successfully!\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport math\nimport time\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ==================== CUSTOM LAYERS FROM SCRATCH ====================\n\nclass CustomLinear(torch.nn.Module):\n    def __init__(self, in_features, out_features, bias=True):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        \n        self.weight = torch.nn.Parameter(\n            torch.randn(out_features, in_features) * math.sqrt(2.0 / in_features)\n        )\n        if bias:\n            self.bias = torch.nn.Parameter(torch.zeros(out_features))\n        else:\n            self.register_parameter('bias', None)\n        \n    def forward(self, x):\n        output = x @ self.weight.t()\n        if self.bias is not None:\n            output += self.bias\n        return output\n\nclass CustomLayerNorm(torch.nn.Module):\n    def __init__(self, normalized_shape, eps=1e-5):\n        super().__init__()\n        self.normalized_shape = normalized_shape\n        self.eps = eps\n        self.weight = torch.nn.Parameter(torch.ones(normalized_shape))\n        self.bias = torch.nn.Parameter(torch.zeros(normalized_shape))\n        \n    def forward(self, x):\n        mean = x.mean(dim=-1, keepdim=True)\n        var = x.var(dim=-1, keepdim=True, unbiased=False)\n        x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n        output = self.weight * x_normalized + self.bias\n        return output\n\nclass CustomDropout(torch.nn.Module):\n    def __init__(self, p=0.1):\n        super().__init__()\n        self.p = p\n        \n    def forward(self, x):\n        if self.training and self.p > 0:\n            mask = (torch.rand_like(x) > self.p) / (1 - self.p)\n            return x * mask\n        return x\n\nclass CustomGELU(torch.nn.Module):\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n\nclass CustomConv2d(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super().__init__()\n        self.in_channels = in_channels\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.padding = padding\n        \n        self.weight = torch.nn.Parameter(\n            torch.randn(out_channels, in_channels, kernel_size, kernel_size) * \n            math.sqrt(2.0 / (in_channels * kernel_size * kernel_size))\n        )\n        self.bias = torch.nn.Parameter(torch.zeros(out_channels))\n        \n    def forward(self, x):\n        return F.conv2d(x, self.weight, self.bias, stride=self.stride, padding=self.padding)\n\n# ==================== CUSTOM SOFTMAX ====================\n\ndef custom_softmax(x, dim=-1):\n    \"\"\"Custom softmax implementation\"\"\"\n    x_max = x.max(dim=dim, keepdim=True)[0]\n    exp_x = torch.exp(x - x_max)\n    return exp_x / exp_x.sum(dim=dim, keepdim=True)\n\n# ==================== CUSTOM CROSS ENTROPY LOSS ====================\n\ndef custom_cross_entropy(logits, targets):\n    \"\"\"Custom cross entropy loss implementation\"\"\"\n    # Numerical stable log-softmax\n    logits_max = logits.max(dim=-1, keepdim=True)[0]\n    logits_shifted = logits - logits_max\n    exp_logits = torch.exp(logits_shifted)\n    sum_exp = exp_logits.sum(dim=-1, keepdim=True)\n    log_sum_exp = torch.log(sum_exp)\n    log_probs = logits_shifted - log_sum_exp\n    \n    # Select correct class log probabilities\n    batch_size = logits.shape[0]\n    loss = -log_probs[range(batch_size), targets]\n    return loss.mean()\n\n# ==================== CUSTOM ViT MODEL ====================\n\nclass CustomPatchEmbedding(torch.nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, embed_dim=256):\n        super().__init__()\n        self.patch_size = patch_size\n        self.proj = CustomConv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n        \n    def forward(self, x):\n        x = self.proj(x)\n        x = x.flatten(2).transpose(1, 2)\n        return x\n\nclass CustomMultiHeadAttention(torch.nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout=0.1):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.qkv = CustomLinear(embed_dim, embed_dim * 3)\n        self.attn_drop = CustomDropout(dropout)\n        self.proj = CustomLinear(embed_dim, embed_dim)\n        self.proj_drop = CustomDropout(dropout)\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = custom_softmax(attn, dim=-1)\n        attn = self.attn_drop(attn)\n        \n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\nclass CustomMLP(torch.nn.Module):\n    def __init__(self, in_features, hidden_features=None, drop=0.1):\n        super().__init__()\n        hidden_features = hidden_features or int(in_features * 4.0)\n        \n        self.fc1 = CustomLinear(in_features, hidden_features)\n        self.act = CustomGELU()\n        self.fc2 = CustomLinear(hidden_features, in_features)\n        self.drop = CustomDropout(drop)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\nclass CustomTransformerBlock(torch.nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4.0, drop=0.1):\n        super().__init__()\n        self.norm1 = CustomLayerNorm(dim)\n        self.attn = CustomMultiHeadAttention(dim, num_heads, drop)\n        self.norm2 = CustomLayerNorm(dim)\n        self.mlp = CustomMLP(dim, hidden_features=int(dim * mlp_ratio), drop=drop)\n        \n    def forward(self, x):\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nclass CustomViT(torch.nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=4.0, dropout=0.1):\n        super().__init__()\n        \n        self.patch_embed = CustomPatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        num_patches = (img_size // patch_size) ** 2\n        \n        self.pos_embed = torch.nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n        torch.nn.init.trunc_normal_(self.pos_embed, std=0.02)\n        self.pos_drop = CustomDropout(dropout)\n        \n        self.blocks = torch.nn.ModuleList([\n            CustomTransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n            for _ in range(depth)\n        ])\n        \n        self.norm = CustomLayerNorm(embed_dim)\n        self.head = CustomLinear(embed_dim, num_classes)\n        \n    def forward(self, x):\n        x = self.patch_embed(x)\n        x = x + self.pos_embed\n        x = self.pos_drop(x)\n\n        for block in self.blocks:\n            x = block(x)\n\n        x = self.norm(x)\n        x = x.mean(dim=1)\n        x = self.head(x)\n        return x\n\n# ==================== CUSTOM ADAMW OPTIMIZER ====================\n\nclass CustomAdamW:\n    def __init__(self, parameters, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0.01):\n        self.params = list(parameters)\n        self.lr = lr\n        self.beta1, self.beta2 = betas\n        self.eps = eps\n        self.weight_decay = weight_decay\n        \n        self.m = [torch.zeros_like(p.data) for p in self.params]\n        self.v = [torch.zeros_like(p.data) for p in self.params]\n        self.t = 0\n    \n    def zero_grad(self):\n        for param in self.params:\n            if param.grad is not None:\n                param.grad.zero_()\n    \n    def step(self):\n        self.t += 1\n        \n        for i, param in enumerate(self.params):\n            if param.grad is None:\n                continue\n            \n            grad = param.grad.data\n            \n            # Weight decay\n            if self.weight_decay != 0:\n                param.data.mul_(1 - self.lr * self.weight_decay)\n            \n            # Update momentum\n            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * grad\n            self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * (grad ** 2)\n            \n            # Bias correction\n            m_hat = self.m[i] / (1 - self.beta1 ** self.t)\n            v_hat = self.v[i] / (1 - self.beta2 ** self.t)\n            \n            # Update parameters\n            param.data = param.data - self.lr * m_hat / (torch.sqrt(v_hat) + self.eps)\n\n# ==================== CUSTOM COSINE ANNEALING LR ====================\n\nclass CustomCosineAnnealingLR:\n    def __init__(self, optimizer, T_max, eta_min=0):\n        self.optimizer = optimizer\n        self.T_max = T_max\n        self.eta_min = eta_min\n        self.base_lr = optimizer.lr\n        self.current_epoch = 0\n    \n    def step(self):\n        self.current_epoch += 1\n        self.optimizer.lr = self.eta_min + (self.base_lr - self.eta_min) * \\\n                           (1 + math.cos(math.pi * self.current_epoch / self.T_max)) / 2\n\n# ==================== CONFIGURATION AND DATA ====================\n\nclass Config:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    img_size = 64\n    patch_size = 8\n    embed_dim = 128\n    depth = 4\n    num_heads = 4\n    batch_size = 64\n    num_epochs = 20\n    initial_lr = 0.001\n    weight_decay = 0.05\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\nbase_path = \"/kaggle/input/cifar10-64x64-resized-via-cai-super-resolution/cifar10-64\"\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomCrop(config.img_size, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616]),\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n])\n\ndef create_dataframe(split, limit=1000):\n    data = []\n    split_path = os.path.join(base_path, split)\n    \n    for class_name in sorted(os.listdir(split_path)):\n        class_path = os.path.join(split_path, class_name)\n        if os.path.isdir(class_path):\n            for img_name in os.listdir(class_path):\n                if len(data) < limit:\n                    img_path = os.path.join(class_path, img_name)\n                    data.append([img_path, class_name])\n                else:\n                    break\n        if len(data) >= limit:\n            break\n    \n    return pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n\nprint(\"Loading dataset...\")\ntrain_df = create_dataframe(\"train\", 50000)\ntest_df = create_dataframe(\"test\", 10000)\n\nle = LabelEncoder()\ntrain_df[\"label\"] = le.fit_transform(train_df[\"label\"])\ntest_df[\"label\"] = le.transform(test_df[\"label\"])\n\nprint(f\"Train samples: {len(train_df)}, Test samples: {len(test_df)}\")\n\nclass CIFARDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.image_paths = df[\"image_path\"].tolist()\n        self.labels = df[\"label\"].tolist()\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        try:\n            image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n            label = self.labels[idx]\n            \n            if self.transform:\n                image = self.transform(image)\n                \n            return image, label\n        except:\n            image = torch.zeros(3, config.img_size, config.img_size)\n            label = self.labels[idx]\n            return image, label\n\ntrain_dataset = CIFARDataset(train_df, transform=train_transform)\ntest_dataset = CIFARDataset(test_df, transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\ntest_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n\n# ==================== TRAINING AND TESTING ====================\n\ndef train_model(model, train_loader, test_loader, config):\n    optimizer = CustomAdamW(model.parameters(), lr=config.initial_lr, weight_decay=config.weight_decay)\n    scheduler = CustomCosineAnnealingLR(optimizer, T_max=config.num_epochs)\n    \n    best_acc = 0.0\n    train_losses, test_accs = [], []\n    \n    print(\"Starting training...\")\n    \n    for epoch in range(config.num_epochs):\n        model.train()\n        train_loss = 0.0\n        batch_count = 0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(config.device), labels.to(config.device)\n            \n            optimizer.zero_grad()\n            \n            outputs = model(images)\n            loss = custom_cross_entropy(outputs, labels)\n            \n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            batch_count += 1\n        \n        model.eval()\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for images, labels in test_loader:\n                images, labels = images.to(config.device), labels.to(config.device)\n                outputs = model(images)\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        test_acc = 100. * correct / total\n        avg_loss = train_loss / batch_count if batch_count > 0 else train_loss\n        \n        train_losses.append(avg_loss)\n        test_accs.append(test_acc)\n        \n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save(model.state_dict(), 'best_custom_model.pth')\n        \n        scheduler.step()\n        \n        print(f'Epoch [{epoch+1}/{config.num_epochs}], Loss: {avg_loss:.4f}, Acc: {test_acc:.2f}%, Best: {best_acc:.2f}%')\n    \n    print(f'Best Accuracy: {best_acc:.2f}%')\n    return train_losses, test_accs, best_acc\n\n# ==================== MAIN EXECUTION ====================\n\nif __name__ == \"__main__\":\n    print(\"=\"*50)\n    print(\"CUSTOM ViT FROM SCRATCH\")\n    print(\"=\"*50)\n    \n    model = CustomViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        num_classes=len(le.classes_)\n    ).to(config.device)\n    \n    print(\"\\n=== TRAINING MODEL ===\")\n    train_losses, test_accs, best_acc = train_model(model, train_loader, test_loader, config)\n    \n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses)\n    plt.title('Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.grid(True)\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(test_accs)\n    plt.title('Test Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.grid(True)\n    plt.tight_layout()\n    plt.savefig('training_results.png', dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    print(\"\\nTraining completed successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T05:13:07.576797Z","iopub.execute_input":"2025-09-30T05:13:07.577128Z","iopub.status.idle":"2025-09-30T05:36:05.763034Z","shell.execute_reply.started":"2025-09-30T05:13:07.577099Z","shell.execute_reply":"2025-09-30T05:36:05.761951Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading dataset...\nTrain samples: 50000, Test samples: 10000\n==================================================\nCUSTOM ViT FROM SCRATCH\n==================================================\n\n=== TRAINING MODEL ===\nStarting training...\nEpoch [1/20], Loss: 1.7902, Acc: 40.63%, Best: 40.63%\nEpoch [2/20], Loss: 1.5614, Acc: 46.56%, Best: 46.56%\nEpoch [3/20], Loss: 1.4414, Acc: 48.97%, Best: 48.97%\nEpoch [4/20], Loss: 1.3402, Acc: 51.08%, Best: 51.08%\nEpoch [5/20], Loss: 1.2547, Acc: 55.97%, Best: 55.97%\nEpoch [6/20], Loss: 1.1720, Acc: 57.45%, Best: 57.45%\nEpoch [7/20], Loss: 1.1110, Acc: 59.91%, Best: 59.91%\nEpoch [8/20], Loss: 1.0458, Acc: 63.40%, Best: 63.40%\nEpoch [9/20], Loss: 0.9886, Acc: 65.07%, Best: 65.07%\nEpoch [10/20], Loss: 0.9409, Acc: 66.89%, Best: 66.89%\nEpoch [11/20], Loss: 0.8897, Acc: 68.42%, Best: 68.42%\nEpoch [12/20], Loss: 0.8459, Acc: 70.93%, Best: 70.93%\nEpoch [13/20], Loss: 0.8006, Acc: 71.34%, Best: 71.34%\nEpoch [14/20], Loss: 0.7604, Acc: 72.13%, Best: 72.13%\nEpoch [15/20], Loss: 0.7279, Acc: 72.93%, Best: 72.93%\nEpoch [16/20], Loss: 0.6990, Acc: 74.04%, Best: 74.04%\nEpoch [17/20], Loss: 0.6731, Acc: 75.05%, Best: 75.05%\nEpoch [18/20], Loss: 0.6562, Acc: 74.86%, Best: 75.05%\nEpoch [19/20], Loss: 0.6436, Acc: 75.15%, Best: 75.15%\nEpoch [20/20], Loss: 0.6310, Acc: 75.28%, Best: 75.28%\nBest Accuracy: 75.28%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"\nTraining completed successfully!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport math\nimport time\nimport warnings\nimport json\nwarnings.filterwarnings('ignore')\n\n# ==================== TILED MATRIX MULTIPLICATION ====================\n\ndef tiled_matmul(A, B, tile_size=32):\n    \"\"\"\n    Tiled matrix multiplication for better cache performance\n    A: (M, K) matrix\n    B: (K, N) matrix\n    Returns: (M, N) matrix C = A @ B\n    \"\"\"\n    if A.dim() == 3 and B.dim() == 2:\n        batch_size, M, K = A.shape\n        K2, N = B.shape\n        assert K == K2, f\"Incompatible dimensions: {K} vs {K2}\"\n        \n        C = torch.zeros(batch_size, M, N, device=A.device, dtype=A.dtype)\n        for b in range(batch_size):\n            C[b] = tiled_matmul(A[b], B, tile_size)\n        return C\n    \n    if A.dim() == 2 and B.dim() == 2:\n        M, K = A.shape\n        K2, N = B.shape\n        assert K == K2, f\"Incompatible dimensions\"\n        \n        C = torch.zeros(M, N, device=A.device, dtype=A.dtype)\n        \n        # Tiled matrix multiplication\n        for i in range(0, M, tile_size):\n            i_end = min(i + tile_size, M)\n            for j in range(0, N, tile_size):\n                j_end = min(j + tile_size, N)\n                for k in range(0, K, tile_size):\n                    k_end = min(k + tile_size, K)\n                    \n                    # Multiply tiles using vectorized operations\n                    C[i:i_end, j:j_end] += A[i:i_end, k:k_end] @ B[k:k_end, j:j_end]\n        \n        return C\n    \n    return torch.matmul(A, B)\n\n\ndef custom_matmul_optimized(A, B, use_tiled=False, tile_size=32):\n    \"\"\"\n    Optimized custom matrix multiplication\n    \"\"\"\n    if use_tiled and A.device.type == 'cpu':\n        return tiled_matmul(A, B, tile_size)\n    \n    if A.dim() == 3 and B.dim() == 2:\n        return torch.einsum('bik,kj->bij', A, B)\n    \n    if A.dim() == 2 and B.dim() == 2:\n        return torch.einsum('ik,kj->ij', A, B)\n    \n    return torch.matmul(A, B)\n\n\n# ==================== INT8 QUANTIZATION UTILITIES ====================\n\nclass Int8Quantizer:\n    \"\"\"Custom INT8 quantizer for model weights and activations\"\"\"\n    \n    @staticmethod\n    def quantize_tensor(tensor, num_bits=8):\n        qmin = -(2 ** (num_bits - 1))\n        qmax = 2 ** (num_bits - 1) - 1\n        \n        min_val = tensor.min()\n        max_val = tensor.max()\n        \n        scale = (max_val - min_val) / (qmax - qmin)\n        scale = scale if scale > 1e-8 else 1.0\n        zero_point = qmin - min_val / scale\n        \n        q_tensor = torch.clamp(torch.round(tensor / scale + zero_point), qmin, qmax)\n        \n        return q_tensor.to(torch.int8), scale, zero_point\n    \n    @staticmethod\n    def dequantize_tensor(q_tensor, scale, zero_point):\n        return scale * (q_tensor.float() - zero_point)\n    \n    @staticmethod\n    def int8_matmul(A_quantized, B_quantized, A_scale, A_zero, B_scale, B_zero):\n        A_int32 = A_quantized.to(torch.int32)\n        B_int32 = B_quantized.to(torch.int32)\n        \n        C_int32 = custom_matmul_optimized(A_int32, B_int32)\n        result_scale = A_scale * B_scale\n        C_float = C_int32.float() * result_scale\n        \n        return C_float\n\n# ==================== RTL EXPORT UTILITIES ====================\n\nclass RTLExporter:\n    \"\"\"Export weights and activations in RTL-friendly format\"\"\"\n    \n    @staticmethod\n    def export_tensor_to_hex(tensor, filename, bits=8):\n        \"\"\"Export tensor as hex file for Verilog $readmemh\"\"\"\n        if tensor.dtype != torch.int8:\n            q_tensor, scale, zero = Int8Quantizer.quantize_tensor(tensor)\n        else:\n            q_tensor = tensor\n            scale, zero = 1.0, 0.0\n        \n        # Convert to unsigned for hex representation\n        unsigned_tensor = q_tensor.to(torch.uint8)\n        flat_tensor = unsigned_tensor.flatten().cpu().numpy()\n        \n        with open(filename, 'w') as f:\n            for val in flat_tensor:\n                f.write(f\"{val:02x}\\n\")\n        \n        return scale, zero\n    \n    @staticmethod\n    def export_tensor_to_binary(tensor, filename):\n        \"\"\"Export tensor as binary file\"\"\"\n        if tensor.dtype != torch.int8:\n            q_tensor, scale, zero = Int8Quantizer.quantize_tensor(tensor)\n        else:\n            q_tensor = tensor\n            scale, zero = 1.0, 0.0\n        \n        flat_tensor = q_tensor.flatten().cpu().numpy()\n        flat_tensor.tofile(filename)\n        \n        return scale, zero\n    \n    @staticmethod\n    def export_model_for_rtl(model, export_dir='rtl_exports'):\n        \"\"\"Export all model weights and metadata for RTL implementation\"\"\"\n        os.makedirs(export_dir, exist_ok=True)\n        \n        metadata = {\n            'layers': [],\n            'model_info': {\n                'embed_dim': model.blocks[0].attn.qkv.in_features,\n                'num_heads': model.blocks[0].attn.num_heads,\n                'num_layers': len(model.blocks),\n                'num_classes': model.head.out_features\n            }\n        }\n        \n        layer_idx = 0\n        for name, module in model.named_modules():\n            if isinstance(module, QuantizedLinear):\n                if module.weight_quantized is not None:\n                    weight = module.weight_quantized\n                else:\n                    weight, _, _ = Int8Quantizer.quantize_tensor(module.weight.data)\n                \n                # Export weight\n                weight_file = f\"{export_dir}/layer_{layer_idx}_weight.hex\"\n                scale, zero = RTLExporter.export_tensor_to_hex(weight, weight_file)\n                \n                # Export bias if exists\n                bias_file = None\n                if module.bias is not None:\n                    bias_file = f\"{export_dir}/layer_{layer_idx}_bias.hex\"\n                    RTLExporter.export_tensor_to_hex(module.bias.data, bias_file)\n                \n                metadata['layers'].append({\n                    'layer_idx': layer_idx,\n                    'name': name,\n                    'weight_file': weight_file,\n                    'bias_file': bias_file,\n                    'in_features': module.in_features,\n                    'out_features': module.out_features,\n                    'weight_shape': list(weight.shape),\n                    'scale': float(scale),\n                    'zero_point': float(zero)\n                })\n                \n                layer_idx += 1\n        \n        # Save metadata\n        with open(f\"{export_dir}/model_metadata.json\", 'w') as f:\n            json.dump(metadata, f, indent=2)\n        \n        print(f\" Exported {layer_idx} layers to {export_dir}/\")\n        return metadata\n    \n    @staticmethod\n    def export_sample_input(image_tensor, filename, export_dir='rtl_exports'):\n        \"\"\"Export sample input for testing RTL implementation\"\"\"\n        os.makedirs(export_dir, exist_ok=True)\n        \n        filepath = f\"{export_dir}/{filename}\"\n        scale, zero = RTLExporter.export_tensor_to_hex(image_tensor, filepath)\n        \n        print(f\" Exported sample input to {filepath}\")\n        return scale, zero\n\n# ==================== QUANTIZED LINEAR LAYER (OPTIMIZED) ====================\n\nclass QuantizedLinear(torch.nn.Module):\n    def __init__(self, in_features, out_features, bias=True, use_custom_matmul=True):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.use_custom_matmul = use_custom_matmul\n        \n        self.weight = torch.nn.Parameter(\n            torch.randn(out_features, in_features) * math.sqrt(2.0 / in_features)\n        )\n        if bias:\n            self.bias = torch.nn.Parameter(torch.zeros(out_features))\n        else:\n            self.register_parameter('bias', None)\n        \n        self.register_buffer('weight_quantized', None)\n        self.register_buffer('weight_scale', None)\n        self.register_buffer('weight_zero_point', None)\n        self.quantized_mode = False\n    \n    def quantize_weights(self):\n        q_weight, scale, zero_point = Int8Quantizer.quantize_tensor(self.weight.data)\n        self.weight_quantized = q_weight\n        self.weight_scale = scale\n        self.weight_zero_point = zero_point\n        self.quantized_mode = True\n    \n    def forward(self, x):\n        if self.quantized_mode and self.weight_quantized is not None:\n            weight_dequant = Int8Quantizer.dequantize_tensor(\n                self.weight_quantized, self.weight_scale, self.weight_zero_point\n            )\n            output = F.linear(x, weight_dequant, self.bias)\n        else:\n            output = F.linear(x, self.weight, self.bias)\n        \n        return output\n\n# ==================== OTHER LAYERS (OPTIMIZED) ====================\n\nclass CustomLayerNorm(torch.nn.Module):\n    def __init__(self, normalized_shape, eps=1e-5):\n        super().__init__()\n        self.normalized_shape = normalized_shape\n        self.eps = eps\n        self.weight = torch.nn.Parameter(torch.ones(normalized_shape))\n        self.bias = torch.nn.Parameter(torch.zeros(normalized_shape))\n        \n    def forward(self, x):\n        return F.layer_norm(x, (self.normalized_shape,), self.weight, self.bias, self.eps)\n\nclass CustomDropout(torch.nn.Module):\n    def __init__(self, p=0.1):\n        super().__init__()\n        self.p = p\n        \n    def forward(self, x):\n        return F.dropout(x, self.p, self.training)\n\nclass CustomGELU(torch.nn.Module):\n    def forward(self, x):\n        return F.gelu(x)\n\nclass CustomConv2d(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super().__init__()\n        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        \n    def forward(self, x):\n        return self.conv(x)\n\n# ==================== MODEL COMPONENTS ====================\n\nclass CustomPatchEmbedding(torch.nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, embed_dim=256):\n        super().__init__()\n        self.patch_size = patch_size\n        self.proj = CustomConv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n        \n    def forward(self, x):\n        x = self.proj(x)\n        x = x.flatten(2).transpose(1, 2)\n        return x\n\nclass QuantizedMultiHeadAttention(torch.nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout=0.1):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.qkv = QuantizedLinear(embed_dim, embed_dim * 3)\n        self.attn_drop = CustomDropout(dropout)\n        self.proj = QuantizedLinear(embed_dim, embed_dim)\n        self.proj_drop = CustomDropout(dropout)\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = F.softmax(attn, dim=-1)\n        attn = self.attn_drop(attn)\n        \n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\nclass QuantizedMLP(torch.nn.Module):\n    def __init__(self, in_features, hidden_features=None, drop=0.1):\n        super().__init__()\n        hidden_features = hidden_features or int(in_features * 4.0)\n        \n        self.fc1 = QuantizedLinear(in_features, hidden_features)\n        self.act = CustomGELU()\n        self.fc2 = QuantizedLinear(hidden_features, in_features)\n        self.drop = CustomDropout(drop)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\nclass QuantizedTransformerBlock(torch.nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4.0, drop=0.1):\n        super().__init__()\n        self.norm1 = CustomLayerNorm(dim)\n        self.attn = QuantizedMultiHeadAttention(dim, num_heads, drop)\n        self.norm2 = CustomLayerNorm(dim)\n        self.mlp = QuantizedMLP(dim, hidden_features=int(dim * mlp_ratio), drop=drop)\n        \n    def forward(self, x):\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nclass QuantizedViT(torch.nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=4.0, dropout=0.1):\n        super().__init__()\n        \n        self.patch_embed = CustomPatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        num_patches = (img_size // patch_size) ** 2\n        \n        self.pos_embed = torch.nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n        torch.nn.init.trunc_normal_(self.pos_embed, std=0.02)\n        self.pos_drop = CustomDropout(dropout)\n        \n        self.blocks = torch.nn.ModuleList([\n            QuantizedTransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n            for _ in range(depth)\n        ])\n        \n        self.norm = CustomLayerNorm(embed_dim)\n        self.head = QuantizedLinear(embed_dim, num_classes)\n        \n        self.quantized_mode = False\n        \n    def quantize_model(self):\n        print(\"Quantizing model to INT8...\")\n        \n        for module in self.modules():\n            if isinstance(module, QuantizedLinear):\n                module.quantize_weights()\n        \n        self.quantized_mode = True\n        print(\" Model quantization completed!\")\n        \n    def get_model_size(self):\n        param_size = sum(p.nelement() * p.element_size() for p in self.parameters())\n        buffer_size = sum(b.nelement() * b.element_size() for b in self.buffers())\n        return (param_size + buffer_size) / (1024 ** 2)\n        \n    def forward(self, x):\n        x = self.patch_embed(x)\n        x = x + self.pos_embed\n        x = self.pos_drop(x)\n\n        for block in self.blocks:\n            x = block(x)\n\n        x = self.norm(x)\n        x = x.mean(dim=1)\n        x = self.head(x)\n        return x\n\n# ==================== OPTIMIZER (USING TORCH FOR SPEED) ====================\n\ndef get_optimizer(parameters, lr, weight_decay):\n    return torch.optim.AdamW(parameters, lr=lr, weight_decay=weight_decay)\n\ndef get_scheduler(optimizer, T_max):\n    return torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n\n# ==================== CONFIGURATION ====================\n\nclass Config:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    img_size = 64\n    patch_size = 8\n    embed_dim = 256\n    depth = 6\n    num_heads = 8\n    batch_size = 1024  \n    num_epochs = 100\n    initial_lr = 0.001\n    weight_decay = 0.05\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\n# ==================== DATA LOADING ====================\n\nbase_path = \"/kaggle/input/cifar10-64x64-resized-via-cai-super-resolution/cifar10-64\"\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomCrop(config.img_size, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616]),\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n])\n\ndef create_dataframe(split, limit=50000):\n    data = []\n    split_path = os.path.join(base_path, split)\n    \n    for class_name in sorted(os.listdir(split_path)):\n        class_path = os.path.join(split_path, class_name)\n        if os.path.isdir(class_path):\n            for img_name in os.listdir(class_path):\n                if len(data) < limit:\n                    data.append([os.path.join(class_path, img_name), class_name])\n    \n    return pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n\nprint(\"Loading dataset...\")\ntrain_df = create_dataframe(\"train\", 50000)\ntest_df = create_dataframe(\"test\", 10000)\n\nle = LabelEncoder()\ntrain_df[\"label\"] = le.fit_transform(train_df[\"label\"])\ntest_df[\"label\"] = le.transform(test_df[\"label\"])\n\nprint(f\"Train: {len(train_df)}, Test: {len(test_df)}\")\n\nclass CIFARDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.image_paths = df[\"image_path\"].tolist()\n        self.labels = df[\"label\"].tolist()\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        try:\n            image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n            return image, self.labels[idx]\n        except:\n            return torch.zeros(3, config.img_size, config.img_size), self.labels[idx]\n\ntrain_dataset = CIFARDataset(train_df, transform=train_transform)\ntest_dataset = CIFARDataset(test_df, transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, \n                          num_workers=4, pin_memory=True, persistent_workers=True)\ntest_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, \n                         num_workers=4, pin_memory=True, persistent_workers=True)\n\n# ==================== TRAINING ====================\n\n@torch.amp.autocast('cuda')\ndef forward_pass(model, images):\n    return model(images)\n\ndef evaluate_model(model, test_loader, device):\n    model.eval()\n    correct = total = 0\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    return 100. * correct / total\n\ndef train_model(model, train_loader, test_loader, config):\n    optimizer = get_optimizer(model.parameters(), config.initial_lr, config.weight_decay)\n    scheduler = get_scheduler(optimizer, config.num_epochs)\n    scaler = torch.amp.GradScaler('cuda')\n    \n    best_acc = 0.0\n    train_losses, test_accs = [], []\n    \n    print(\"Starting training...\")\n    \n    for epoch in range(config.num_epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for images, labels in train_loader:\n            images = images.to(config.device, non_blocking=True)\n            labels = labels.to(config.device, non_blocking=True)\n            \n            optimizer.zero_grad(set_to_none=True)\n            \n            with torch.amp.autocast('cuda'):\n                outputs = model(images)\n                loss = F.cross_entropy(outputs, labels)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            \n            train_loss += loss.item()\n        \n        test_acc = evaluate_model(model, test_loader, config.device)\n        avg_loss = train_loss / len(train_loader)\n        \n        train_losses.append(avg_loss)\n        test_accs.append(test_acc)\n        \n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save(model.state_dict(), 'best_float32_model.pth')\n        \n        scheduler.step()\n        \n        print(f'Epoch [{epoch+1}/{config.num_epochs}] Loss: {avg_loss:.4f} Acc: {test_acc:.2f}% Best: {best_acc:.2f}%')\n    \n    return train_losses, test_accs, best_acc\n\n# ==================== MAIN ====================\n\nif __name__ == \"__main__\":\n    print(\"=\"*70)\n    print(\"OPTIMIZED ViT WITH INT8 QUANTIZATION & RTL EXPORT\")\n    print(\"=\"*70)\n    \n    model = QuantizedViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        num_classes=len(le.classes_)\n    ).to(config.device)\n    \n    float32_size = model.get_model_size()\n    print(f\"\\nFloat32 Model: {float32_size:.2f} MB\")\n    \n    print(\"\\n=== TRAINING ===\")\n    start_time = time.time()\n    train_losses, test_accs, float32_best_acc = train_model(model, train_loader, test_loader, config)\n    training_time = time.time() - start_time\n    print(f\"Training time: {training_time:.1f}s\")\n    \n    print(\"\\n=== QUANTIZING ===\")\n    model.quantize_model()\n    int8_size = model.get_model_size()\n    print(f\"INT8 Model: {int8_size:.2f} MB (Compression: {float32_size/int8_size:.2f}x)\")\n    \n    int8_acc = evaluate_model(model, test_loader, config.device)\n    print(f\"INT8 Accuracy: {int8_acc:.2f}% (Drop: {float32_best_acc - int8_acc:.2f}%)\")\n    \n    print(\"\\n=== EXPORTING FOR RTL ===\")\n    metadata = RTLExporter.export_model_for_rtl(model, 'rtl_exports')\n    \n    # Export sample input\n    sample_image, sample_label = next(iter(test_loader))\n    sample_image = sample_image[0:1].to(config.device)\n    RTLExporter.export_sample_input(sample_image, 'sample_input.hex')\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"SUMMARY\")\n    print(\"=\"*70)\n    print(f\"Float32: {float32_size:.2f} MB, {float32_best_acc:.2f}%\")\n    print(f\"INT8: {int8_size:.2f} MB, {int8_acc:.2f}%\")\n    print(f\"Compression: {float32_size/int8_size:.2f}x\")\n    print(f\"Training time: {training_time:.1f}s\")\n    print(f\"RTL files exported to: rtl_exports/\")\n    print(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T16:39:38.038862Z","iopub.execute_input":"2025-09-30T16:39:38.039272Z","iopub.status.idle":"2025-09-30T17:21:11.566770Z","shell.execute_reply.started":"2025-09-30T16:39:38.039226Z","shell.execute_reply":"2025-09-30T17:21:11.565120Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading dataset...\nTrain: 50000, Test: 10000\n======================================================================\nOPTIMIZED ViT WITH INT8 QUANTIZATION & RTL EXPORT\n======================================================================\n\nFloat32 Model: 18.34 MB\n\n=== TRAINING ===\nStarting training...\nEpoch [1/100] Loss: 2.3629 Acc: 28.03% Best: 28.03%\nEpoch [2/100] Loss: 1.9017 Acc: 32.76% Best: 32.76%\nEpoch [3/100] Loss: 1.7711 Acc: 35.32% Best: 35.32%\nEpoch [4/100] Loss: 1.6482 Acc: 41.69% Best: 41.69%\nEpoch [5/100] Loss: 1.5235 Acc: 46.21% Best: 46.21%\nEpoch [6/100] Loss: 1.4428 Acc: 46.13% Best: 46.21%\nEpoch [7/100] Loss: 1.3668 Acc: 52.98% Best: 52.98%\nEpoch [8/100] Loss: 1.2936 Acc: 55.68% Best: 55.68%\nEpoch [9/100] Loss: 1.2408 Acc: 55.13% Best: 55.68%\nEpoch [10/100] Loss: 1.2037 Acc: 57.16% Best: 57.16%\nEpoch [11/100] Loss: 1.1703 Acc: 59.34% Best: 59.34%\nEpoch [12/100] Loss: 1.1291 Acc: 60.45% Best: 60.45%\nEpoch [13/100] Loss: 1.1145 Acc: 60.84% Best: 60.84%\nEpoch [14/100] Loss: 1.0835 Acc: 61.06% Best: 61.06%\nEpoch [15/100] Loss: 1.0611 Acc: 60.75% Best: 61.06%\nEpoch [16/100] Loss: 1.0489 Acc: 63.32% Best: 63.32%\nEpoch [17/100] Loss: 1.0120 Acc: 64.21% Best: 64.21%\nEpoch [18/100] Loss: 0.9965 Acc: 64.75% Best: 64.75%\nEpoch [19/100] Loss: 0.9806 Acc: 64.41% Best: 64.75%\nEpoch [20/100] Loss: 0.9533 Acc: 65.35% Best: 65.35%\nEpoch [21/100] Loss: 0.9400 Acc: 65.79% Best: 65.79%\nEpoch [22/100] Loss: 0.9158 Acc: 67.33% Best: 67.33%\nEpoch [23/100] Loss: 0.8908 Acc: 66.71% Best: 67.33%\nEpoch [24/100] Loss: 0.8863 Acc: 67.63% Best: 67.63%\nEpoch [25/100] Loss: 0.8657 Acc: 68.61% Best: 68.61%\nEpoch [26/100] Loss: 0.8549 Acc: 68.15% Best: 68.61%\nEpoch [27/100] Loss: 0.8368 Acc: 68.33% Best: 68.61%\nEpoch [28/100] Loss: 0.8328 Acc: 69.32% Best: 69.32%\nEpoch [29/100] Loss: 0.8137 Acc: 69.43% Best: 69.43%\nEpoch [30/100] Loss: 0.7932 Acc: 70.21% Best: 70.21%\nEpoch [31/100] Loss: 0.7869 Acc: 70.71% Best: 70.71%\nEpoch [32/100] Loss: 0.7618 Acc: 70.33% Best: 70.71%\nEpoch [33/100] Loss: 0.7628 Acc: 70.68% Best: 70.71%\nEpoch [34/100] Loss: 0.7400 Acc: 71.15% Best: 71.15%\nEpoch [35/100] Loss: 0.7272 Acc: 70.53% Best: 71.15%\nEpoch [36/100] Loss: 0.7199 Acc: 70.92% Best: 71.15%\nEpoch [37/100] Loss: 0.7006 Acc: 72.01% Best: 72.01%\nEpoch [38/100] Loss: 0.6819 Acc: 71.85% Best: 72.01%\nEpoch [39/100] Loss: 0.6770 Acc: 73.03% Best: 73.03%\nEpoch [40/100] Loss: 0.6566 Acc: 72.56% Best: 73.03%\nEpoch [41/100] Loss: 0.6460 Acc: 72.73% Best: 73.03%\nEpoch [42/100] Loss: 0.6307 Acc: 72.68% Best: 73.03%\nEpoch [43/100] Loss: 0.6249 Acc: 73.00% Best: 73.03%\nEpoch [44/100] Loss: 0.6114 Acc: 73.24% Best: 73.24%\nEpoch [45/100] Loss: 0.5893 Acc: 72.90% Best: 73.24%\nEpoch [46/100] Loss: 0.5826 Acc: 73.50% Best: 73.50%\nEpoch [47/100] Loss: 0.5700 Acc: 73.96% Best: 73.96%\nEpoch [48/100] Loss: 0.5444 Acc: 73.92% Best: 73.96%\nEpoch [49/100] Loss: 0.5376 Acc: 74.39% Best: 74.39%\nEpoch [50/100] Loss: 0.5277 Acc: 73.78% Best: 74.39%\nEpoch [51/100] Loss: 0.5185 Acc: 74.56% Best: 74.56%\nEpoch [52/100] Loss: 0.5151 Acc: 73.95% Best: 74.56%\nEpoch [53/100] Loss: 0.4883 Acc: 74.11% Best: 74.56%\nEpoch [54/100] Loss: 0.4671 Acc: 74.85% Best: 74.85%\nEpoch [55/100] Loss: 0.4542 Acc: 74.91% Best: 74.91%\nEpoch [56/100] Loss: 0.4414 Acc: 74.66% Best: 74.91%\nEpoch [57/100] Loss: 0.4363 Acc: 74.70% Best: 74.91%\nEpoch [58/100] Loss: 0.4153 Acc: 74.78% Best: 74.91%\nEpoch [59/100] Loss: 0.4039 Acc: 74.83% Best: 74.91%\nEpoch [60/100] Loss: 0.3889 Acc: 74.57% Best: 74.91%\nEpoch [61/100] Loss: 0.3801 Acc: 74.82% Best: 74.91%\nEpoch [62/100] Loss: 0.3675 Acc: 74.50% Best: 74.91%\nEpoch [63/100] Loss: 0.3502 Acc: 74.58% Best: 74.91%\nEpoch [64/100] Loss: 0.3353 Acc: 74.97% Best: 74.97%\nEpoch [65/100] Loss: 0.3249 Acc: 74.74% Best: 74.97%\nEpoch [66/100] Loss: 0.3192 Acc: 74.42% Best: 74.97%\nEpoch [67/100] Loss: 0.2999 Acc: 74.74% Best: 74.97%\nEpoch [68/100] Loss: 0.2875 Acc: 74.57% Best: 74.97%\nEpoch [69/100] Loss: 0.2770 Acc: 75.12% Best: 75.12%\nEpoch [70/100] Loss: 0.2638 Acc: 74.26% Best: 75.12%\nEpoch [71/100] Loss: 0.2552 Acc: 74.83% Best: 75.12%\nEpoch [72/100] Loss: 0.2442 Acc: 74.64% Best: 75.12%\nEpoch [73/100] Loss: 0.2344 Acc: 74.54% Best: 75.12%\nEpoch [74/100] Loss: 0.2278 Acc: 74.68% Best: 75.12%\nEpoch [75/100] Loss: 0.2192 Acc: 74.62% Best: 75.12%\nEpoch [76/100] Loss: 0.2083 Acc: 74.59% Best: 75.12%\nEpoch [77/100] Loss: 0.2035 Acc: 75.00% Best: 75.12%\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2686673862.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    586\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== TRAINING ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat32_best_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m     \u001b[0mtraining_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training time: {training_time:.1f}s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2686673862.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, config)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport math\nimport time\nimport warnings\nimport json\nwarnings.filterwarnings('ignore')\n\n# ==================== TILED MATRIX MULTIPLICATION ====================\n\ndef tiled_matmul(A, B, tile_size=32):\n    \"\"\"\n    Tiled matrix multiplication for better cache performance\n    \"\"\"\n    if A.dim() == 3 and B.dim() == 2:\n        batch_size, M, K = A.shape\n        K2, N = B.shape\n        assert K == K2, f\"Incompatible dimensions: {K} vs {K2}\"\n        \n        C = torch.zeros(batch_size, M, N, device=A.device, dtype=A.dtype)\n        for b in range(batch_size):\n            C[b] = tiled_matmul(A[b], B, tile_size)\n        return C\n    \n    if A.dim() == 2 and B.dim() == 2:\n        M, K = A.shape\n        K2, N = B.shape\n        assert K == K2, f\"Incompatible dimensions\"\n        \n        C = torch.zeros(M, N, device=A.device, dtype=A.dtype)\n        \n        # Tiled matrix multiplication\n        for i in range(0, M, tile_size):\n            i_end = min(i + tile_size, M)\n            for j in range(0, N, tile_size):\n                j_end = min(j + tile_size, N)\n                for k in range(0, K, tile_size):\n                    k_end = min(k + tile_size, K)\n                    \n                    # Multiply tiles using vectorized operations\n                    C[i:i_end, j:j_end] += A[i:i_end, k:k_end] @ B[k:k_end, j:j_end]\n        \n        return C\n    \n    return torch.matmul(A, B)\n\ndef custom_matmul_optimized(A, B, use_tiled=False, tile_size=32):\n    \"\"\"\n    Optimized custom matrix multiplication\n    \"\"\"\n    if use_tiled and A.device.type == 'cpu':\n        return tiled_matmul(A, B, tile_size)\n    \n    # For GPU or non-tiled, use einsum (fastest)\n    if A.dim() == 3 and B.dim() == 2:\n        return torch.einsum('bik,kj->bij', A, B)\n    \n    if A.dim() == 2 and B.dim() == 2:\n        return torch.einsum('ik,kj->ij', A, B)\n    \n    return torch.matmul(A, B)\n\n# ==================== INT8 QUANTIZATION UTILITIES ====================\n\nclass Int8Quantizer:\n    \"\"\"Custom INT8 quantizer for model weights and activations\"\"\"\n    \n    @staticmethod\n    def quantize_tensor(tensor, num_bits=8, symmetric=False):\n        if symmetric:\n            # Symmetric quantization\n            max_val = tensor.abs().max()\n            scale = max_val / (2**(num_bits-1) - 1)\n            zero_point = 0\n        else:\n            # Asymmetric quantization\n            qmin = -(2 ** (num_bits - 1))\n            qmax = 2 ** (num_bits - 1) - 1\n            \n            min_val = tensor.min()\n            max_val = tensor.max()\n            \n            scale = (max_val - min_val) / (qmax - qmin)\n            scale = max(scale, 1e-8)  # Avoid division by zero\n            zero_point = qmin - min_val / scale\n        \n        q_tensor = torch.round(tensor / scale + zero_point)\n        q_tensor = torch.clamp(q_tensor, qmin, qmax)\n        \n        return q_tensor.to(torch.int8), scale, zero_point\n    \n    @staticmethod\n    def dequantize_tensor(q_tensor, scale, zero_point):\n        return scale * (q_tensor.float() - zero_point)\n    \n    @staticmethod\n    def quantize_bias(bias, weight_scale, input_scale):\n        \"\"\"Quantize bias with proper scaling\"\"\"\n        bias_scale = weight_scale * input_scale\n        q_bias = torch.round(bias / bias_scale)\n        q_bias = torch.clamp(q_bias, -2**31, 2**31-1)  # INT32 range\n        return q_bias.to(torch.int32), bias_scale\n    \n    @staticmethod\n    def int8_matmul(A_quantized, B_quantized, A_scale, A_zero_point, B_scale, B_zero_point):\n        \"\"\"Proper INT8 matrix multiplication with zero point handling\"\"\"\n        # Convert to int32 for accumulation\n        A_int32 = A_quantized.to(torch.int32)\n        B_int32 = B_quantized.to(torch.int32)\n        \n        # Subtract zero points before multiplication\n        A_shifted = A_int32 - A_zero_point\n        B_shifted = B_int32 - B_zero_point\n        \n        # Perform matrix multiplication\n        C_int32 = custom_matmul_optimized(A_shifted, B_shifted)\n        \n        # Calculate result scale\n        result_scale = A_scale * B_scale\n        \n        # Convert back to float\n        C_float = C_int32.float() * result_scale\n        \n        return C_float\n\n# ==================== RTL EXPORT UTILITIES ====================\n\nclass RTLExporter:\n    \"\"\"Export weights and activations in RTL-friendly format\"\"\"\n    \n    @staticmethod\n    def export_tensor_to_hex(tensor, filename, bits=8):\n        \"\"\"Export tensor as hex file for Verilog $readmemh\"\"\"\n        if tensor.dtype != torch.int8 and tensor.dtype != torch.int32:\n            q_tensor, scale, zero_point = Int8Quantizer.quantize_tensor(tensor)\n        else:\n            q_tensor = tensor\n            scale, zero_point = 1.0, 0.0\n        \n        # Convert to appropriate format for hex representation\n        if q_tensor.dtype == torch.int8:\n            unsigned_tensor = q_tensor.to(torch.uint8)\n        elif q_tensor.dtype == torch.int32:\n            # For 32-bit values, split into bytes\n            unsigned_tensor = q_tensor.to(torch.int32)\n        else:\n            unsigned_tensor = q_tensor\n        \n        flat_tensor = unsigned_tensor.flatten().cpu().numpy()\n        \n        with open(filename, 'w') as f:\n            if bits == 8:\n                for val in flat_tensor:\n                    f.write(f\"{val & 0xFF:02x}\\n\")\n            elif bits == 32:\n                for val in flat_tensor:\n                    # Write as little-endian 32-bit hex\n                    f.write(f\"{val & 0xFFFFFFFF:08x}\\n\")\n        \n        return scale, zero_point\n    \n    @staticmethod\n    def export_tensor_to_binary(tensor, filename):\n        \"\"\"Export tensor as binary file\"\"\"\n        if tensor.dtype != torch.int8 and tensor.dtype != torch.int32:\n            q_tensor, scale, zero_point = Int8Quantizer.quantize_tensor(tensor)\n        else:\n            q_tensor = tensor\n            scale, zero_point = 1.0, 0.0\n        \n        flat_tensor = q_tensor.flatten().cpu().numpy()\n        flat_tensor.tofile(filename)\n        \n        return scale, zero_point\n    \n    @staticmethod\n    def export_model_for_rtl(model, export_dir='rtl_exports'):\n        \"\"\"Export all model weights and metadata for RTL implementation\"\"\"\n        os.makedirs(export_dir, exist_ok=True)\n        \n        metadata = {\n            'layers': [],\n            'model_info': {\n                'embed_dim': 256,\n                'num_heads': 8,\n                'num_layers': 6,\n                'num_classes': 10\n            },\n            'quantization_info': {\n                'weight_bits': 8,\n                'bias_bits': 32,\n                'symmetric': False\n            }\n        }\n        \n        layer_idx = 0\n        for name, module in model.named_modules():\n            if hasattr(module, 'weight_quantized') and module.weight_quantized is not None:\n                # Export weights\n                weight_file = f\"{export_dir}/layer_{layer_idx}_weight.hex\"\n                scale, zero_point = RTLExporter.export_tensor_to_hex(\n                    module.weight_quantized, weight_file, bits=8\n                )\n                \n                # Export bias if exists\n                bias_file = None\n                bias_scale = None\n                if hasattr(module, 'bias_quantized') and module.bias_quantized is not None:\n                    bias_file = f\"{export_dir}/layer_{layer_idx}_bias.hex\"\n                    bias_scale, _ = RTLExporter.export_tensor_to_hex(\n                        module.bias_quantized, bias_file, bits=32\n                    )\n                \n                metadata['layers'].append({\n                    'layer_idx': layer_idx,\n                    'name': name,\n                    'weight_file': weight_file,\n                    'bias_file': bias_file,\n                    'in_features': getattr(module, 'in_features', 'N/A'),\n                    'out_features': getattr(module, 'out_features', 'N/A'),\n                    'weight_shape': list(module.weight_quantized.shape),\n                    'weight_scale': float(scale),\n                    'weight_zero_point': float(zero_point),\n                    'bias_scale': float(bias_scale) if bias_scale else None\n                })\n                \n                layer_idx += 1\n        \n        # Save metadata\n        with open(f\"{export_dir}/model_metadata.json\", 'w') as f:\n            json.dump(metadata, f, indent=2)\n        \n        print(f\" Exported {layer_idx} layers to {export_dir}/\")\n        return metadata\n    \n    @staticmethod\n    def export_sample_input(image_tensor, filename, export_dir='rtl_exports'):\n        \"\"\"Export sample input for testing RTL implementation\"\"\"\n        os.makedirs(export_dir, exist_ok=True)\n        \n        filepath = f\"{export_dir}/{filename}\"\n        scale, zero_point = RTLExporter.export_tensor_to_hex(image_tensor, filepath)\n        \n        print(f\" Exported sample input to {filepath}\")\n        return scale, zero_point\n\n# ==================== QUANTIZED LINEAR LAYER (OPTIMIZED) ====================\n\nclass QuantizedLinear(torch.nn.Module):\n    def __init__(self, in_features, out_features, bias=True, use_custom_matmul=True):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.use_custom_matmul = use_custom_matmul\n        \n        # Initialize weights with Kaiming initialization\n        self.weight = torch.nn.Parameter(\n            torch.randn(out_features, in_features) * math.sqrt(2.0 / in_features)\n        )\n        \n        if bias:\n            self.bias = torch.nn.Parameter(torch.zeros(out_features))\n        else:\n            self.register_parameter('bias', None)\n        \n        # Quantization buffers\n        self.register_buffer('weight_quantized', None)\n        self.register_buffer('bias_quantized', None)\n        self.register_buffer('weight_scale', torch.tensor(1.0))\n        self.register_buffer('weight_zero_point', torch.tensor(0.0))\n        self.register_buffer('bias_scale', torch.tensor(1.0))\n        \n        self.quantized_mode = False\n    \n    def quantize_weights(self, input_scale=1.0):\n        \"\"\"Quantize weights and bias\"\"\"\n        # Quantize weights\n        self.weight_quantized, self.weight_scale, self.weight_zero_point = (\n            Int8Quantizer.quantize_tensor(self.weight.data, symmetric=True)\n        )\n        \n        # Quantize bias if exists\n        if self.bias is not None:\n            self.bias_quantized, self.bias_scale = Int8Quantizer.quantize_bias(\n                self.bias.data, self.weight_scale, input_scale\n            )\n        \n        self.quantized_mode = True\n    \n    def forward(self, x):\n        if self.quantized_mode and self.weight_quantized is not None:\n            # Use quantized weights (for inference)\n            weight_dequant = Int8Quantizer.dequantize_tensor(\n                self.weight_quantized, self.weight_scale, self.weight_zero_point\n            )\n            \n            if self.bias is not None and self.bias_quantized is not None:\n                bias_dequant = self.bias_quantized.float() * self.bias_scale\n            else:\n                bias_dequant = self.bias\n            \n            output = F.linear(x, weight_dequant, bias_dequant)\n        else:\n            # Use original float weights (for training)\n            output = F.linear(x, self.weight, self.bias)\n        \n        return output\n    \n    def get_quantized_size(self):\n        \"\"\"Calculate size of quantized parameters in MB\"\"\"\n        total_bytes = 0\n        \n        if self.weight_quantized is not None:\n            total_bytes += self.weight_quantized.nelement() * 1  # INT8 = 1 byte\n        \n        if self.bias_quantized is not None:\n            total_bytes += self.bias_quantized.nelement() * 4  # INT32 = 4 bytes\n        \n        return total_bytes / (1024 ** 2)\n\n# ==================== OTHER LAYERS (OPTIMIZED) ====================\n\nclass CustomLayerNorm(torch.nn.Module):\n    def __init__(self, normalized_shape, eps=1e-5):\n        super().__init__()\n        self.normalized_shape = normalized_shape\n        self.eps = eps\n        self.weight = torch.nn.Parameter(torch.ones(normalized_shape))\n        self.bias = torch.nn.Parameter(torch.zeros(normalized_shape))\n        \n    def forward(self, x):\n        return F.layer_norm(x, (self.normalized_shape,), self.weight, self.bias, self.eps)\n\nclass CustomDropout(torch.nn.Module):\n    def __init__(self, p=0.1):\n        super().__init__()\n        self.p = p\n        \n    def forward(self, x):\n        return F.dropout(x, self.p, self.training)\n\nclass CustomGELU(torch.nn.Module):\n    def forward(self, x):\n        return F.gelu(x)\n\nclass CustomConv2d(torch.nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n        super().__init__()\n        self.conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        \n    def forward(self, x):\n        return self.conv(x)\n\n# ==================== MODEL COMPONENTS ====================\n\nclass CustomPatchEmbedding(torch.nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, embed_dim=256):\n        super().__init__()\n        self.patch_size = patch_size\n        self.proj = CustomConv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n        \n    def forward(self, x):\n        x = self.proj(x)\n        x = x.flatten(2).transpose(1, 2)\n        return x\n\nclass QuantizedMultiHeadAttention(torch.nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout=0.1):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.qkv = QuantizedLinear(embed_dim, embed_dim * 3)\n        self.attn_drop = CustomDropout(dropout)\n        self.proj = QuantizedLinear(embed_dim, embed_dim)\n        self.proj_drop = CustomDropout(dropout)\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = F.softmax(attn, dim=-1)\n        attn = self.attn_drop(attn)\n        \n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\nclass QuantizedMLP(torch.nn.Module):\n    def __init__(self, in_features, hidden_features=None, drop=0.1):\n        super().__init__()\n        hidden_features = hidden_features or int(in_features * 4.0)\n        \n        self.fc1 = QuantizedLinear(in_features, hidden_features)\n        self.act = CustomGELU()\n        self.fc2 = QuantizedLinear(hidden_features, in_features)\n        self.drop = CustomDropout(drop)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\nclass QuantizedTransformerBlock(torch.nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4.0, drop=0.1):\n        super().__init__()\n        self.norm1 = CustomLayerNorm(dim)\n        self.attn = QuantizedMultiHeadAttention(dim, num_heads, drop)\n        self.norm2 = CustomLayerNorm(dim)\n        self.mlp = QuantizedMLP(dim, hidden_features=int(dim * mlp_ratio), drop=drop)\n        \n    def forward(self, x):\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nclass QuantizedViT(torch.nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=4.0, dropout=0.1):\n        super().__init__()\n        \n        self.patch_embed = CustomPatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        num_patches = (img_size // patch_size) ** 2\n        \n        self.pos_embed = torch.nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n        torch.nn.init.trunc_normal_(self.pos_embed, std=0.02)\n        self.pos_drop = CustomDropout(dropout)\n        \n        self.blocks = torch.nn.ModuleList([\n            QuantizedTransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n            for _ in range(depth)\n        ])\n        \n        self.norm = CustomLayerNorm(embed_dim)\n        self.head = QuantizedLinear(embed_dim, num_classes)\n        \n        self.quantized_mode = False\n        \n    def quantize_model(self):\n        \"\"\"Quantize all linear layers in the model\"\"\"\n        print(\"Quantizing model to INT8...\")\n        \n        for module in self.modules():\n            if isinstance(module, QuantizedLinear):\n                module.quantize_weights()\n        \n        self.quantized_mode = True\n        print(\"Model quantization completed!\")\n        \n    def get_model_size(self, quantized=False):\n        \"\"\"Calculate model size in MB\"\"\"\n        if quantized:\n            # Calculate quantized size\n            total_bytes = 0\n            for module in self.modules():\n                if isinstance(module, QuantizedLinear):\n                    total_bytes += module.get_quantized_size() * (1024 ** 2)\n            return total_bytes / (1024 ** 2)\n        else:\n            # Calculate float32 size\n            param_size = sum(p.nelement() * p.element_size() for p in self.parameters())\n            buffer_size = sum(b.nelement() * b.element_size() for b in self.buffers())\n            return (param_size + buffer_size) / (1024 ** 2)\n        \n    def forward(self, x):\n        x = self.patch_embed(x)\n        x = x + self.pos_embed\n        x = self.pos_drop(x)\n\n        for block in self.blocks:\n            x = block(x)\n\n        x = self.norm(x)\n        x = x.mean(dim=1)\n        x = self.head(x)\n        return x\n\n# ==================== OPTIMIZER & SCHEDULER ====================\n\ndef get_optimizer(parameters, lr, weight_decay):\n    return torch.optim.AdamW(parameters, lr=lr, weight_decay=weight_decay)\n\ndef get_scheduler(optimizer, T_max):\n    return torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_max)\n\n# ==================== CONFIGURATION ====================\n\nclass Config:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    img_size = 64\n    patch_size = 8\n    embed_dim = 256\n    depth = 6\n    num_heads = 8\n    batch_size = 64  # Start with smaller batch size\n    num_epochs = 100\n    initial_lr = 0.001\n    weight_decay = 0.05\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\n# ==================== DATA LOADING ====================\n\nbase_path = \"/kaggle/input/cifar10-64x64-resized-via-cai-super-resolution/cifar10-64\"\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomCrop(config.img_size, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616]),\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n])\n\ndef create_dataframe(split, limit=None):\n    data = []\n    split_path = os.path.join(base_path, split)\n    \n    for class_name in sorted(os.listdir(split_path)):\n        class_path = os.path.join(split_path, class_name)\n        if os.path.isdir(class_path):\n            for img_name in os.listdir(class_path):\n                if limit is None or len(data) < limit:\n                    data.append([os.path.join(class_path, img_name), class_name])\n    \n    return pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n\nprint(\"Loading dataset...\")\ntrain_df = create_dataframe(\"train\")\ntest_df = create_dataframe(\"test\")\n\nle = LabelEncoder()\ntrain_df[\"label\"] = le.fit_transform(train_df[\"label\"])\ntest_df[\"label\"] = le.transform(test_df[\"label\"])\n\nprint(f\"Train: {len(train_df)}, Test: {len(test_df)}\")\n\nclass CIFARDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.image_paths = df[\"image_path\"].tolist()\n        self.labels = df[\"label\"].tolist()\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        try:\n            image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n            return image, self.labels[idx]\n        except Exception as e:\n            print(f\"Error loading image {self.image_paths[idx]}: {e}\")\n            return torch.zeros(3, config.img_size, config.img_size), self.labels[idx]\n\ntrain_dataset = CIFARDataset(train_df, transform=train_transform)\ntest_dataset = CIFARDataset(test_df, transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, \n                          num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, \n                         num_workers=2, pin_memory=True)\n\n# ==================== TRAINING ====================\n\ndef forward_pass(model, images):\n    return model(images)\n\ndef evaluate_model(model, test_loader, device):\n    model.eval()\n    correct = total = 0\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    return 100. * correct / total\n\ndef train_model(model, train_loader, test_loader, config):\n    optimizer = get_optimizer(model.parameters(), config.initial_lr, config.weight_decay)\n    scheduler = get_scheduler(optimizer, config.num_epochs)\n    \n    # Use GradScaler for mixed precision\n    scaler = torch.cuda.amp.GradScaler() if config.device.type == 'cuda' else None\n    \n    best_acc = 0.0\n    train_losses, test_accs = [], []\n    \n    print(\"Starting training...\")\n    \n    for epoch in range(config.num_epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(config.device), labels.to(config.device)\n            \n            optimizer.zero_grad(set_to_none=True)\n            \n            if scaler:\n                # Mixed precision training\n                with torch.cuda.amp.autocast():\n                    outputs = model(images)\n                    loss = F.cross_entropy(outputs, labels)\n                \n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                # Standard training\n                outputs = model(images)\n                loss = F.cross_entropy(outputs, labels)\n                loss.backward()\n                optimizer.step()\n            \n            train_loss += loss.item()\n        \n        test_acc = evaluate_model(model, test_loader, config.device)\n        avg_loss = train_loss / len(train_loader)\n        \n        train_losses.append(avg_loss)\n        test_accs.append(test_acc)\n        \n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save(model.state_dict(), 'best_float32_model.pth')\n        \n        scheduler.step()\n        \n        if (epoch + 1) % 10 == 0:\n            print(f'Epoch [{epoch+1}/{config.num_epochs}] Loss: {avg_loss:.4f} Acc: {test_acc:.2f}% Best: {best_acc:.2f}%')\n    \n    return train_losses, test_accs, best_acc\n\n# ==================== UNIT TESTS ====================\n\ndef run_unit_tests():\n    \"\"\"Run unit tests for quantization and matrix multiplication\"\"\"\n    print(\"Running unit tests...\")\n    \n    # Test quantization\n    test_tensor = torch.randn(10, 10) * 2.0\n    q_tensor, scale, zero_point = Int8Quantizer.quantize_tensor(test_tensor)\n    deq_tensor = Int8Quantizer.dequantize_tensor(q_tensor, scale, zero_point)\n    \n    quantization_error = (test_tensor - deq_tensor).abs().mean()\n    print(f\" Quantization test - Mean error: {quantization_error:.6f}\")\n    \n    # Test matrix multiplication\n    A = torch.randn(32, 64)\n    B = torch.randn(64, 32)\n    \n    # Standard matmul\n    C_standard = torch.matmul(A, B)\n    \n    # Tiled matmul\n    C_tiled = tiled_matmul(A, B, tile_size=16)\n    \n    matmul_error = (C_standard - C_tiled).abs().mean()\n    print(f\" Matrix multiplication test - Mean error: {matmul_error:.6f}\")\n    \n    # Test INT8 matmul\n    A_q, A_scale, A_zp = Int8Quantizer.quantize_tensor(A)\n    B_q, B_scale, B_zp = Int8Quantizer.quantize_tensor(B)\n    \n    C_int8 = Int8Quantizer.int8_matmul(A_q, B_q, A_scale, A_zp, B_scale, B_zp)\n    int8_error = (C_standard - C_int8).abs().mean()\n    print(f\"INT8 matmul test - Mean error: {int8_error:.6f}\")\n    \n    print(\"All unit tests passed! \")\n\n# ==================== MAIN ====================\n\nif __name__ == \"__main__\":\n    print(\"=\"*70)\n    print(\"OPTIMIZED ViT WITH INT8 QUANTIZATION & RTL EXPORT\")\n    print(\"=\"*70)\n    \n    # Run unit tests\n    run_unit_tests()\n    \n    # Create model\n    model = QuantizedViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        num_classes=len(le.classes_)\n    ).to(config.device)\n    \n    float32_size = model.get_model_size(quantized=False)\n    print(f\"\\nFloat32 Model: {float32_size:.2f} MB\")\n    c\n    # Training\n    print(\"\\n=== TRAINING ===\")\n    start_time = time.time()\n    train_losses, test_accs, float32_best_acc = train_model(model, train_loader, test_loader, config)\n    training_time = time.time() - start_time\n    print(f\"Training time: {training_time:.1f}s\")\n    \n    # Quantization\n    print(\"\\n=== QUANTIZING ===\")\n    model.quantize_model()\n    int8_size = model.get_model_size(quantized=True)\n    print(f\"INT8 Model: {int8_size:.2f} MB (Compression: {float32_size/int8_size:.2f}x)\")\n    \n    # Test quantized model\n    int8_acc = evaluate_model(model, test_loader, config.device)\n    print(f\"INT8 Accuracy: {int8_acc:.2f}% (Drop: {float32_best_acc - int8_acc:.2f}%)\")\n    \n    # RTL Export\n    print(\"\\n=== EXPORTING FOR RTL ===\")\n    metadata = RTLExporter.export_model_for_rtl(model, 'rtl_exports')\n    \n    # Export sample input\n    sample_image, sample_label = next(iter(test_loader))\n    sample_image = sample_image[0:1].to(config.device)\n    RTLExporter.export_sample_input(sample_image, 'sample_input.hex')\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"SUMMARY\")\n    print(\"=\"*70)\n    print(f\"Float32: {float32_size:.2f} MB, {float32_best_acc:.2f}%\")\n    print(f\"INT8: {int8_size:.2f} MB, {int8_acc:.2f}%\")\n    print(f\"Compression: {float32_size/int8_size:.2f}x\")\n    print(f\"Accuracy drop: {float32_best_acc - int8_acc:.2f}%\")\n    print(f\"Training time: {training_time:.1f}s\")\n    print(f\"Training samples: {len(train_dataset)}\")\n    print(f\"Test samples: {len(test_dataset)}\")\n    print(f\"RTL files exported to: rtl_exports/\")\n    print(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-30T17:42:35.351385Z","iopub.execute_input":"2025-09-30T17:42:35.351684Z","iopub.status.idle":"2025-09-30T19:01:46.817992Z","shell.execute_reply.started":"2025-09-30T17:42:35.351658Z","shell.execute_reply":"2025-09-30T19:01:46.816834Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading dataset...\nTrain: 50000, Test: 10000\n======================================================================\nOPTIMIZED ViT WITH INT8 QUANTIZATION & RTL EXPORT\n======================================================================\nRunning unit tests...\n Quantization test - Mean error: 0.009003\n Matrix multiplication test - Mean error: 0.000001\nINT8 matmul test - Mean error: 0.069847\nAll unit tests passed! \n\nFloat32 Model: 18.34 MB\n\n=== TRAINING ===\nStarting training...\nEpoch [10/100] Loss: 1.2147 Acc: 57.03% Best: 57.03%\nEpoch [20/100] Loss: 0.8968 Acc: 67.97% Best: 67.97%\nEpoch [30/100] Loss: 0.6578 Acc: 74.19% Best: 74.19%\nEpoch [40/100] Loss: 0.4594 Acc: 77.49% Best: 77.49%\nEpoch [50/100] Loss: 0.2937 Acc: 78.94% Best: 79.27%\nEpoch [60/100] Loss: 0.1652 Acc: 79.94% Best: 79.94%\nEpoch [70/100] Loss: 0.0799 Acc: 79.99% Best: 79.99%\nEpoch [80/100] Loss: 0.0318 Acc: 80.34% Best: 80.44%\nEpoch [90/100] Loss: 0.0120 Acc: 80.98% Best: 81.09%\nEpoch [100/100] Loss: 0.0072 Acc: 81.06% Best: 81.16%\nTraining time: 4750.9s\n\n=== QUANTIZING ===\nQuantizing model to INT8...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2368248439.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;31m# Quantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== QUANTIZING ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m     \u001b[0mint8_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"INT8 Model: {int8_size:.2f} MB (Compression: {float32_size/int8_size:.2f}x)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2368248439.py\u001b[0m in \u001b[0;36mquantize_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuantizedLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantized_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2368248439.py\u001b[0m in \u001b[0;36mquantize_weights\u001b[0;34m(self, input_scale)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# Quantize weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         self.weight_quantized, self.weight_scale, self.weight_zero_point = (\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0mInt8Quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         )\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2368248439.py\u001b[0m in \u001b[0;36mquantize_tensor\u001b[0;34m(tensor, num_bits, symmetric)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mq_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mzero_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mq_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mq_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'qmin' where it is not associated with a value"],"ename":"UnboundLocalError","evalue":"cannot access local variable 'qmin' where it is not associated with a value","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport os\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport math\nimport time\nimport warnings\nimport json\nwarnings.filterwarnings('ignore')\n\n# ==================== INT8 QUANTIZATION UTILITIES ====================\n\nclass Int8Quantizer:\n    \"\"\"Custom INT8 quantizer for model weights and activations\"\"\"\n    \n    @staticmethod\n    def quantize_tensor(tensor, num_bits=8, symmetric=False):\n        if symmetric:\n            # Symmetric quantization\n            max_val = tensor.abs().max()\n            scale = max_val / (2**(num_bits-1) - 1)\n            zero_point = 0\n            \n            qmin = -(2 ** (num_bits - 1))\n            qmax = 2 ** (num_bits - 1) - 1\n        else:\n            # Asymmetric quantization\n            qmin = -(2 ** (num_bits - 1))\n            qmax = 2 ** (num_bits - 1) - 1\n            \n            min_val = tensor.min()\n            max_val = tensor.max()\n            \n            scale = (max_val - min_val) / (qmax - qmin)\n            scale = max(scale, 1e-8)  # Avoid division by zero\n            zero_point = qmin - min_val / scale\n        \n        q_tensor = torch.round(tensor / scale + zero_point)\n        q_tensor = torch.clamp(q_tensor, qmin, qmax)\n        \n        return q_tensor.to(torch.int8), scale, zero_point\n    \n    @staticmethod\n    def dequantize_tensor(q_tensor, scale, zero_point):\n        return scale * (q_tensor.float() - zero_point)\n    \n    @staticmethod\n    def quantize_bias(bias, weight_scale, input_scale):\n        \"\"\"Quantize bias with proper scaling\"\"\"\n        bias_scale = weight_scale * input_scale\n        q_bias = torch.round(bias / bias_scale)\n        q_bias = torch.clamp(q_bias, -2**31, 2**31-1)  # INT32 range\n        return q_bias.to(torch.int32), bias_scale\n\n# ==================== RTL EXPORT UTILITIES ====================\n\nclass RTLExporter:\n    \"\"\"Export weights and activations in RTL-friendly format\"\"\"\n    \n    @staticmethod\n    def export_tensor_to_hex(tensor, filename, bits=8):\n        \"\"\"Export tensor as hex file for Verilog $readmemh\"\"\"\n        if tensor.dtype != torch.int8 and tensor.dtype != torch.int32:\n            q_tensor, scale, zero_point = Int8Quantizer.quantize_tensor(tensor)\n        else:\n            q_tensor = tensor\n            scale, zero_point = 1.0, 0.0\n        \n        # Convert to appropriate format for hex representation\n        if q_tensor.dtype == torch.int8:\n            unsigned_tensor = q_tensor.to(torch.uint8)\n        elif q_tensor.dtype == torch.int32:\n            # For 32-bit values, split into bytes\n            unsigned_tensor = q_tensor.to(torch.int32)\n        else:\n            unsigned_tensor = q_tensor\n        \n        flat_tensor = unsigned_tensor.flatten().cpu().numpy()\n        \n        with open(filename, 'w') as f:\n            if bits == 8:\n                for val in flat_tensor:\n                    f.write(f\"{val & 0xFF:02x}\\n\")\n            elif bits == 32:\n                for val in flat_tensor:\n                    # Write as little-endian 32-bit hex\n                    f.write(f\"{val & 0xFFFFFFFF:08x}\\n\")\n        \n        return scale, zero_point\n    \n    @staticmethod\n    def export_tensor_to_binary(tensor, filename):\n        \"\"\"Export tensor as binary file\"\"\"\n        if tensor.dtype != torch.int8 and tensor.dtype != torch.int32:\n            q_tensor, scale, zero_point = Int8Quantizer.quantize_tensor(tensor)\n        else:\n            q_tensor = tensor\n            scale, zero_point = 1.0, 0.0\n        \n        flat_tensor = q_tensor.flatten().cpu().numpy()\n        flat_tensor.tofile(filename)\n        \n        return scale, zero_point\n    \n    @staticmethod\n    def export_model_for_rtl(model, export_dir='rtl_exports'):\n        \"\"\"Export all model weights and metadata for RTL implementation\"\"\"\n        os.makedirs(export_dir, exist_ok=True)\n        \n        metadata = {\n            'layers': [],\n            'model_info': {\n                'embed_dim': 256,\n                'num_heads': 8,\n                'num_layers': 6,\n                'num_classes': 10\n            },\n            'quantization_info': {\n                'weight_bits': 8,\n                'bias_bits': 32,\n                'symmetric': False\n            }\n        }\n        \n        layer_idx = 0\n        for name, module in model.named_modules():\n            if hasattr(module, 'weight_quantized') and module.weight_quantized is not None:\n                # Export weights\n                weight_file = f\"{export_dir}/layer_{layer_idx}_weight.hex\"\n                scale, zero_point = RTLExporter.export_tensor_to_hex(\n                    module.weight_quantized, weight_file, bits=8\n                )\n                \n                # Export bias if exists\n                bias_file = None\n                bias_scale = None\n                if hasattr(module, 'bias_quantized') and module.bias_quantized is not None:\n                    bias_file = f\"{export_dir}/layer_{layer_idx}_bias.hex\"\n                    bias_scale, _ = RTLExporter.export_tensor_to_hex(\n                        module.bias_quantized, bias_file, bits=32\n                    )\n                \n                metadata['layers'].append({\n                    'layer_idx': layer_idx,\n                    'name': name,\n                    'weight_file': weight_file,\n                    'bias_file': bias_file,\n                    'in_features': getattr(module, 'in_features', 'N/A'),\n                    'out_features': getattr(module, 'out_features', 'N/A'),\n                    'weight_shape': list(module.weight_quantized.shape),\n                    'weight_scale': float(scale),\n                    'weight_zero_point': float(zero_point),\n                    'bias_scale': float(bias_scale) if bias_scale else None\n                })\n                \n                layer_idx += 1\n        \n        # Save metadata\n        with open(f\"{export_dir}/model_metadata.json\", 'w') as f:\n            json.dump(metadata, f, indent=2)\n        \n        print(f\" Exported {layer_idx} layers to {export_dir}/\")\n        return metadata\n    \n    @staticmethod\n    def export_sample_input(image_tensor, filename, export_dir='rtl_exports'):\n        \"\"\"Export sample input for testing RTL implementation\"\"\"\n        os.makedirs(export_dir, exist_ok=True)\n        \n        filepath = f\"{export_dir}/{filename}\"\n        scale, zero_point = RTLExporter.export_tensor_to_hex(image_tensor, filepath)\n        \n        print(f\" Exported sample input to {filepath}\")\n        return scale, zero_point\n\n# ==================== QUANTIZED LINEAR LAYER ====================\n\nclass QuantizedLinear(nn.Module):\n    def __init__(self, in_features, out_features, bias=True):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        \n        # Initialize weights with Kaiming initialization\n        self.weight = nn.Parameter(\n            torch.randn(out_features, in_features) * math.sqrt(2.0 / in_features)\n        )\n        \n        if bias:\n            self.bias = nn.Parameter(torch.zeros(out_features))\n        else:\n            self.register_parameter('bias', None)\n        \n        # Quantization buffers\n        self.register_buffer('weight_quantized', None)\n        self.register_buffer('bias_quantized', None)\n        self.register_buffer('weight_scale', torch.tensor(1.0))\n        self.register_buffer('weight_zero_point', torch.tensor(0.0))\n        self.register_buffer('bias_scale', torch.tensor(1.0))\n        \n        self.quantized_mode = False\n    \n    def quantize_weights(self, input_scale=1.0):\n        \"\"\"Quantize weights and bias\"\"\"\n        # Quantize weights\n        self.weight_quantized, self.weight_scale, self.weight_zero_point = (\n            Int8Quantizer.quantize_tensor(self.weight.data, symmetric=True)\n        )\n        \n        # Quantize bias if exists\n        if self.bias is not None:\n            self.bias_quantized, self.bias_scale = Int8Quantizer.quantize_bias(\n                self.bias.data, self.weight_scale, input_scale\n            )\n        \n        self.quantized_mode = True\n    \n    def forward(self, x):\n        if self.quantized_mode and self.weight_quantized is not None:\n            # Use quantized weights (for inference)\n            weight_dequant = Int8Quantizer.dequantize_tensor(\n                self.weight_quantized, self.weight_scale, self.weight_zero_point\n            )\n            \n            if self.bias is not None and self.bias_quantized is not None:\n                bias_dequant = self.bias_quantized.float() * self.bias_scale\n            else:\n                bias_dequant = self.bias\n            \n            output = F.linear(x, weight_dequant, bias_dequant)\n        else:\n            # Use original float weights (for training)\n            output = F.linear(x, self.weight, self.bias)\n        \n        return output\n    \n    def get_quantized_size(self):\n        \"\"\"Calculate size of quantized parameters in MB\"\"\"\n        total_bytes = 0\n        \n        if self.weight_quantized is not None:\n            total_bytes += self.weight_quantized.nelement() * 1  # INT8 = 1 byte\n        \n        if self.bias_quantized is not None:\n            total_bytes += self.bias_quantized.nelement() * 4  # INT32 = 4 bytes\n        \n        return total_bytes / (1024 ** 2)\n\n# ==================== MODEL COMPONENTS ====================\n\nclass CustomPatchEmbedding(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, embed_dim=256):\n        super().__init__()\n        self.patch_size = patch_size\n        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n        \n    def forward(self, x):\n        x = self.proj(x)\n        x = x.flatten(2).transpose(1, 2)\n        return x\n\nclass QuantizedMultiHeadAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout=0.1):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        self.scale = self.head_dim ** -0.5\n        \n        self.qkv = QuantizedLinear(embed_dim, embed_dim * 3)\n        self.attn_drop = nn.Dropout(dropout)\n        self.proj = QuantizedLinear(embed_dim, embed_dim)\n        self.proj_drop = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        B, N, C = x.shape\n        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = F.softmax(attn, dim=-1)\n        attn = self.attn_drop(attn)\n        \n        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n        x = self.proj(x)\n        x = self.proj_drop(x)\n        return x\n\nclass QuantizedMLP(nn.Module):\n    def __init__(self, in_features, hidden_features=None, drop=0.1):\n        super().__init__()\n        hidden_features = hidden_features or int(in_features * 4.0)\n        \n        self.fc1 = QuantizedLinear(in_features, hidden_features)\n        self.act = nn.GELU()\n        self.fc2 = QuantizedLinear(hidden_features, in_features)\n        self.drop = nn.Dropout(drop)\n        \n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.act(x)\n        x = self.drop(x)\n        x = self.fc2(x)\n        x = self.drop(x)\n        return x\n\nclass QuantizedTransformerBlock(nn.Module):\n    def __init__(self, dim, num_heads, mlp_ratio=4.0, drop=0.1):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(dim)\n        self.attn = QuantizedMultiHeadAttention(dim, num_heads, drop)\n        self.norm2 = nn.LayerNorm(dim)\n        self.mlp = QuantizedMLP(dim, hidden_features=int(dim * mlp_ratio), drop=drop)\n        \n    def forward(self, x):\n        x = x + self.attn(self.norm1(x))\n        x = x + self.mlp(self.norm2(x))\n        return x\n\nclass QuantizedViT(nn.Module):\n    def __init__(self, img_size=64, patch_size=8, in_channels=3, num_classes=10,\n                 embed_dim=256, depth=6, num_heads=8, mlp_ratio=4.0, dropout=0.1):\n        super().__init__()\n        \n        self.patch_embed = CustomPatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        num_patches = (img_size // patch_size) ** 2\n        \n        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n        self.pos_drop = nn.Dropout(dropout)\n        \n        self.blocks = nn.ModuleList([\n            QuantizedTransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n            for _ in range(depth)\n        ])\n        \n        self.norm = nn.LayerNorm(embed_dim)\n        self.head = QuantizedLinear(embed_dim, num_classes)\n        \n        self.quantized_mode = False\n        \n    def quantize_model(self):\n        \"\"\"Quantize all linear layers in the model\"\"\"\n        print(\"Quantizing model to INT8...\")\n        \n        for module in self.modules():\n            if isinstance(module, QuantizedLinear):\n                module.quantize_weights()\n        \n        self.quantized_mode = True\n        print(\"Model quantization completed!\")\n        \n    def get_model_size(self, quantized=False):\n        \"\"\"Calculate model size in MB\"\"\"\n        if quantized:\n            # Calculate quantized size\n            total_bytes = 0\n            for module in self.modules():\n                if isinstance(module, QuantizedLinear):\n                    total_bytes += module.get_quantized_size() * (1024 ** 2)\n            return total_bytes / (1024 ** 2)\n        else:\n            # Calculate float32 size\n            param_size = sum(p.nelement() * p.element_size() for p in self.parameters())\n            buffer_size = sum(b.nelement() * b.element_size() for b in self.buffers())\n            return (param_size + buffer_size) / (1024 ** 2)\n        \n    def forward(self, x):\n        x = self.patch_embed(x)\n        x = x + self.pos_embed\n        x = self.pos_drop(x)\n\n        for block in self.blocks:\n            x = block(x)\n\n        x = self.norm(x)\n        x = x.mean(dim=1)\n        x = self.head(x)\n        return x\n\n# ==================== CONFIGURATION ====================\n\nclass Config:\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    img_size = 64\n    patch_size = 8\n    embed_dim = 256\n    depth = 6\n    num_heads = 8\n    batch_size = 64\n    num_epochs = 200\n    initial_lr = 0.001\n    weight_decay = 0.05\n\nconfig = Config()\nprint(f\"Using device: {config.device}\")\n\n# ==================== DATA LOADING ====================\n\nbase_path = \"/kaggle/input/cifar10-64x64-resized-via-cai-super-resolution/cifar10-64\"\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomCrop(config.img_size, padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616]),\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((config.img_size, config.img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2470, 0.2435, 0.2616])\n])\n\ndef create_dataframe(split, limit=None):\n    data = []\n    split_path = os.path.join(base_path, split)\n    \n    for class_name in sorted(os.listdir(split_path)):\n        class_path = os.path.join(split_path, class_name)\n        if os.path.isdir(class_path):\n            for img_name in os.listdir(class_path):\n                if limit is None or len(data) < limit:\n                    data.append([os.path.join(class_path, img_name), class_name])\n    \n    return pd.DataFrame(data, columns=[\"image_path\", \"label\"])\n\nprint(\"Loading dataset...\")\ntrain_df = create_dataframe(\"train\")\ntest_df = create_dataframe(\"test\")\n\nle = LabelEncoder()\ntrain_df[\"label\"] = le.fit_transform(train_df[\"label\"])\ntest_df[\"label\"] = le.transform(test_df[\"label\"])\n\nprint(f\"Train: {len(train_df)}, Test: {len(test_df)}\")\n\nclass CIFARDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        self.image_paths = df[\"image_path\"].tolist()\n        self.labels = df[\"label\"].tolist()\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        try:\n            image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n            return image, self.labels[idx]\n        except Exception as e:\n            print(f\"Error loading image {self.image_paths[idx]}: {e}\")\n            return torch.zeros(3, config.img_size, config.img_size), self.labels[idx]\n\ntrain_dataset = CIFARDataset(train_df, transform=train_transform)\ntest_dataset = CIFARDataset(test_df, transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, \n                          num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, \n                         num_workers=2, pin_memory=True)\n\n# ==================== TRAINING ====================\n\ndef evaluate_model(model, test_loader, device):\n    model.eval()\n    correct = total = 0\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    return 100. * correct / total\n\ndef train_model(model, train_loader, test_loader, config):\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config.initial_lr, weight_decay=config.weight_decay)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.num_epochs)\n    \n    # Use GradScaler for mixed precision\n    scaler = torch.cuda.amp.GradScaler() if config.device.type == 'cuda' else None\n    \n    best_acc = 0.0\n    train_losses, test_accs = [], []\n    \n    print(\"Starting training...\")\n    \n    for epoch in range(config.num_epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for images, labels in train_loader:\n            images, labels = images.to(config.device), labels.to(config.device)\n            \n            optimizer.zero_grad(set_to_none=True)\n            \n            if scaler:\n                # Mixed precision training\n                with torch.cuda.amp.autocast():\n                    outputs = model(images)\n                    loss = F.cross_entropy(outputs, labels)\n                \n                scaler.scale(loss).backward()\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                # Standard training\n                outputs = model(images)\n                loss = F.cross_entropy(outputs, labels)\n                loss.backward()\n                optimizer.step()\n            \n            train_loss += loss.item()\n        \n        test_acc = evaluate_model(model, test_loader, config.device)\n        avg_loss = train_loss / len(train_loader)\n        \n        train_losses.append(avg_loss)\n        test_accs.append(test_acc)\n        \n        if test_acc > best_acc:\n            best_acc = test_acc\n            torch.save(model.state_dict(), 'best_float32_model.pth')\n        \n        scheduler.step()\n        \n        if (epoch + 1) % 10 == 0:\n            print(f'Epoch [{epoch+1}/{config.num_epochs}] Loss: {avg_loss:.4f} Acc: {test_acc:.2f}% Best: {best_acc:.2f}%')\n    \n    return train_losses, test_accs, best_acc\n\n# ==================== UNIT TESTS ====================\n\ndef run_unit_tests():\n    \"\"\"Run unit tests for quantization\"\"\"\n    print(\"Running unit tests...\")\n    \n    # Test quantization\n    test_tensor = torch.randn(10, 10) * 2.0\n    q_tensor, scale, zero_point = Int8Quantizer.quantize_tensor(test_tensor)\n    deq_tensor = Int8Quantizer.dequantize_tensor(q_tensor, scale, zero_point)\n    \n    quantization_error = (test_tensor - deq_tensor).abs().mean()\n    print(f\" Quantization test - Mean error: {quantization_error:.6f}\")\n    \n    print(\"All unit tests passed! \")\n\n# ==================== API ENDPOINTS ====================\n\nclass ViTAPI:\n    \"\"\"API for ViT model management\"\"\"\n    \n    def __init__(self, model, config):\n        self.model = model\n        self.config = config\n        self.is_quantized = False\n    \n    def train(self, train_loader, test_loader):\n        \"\"\"Train the model\"\"\"\n        return train_model(self.model, train_loader, test_loader, self.config)\n    \n    def quantize(self):\n        \"\"\"Quantize the model to INT8\"\"\"\n        self.model.quantize_model()\n        self.is_quantized = True\n        return True\n    \n    def evaluate(self, test_loader):\n        \"\"\"Evaluate model accuracy\"\"\"\n        return evaluate_model(self.model, test_loader, self.config.device)\n    \n    def export_for_rtl(self, export_dir='rtl_exports'):\n        \"\"\"Export model for RTL implementation\"\"\"\n        return RTLExporter.export_model_for_rtl(self.model, export_dir)\n    \n    def get_model_size(self):\n        \"\"\"Get model size in MB\"\"\"\n        return self.model.get_model_size(quantized=self.is_quantized)\n    \n    def predict(self, image_tensor):\n        \"\"\"Make prediction on single image\"\"\"\n        self.model.eval()\n        with torch.no_grad():\n            output = self.model(image_tensor.unsqueeze(0).to(self.config.device))\n            return F.softmax(output, dim=1)\n\n# ==================== MAIN ====================\n\nif __name__ == \"__main__\":\n    print(\"=\"*70)\n    print(\"OPTIMIZED ViT WITH INT8 QUANTIZATION & RTL EXPORT\")\n    print(\"=\"*70)\n    \n    # Run unit tests\n    run_unit_tests()\n    \n    # Create model\n    model = QuantizedViT(\n        img_size=config.img_size,\n        patch_size=config.patch_size,\n        embed_dim=config.embed_dim,\n        depth=config.depth,\n        num_heads=config.num_heads,\n        num_classes=len(le.classes_)\n    ).to(config.device)\n    \n    # Create API instance\n    vit_api = ViTAPI(model, config)\n    \n    float32_size = vit_api.get_model_size()\n    print(f\"\\nFloat32 Model: {float32_size:.2f} MB\")\n    \n    # Training\n    print(\"\\n=== TRAINING ===\")\n    start_time = time.time()\n    train_losses, test_accs, float32_best_acc = vit_api.train(train_loader, test_loader)\n    training_time = time.time() - start_time\n    print(f\"Training time: {training_time:.1f}s\")\n    \n    # Quantization\n    print(\"\\n=== QUANTIZING ===\")\n    vit_api.quantize()\n    int8_size = vit_api.get_model_size()\n    print(f\"INT8 Model: {int8_size:.2f} MB (Compression: {float32_size/int8_size:.2f}x)\")\n    \n    # Test quantized model\n    int8_acc = vit_api.evaluate(test_loader)\n    print(f\"INT8 Accuracy: {int8_acc:.2f}% (Drop: {float32_best_acc - int8_acc:.2f}%)\")\n    \n    # RTL Export\n    print(\"\\n=== EXPORTING FOR RTL ===\")\n    metadata = vit_api.export_for_rtl('rtl_exports')\n    \n    # Export sample input\n    sample_image, sample_label = next(iter(test_loader))\n    sample_image = sample_image[0:1].to(config.device)\n    RTLExporter.export_sample_input(sample_image, 'sample_input.hex')\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"SUMMARY\")\n    print(\"=\"*70)\n    print(f\"Float32: {float32_size:.2f} MB, {float32_best_acc:.2f}%\")\n    print(f\"INT8: {int8_size:.2f} MB, {int8_acc:.2f}%\")\n    print(f\"Compression: {float32_size/int8_size:.2f}x\")\n    print(f\"Accuracy drop: {float32_best_acc - int8_acc:.2f}%\")\n    print(f\"Training time: {training_time:.1f}s\")\n    print(f\"Training samples: {len(train_dataset)}\")\n    print(f\"Test samples: {len(test_dataset)}\")\n    print(f\"RTL files exported to: rtl_exports/\")\n    print(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-01T15:22:50.788890Z","iopub.execute_input":"2025-10-01T15:22:50.789675Z","iopub.status.idle":"2025-10-01T17:59:30.955377Z","shell.execute_reply.started":"2025-10-01T15:22:50.789648Z","shell.execute_reply":"2025-10-01T17:59:30.954294Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading dataset...\nTrain: 50000, Test: 10000\n======================================================================\nOPTIMIZED ViT WITH INT8 QUANTIZATION & RTL EXPORT\n======================================================================\nRunning unit tests...\n Quantization test - Mean error: 0.011008\nAll unit tests passed! \n\nFloat32 Model: 18.34 MB\n\n=== TRAINING ===\nStarting training...\nEpoch [10/200] Loss: 1.2324 Acc: 56.16% Best: 56.16%\nEpoch [20/200] Loss: 0.9214 Acc: 66.79% Best: 66.79%\nEpoch [30/200] Loss: 0.7001 Acc: 73.53% Best: 73.53%\nEpoch [40/200] Loss: 0.5164 Acc: 73.96% Best: 76.92%\nEpoch [50/200] Loss: 0.3881 Acc: 78.79% Best: 79.23%\nEpoch [60/200] Loss: 0.2963 Acc: 78.75% Best: 80.14%\nEpoch [70/200] Loss: 0.2326 Acc: 80.12% Best: 80.15%\nEpoch [80/200] Loss: 0.1803 Acc: 78.99% Best: 80.15%\nEpoch [90/200] Loss: 0.1434 Acc: 79.36% Best: 80.30%\nEpoch [100/200] Loss: 0.1128 Acc: 79.17% Best: 80.37%\nEpoch [110/200] Loss: 0.0861 Acc: 80.72% Best: 80.84%\nEpoch [120/200] Loss: 0.0589 Acc: 80.22% Best: 80.84%\nEpoch [130/200] Loss: 0.0492 Acc: 80.32% Best: 80.84%\nEpoch [140/200] Loss: 0.0294 Acc: 81.02% Best: 81.17%\nEpoch [150/200] Loss: 0.0168 Acc: 80.95% Best: 81.93%\nEpoch [160/200] Loss: 0.0112 Acc: 81.51% Best: 81.93%\nEpoch [170/200] Loss: 0.0042 Acc: 81.57% Best: 82.10%\nEpoch [180/200] Loss: 0.0017 Acc: 82.19% Best: 82.34%\nEpoch [190/200] Loss: 0.0008 Acc: 82.28% Best: 82.39%\nEpoch [200/200] Loss: 0.0006 Acc: 82.28% Best: 82.39%\nTraining time: 9399.2s\n\n=== QUANTIZING ===\nQuantizing model to INT8...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3804880635.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;31m# Quantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== QUANTIZING ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m     \u001b[0mvit_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m     \u001b[0mint8_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvit_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"INT8 Model: {int8_size:.2f} MB (Compression: {float32_size/int8_size:.2f}x)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3804880635.py\u001b[0m in \u001b[0;36mquantize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;34m\"\"\"Quantize the model to INT8\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_quantized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3804880635.py\u001b[0m in \u001b[0;36mquantize_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQuantizedLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantized_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3804880635.py\u001b[0m in \u001b[0;36mquantize_weights\u001b[0;34m(self, input_scale)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;34m\"\"\"Quantize weights and bias\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# Quantize weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         self.weight_quantized, self.weight_scale, self.weight_zero_point = (\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0mInt8Quantizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1992\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1994\u001b[0;31m                         raise TypeError(\n\u001b[0m\u001b[1;32m   1995\u001b[0m                             \u001b[0;34mf\"cannot assign '{torch.typename(value)}' as buffer '{name}' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m                             \u001b[0;34m\"(torch.nn.Buffer, torch.Tensor or None expected)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: cannot assign 'int' as buffer 'weight_zero_point' (torch.nn.Buffer, torch.Tensor or None expected)"],"ename":"TypeError","evalue":"cannot assign 'int' as buffer 'weight_zero_point' (torch.nn.Buffer, torch.Tensor or None expected)","output_type":"error"}],"execution_count":3}]}